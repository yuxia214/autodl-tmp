{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/home/HDD6TB/datasets/emotions/ABAW/ABAW_8/8th_ABAW_Annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import pathlib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score,roc_auc_score,average_precision_score\n",
    "import mord\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import glob\n",
    "import gc\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv  \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_names(id):\n",
    "    name = \"\"\n",
    "    if id>=0 and id<10:\n",
    "        name = \"0000\" + str(id)\n",
    "    elif id>=10 and id<100:\n",
    "        name = \"000\" + str(id)\n",
    "    elif id>=100 and id<1000:\n",
    "        name = \"00\" + str(id)\n",
    "    elif id>=1000 and id<10000:\n",
    "        name = \"0\" + str(id)\n",
    "    else:\n",
    "        name = str(id)\n",
    "    return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_filenames=lambda x: int(os.path.splitext(x)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.0.1+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from itertools import chain\n",
    "import os\n",
    "import random\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "print(f\"Torch: {torch.__version__}\")\n",
    "device = 'cuda'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_classes=7\n",
    "if False:\n",
    "    #PATH='affectnet_vggface2_enet2_gmp_smooth.pt'\n",
    "    PATH='enet_b2_8_best.pt'\n",
    "    #PATH='enet_b2_7.pt'\n",
    "    IMG_SIZE=260 #224 #\n",
    "else:\n",
    "    #PATH='affectnet_vggface2_enet0.pt'\n",
    "    #PATH='affectnet_vggface2_enet0_new.pt'\n",
    "    #PATH='enet_b0_7.pt'\n",
    "    #PATH='enet_b0_8_best_afew.pt'\n",
    "    PATH='enet_b0_8_best_vgaf.pt'\n",
    "    #PATH='mobilevit_mtl_new.pt'\n",
    "    \n",
    "    #PATH='enet_b0_8_va_mtl.pt'\n",
    "    IMG_SIZE=224\n",
    "    \n",
    "#IMG_SIZE=112\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "np_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(None),\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        #transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_vgaf.pt\n"
     ]
    }
   ],
   "source": [
    "print(PATH)\n",
    "feature_extractor_model = torch.load('../../../models/affectnet_emotions/'+PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 512) [[ 0.01794354 -0.03431091 -0.00016818 ... -0.0268224  -0.02347743\n",
      "   0.02176051]\n",
      " [-0.02611435 -0.02214147  0.03573207 ... -0.00466314  0.04239551\n",
      "  -0.01990408]\n",
      " [-0.05963856 -0.01730311  0.04917104 ... -0.01539477 -0.00746309\n",
      "  -0.01494454]\n",
      " ...\n",
      " [ 0.04475736 -0.00453137  0.0154746  ... -0.00426385 -0.00999709\n",
      "  -0.01408496]\n",
      " [ 0.0183069  -0.00611857 -0.00720661 ...  0.00141637 -0.01378473\n",
      "  -0.00045164]\n",
      " [ 0.01398357  0.00257701  0.00391316 ... -0.00689993 -0.0030514\n",
      "   0.03322613]]\n",
      "(10,) [ 0.00227628  0.00355737 -0.00111303 -0.03025234 -0.0463375   0.0778885\n",
      "  0.01492943 -0.01847218 -0.05123357  0.05881068]\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    classifier_weights=feature_extractor_model.classifier[0].weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.classifier[0].bias.cpu().data.numpy()\n",
    "elif False:\n",
    "    classifier_weights=feature_extractor_model.classifier.weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.classifier.bias.cpu().data.numpy()\n",
    "elif False:\n",
    "    classifier_weights=feature_extractor_model.head.fc.weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.head.fc.bias.cpu().data.numpy()\n",
    "else:\n",
    "    classifier_weights=feature_extractor_model.fc.weight.cpu().data.numpy()\n",
    "    classifier_bias=feature_extractor_model.fc.bias.cpu().data.numpy()\n",
    "print(classifier_weights.shape,classifier_weights)\n",
    "print(classifier_bias.shape,classifier_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DDAMNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv_block(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (1): Conv_block(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=64)\n",
       "    )\n",
       "    (2): Mix_Depth_Wise(\n",
       "      (conv): Conv_block(\n",
       "        (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "      )\n",
       "      (conv_dw): MDConv(\n",
       "        (mixed_depthwise_conv): ModuleList(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=32, bias=False)\n",
       "          (2): Conv2d(32, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=32, bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=128)\n",
       "      )\n",
       "      (CA): CoordAtt(\n",
       "        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): h_swish(\n",
       "          (sigmoid): h_sigmoid(\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (project): Linear_block(\n",
       "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Mix_Residual(\n",
       "      (model): Sequential(\n",
       "        (0): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (8): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)\n",
       "              (1): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=32, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=128)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): Mix_Depth_Wise(\n",
       "      (conv): Conv_block(\n",
       "        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "      )\n",
       "      (conv_dw): MDConv(\n",
       "        (mixed_depthwise_conv): ModuleList(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64, bias=False)\n",
       "          (2): Conv2d(64, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=64, bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=256)\n",
       "      )\n",
       "      (CA): CoordAtt(\n",
       "        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): h_swish(\n",
       "          (sigmoid): h_sigmoid(\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (project): Linear_block(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Mix_Residual(\n",
       "      (model): Sequential(\n",
       "        (0): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (8): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (9): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (10): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (11): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (12): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (13): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (14): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (15): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "              (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=256)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(256, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(8, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): Mix_Depth_Wise(\n",
       "      (conv): Conv_block(\n",
       "        (conv): Conv2d(128, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1024)\n",
       "      )\n",
       "      (conv_dw): MDConv(\n",
       "        (mixed_depthwise_conv): ModuleList(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "          (1): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256, bias=False)\n",
       "          (2): Conv2d(256, 256, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=256, bias=False)\n",
       "          (3): Conv2d(256, 256, kernel_size=(9, 9), stride=(2, 2), padding=(4, 4), groups=256, bias=False)\n",
       "        )\n",
       "        (bn): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (prelu): PReLU(num_parameters=1024)\n",
       "      )\n",
       "      (CA): CoordAtt(\n",
       "        (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "        (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "        (conv1): Conv2d(1024, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (conv3): Conv2d(32, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (relu): h_swish(\n",
       "          (sigmoid): h_sigmoid(\n",
       "            (relu): ReLU6(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (project): Linear_block(\n",
       "        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Mix_Residual(\n",
       "      (model): Sequential(\n",
       "        (0): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (3): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (4): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Mix_Depth_Wise(\n",
       "          (conv): Conv_block(\n",
       "            (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (conv_dw): MDConv(\n",
       "            (mixed_depthwise_conv): ModuleList(\n",
       "              (0): Conv2d(172, 172, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=172, bias=False)\n",
       "              (1): Conv2d(170, 170, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=170, bias=False)\n",
       "              (2): Conv2d(170, 170, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=170, bias=False)\n",
       "            )\n",
       "            (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (prelu): PReLU(num_parameters=512)\n",
       "          )\n",
       "          (CA): CoordAtt(\n",
       "            (pool_h): AdaptiveAvgPool2d(output_size=(None, 1))\n",
       "            (pool_w): AdaptiveAvgPool2d(output_size=(1, None))\n",
       "            (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (relu): h_swish(\n",
       "              (sigmoid): h_sigmoid(\n",
       "                (relu): ReLU6(inplace=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (project): Linear_block(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (8): Conv_block(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "    )\n",
       "  )\n",
       "  (cat_head0): CoordAttHead(\n",
       "    (CoordAtt): CoordAtt(\n",
       "      (Linear_h): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (Linear_w): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): h_swish(\n",
       "        (sigmoid): h_sigmoid(\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Linear): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (flatten): Flatten()\n",
       "    )\n",
       "  )\n",
       "  (cat_head1): CoordAttHead(\n",
       "    (CoordAtt): CoordAtt(\n",
       "      (Linear_h): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(1, 7), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (Linear_w): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(7, 1), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (conv1): Conv2d(512, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (conv3): Conv2d(16, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (relu): h_swish(\n",
       "        (sigmoid): h_sigmoid(\n",
       "          (relu): ReLU6(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (Linear): Linear_block(\n",
       "        (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (flatten): Flatten()\n",
       "    )\n",
       "  )\n",
       "  (Linear): Linear_block(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (flatten): Flatten()\n",
       "  (fc): Identity()\n",
       "  (bn): Identity()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if True:\n",
    "    feature_extractor_model.classifier=torch.nn.Identity()\n",
    "elif False:\n",
    "    feature_extractor_model.head.fc=torch.nn.Identity()\n",
    "else:\n",
    "    feature_extractor_model.fc=torch.nn.Identity()\n",
    "feature_extractor_model=feature_extractor_model.to(device)\n",
    "feature_extractor_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probab(features):\n",
    "    x=np.dot(features,np.transpose(classifier_weights))+classifier_bias\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=(112, 112), interpolation=bilinear, max_size=None, antialias=warn)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "/home/HDD6TB/datasets/emotions/ABAW/ABAW_6/6th_ABAW_Annotations/cropped\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238a9d168d164181ad18556263385b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(test_transforms)\n",
    "img_names=[]\n",
    "X_global_features=[]\n",
    "imgs=[]\n",
    "data_dir=os.path.join(DATA_DIR,'cropped')\n",
    "print(data_dir)\n",
    "for filename in tqdm(os.listdir(data_dir)):\n",
    "    frames_dir=os.path.join(data_dir,filename)   \n",
    "    if not os.path.isdir(frames_dir):\n",
    "        continue\n",
    "    for img_name in os.listdir(frames_dir):\n",
    "        if img_name.lower().endswith('.jpg'):\n",
    "            img = Image.open(os.path.join(frames_dir,img_name))\n",
    "            img_tensor = test_transforms(img)\n",
    "            if img.size:\n",
    "                img_names.append(filename+'/'+img_name)\n",
    "                imgs.append(img_tensor)\n",
    "                if len(imgs)>=64: #96: #64: #32:        \n",
    "                    features,_,_  = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                    features=features.data.cpu().numpy()\n",
    "                    #print(features.shape)\n",
    "\n",
    "                    if len(X_global_features)==0:\n",
    "                        X_global_features=features\n",
    "                    else:\n",
    "                        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "                    imgs=[]\n",
    "\n",
    "if len(imgs)>0:        \n",
    "    features,_,_  = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "    features=features.data.cpu().numpy()\n",
    "\n",
    "    if len(X_global_features)==0:\n",
    "        X_global_features=features\n",
    "    else:\n",
    "        X_global_features=np.concatenate((X_global_features,features),axis=0)\n",
    "\n",
    "    imgs=[]\n",
    "\n",
    "    #X_scores=X_global_features #get_probab(X_global_features)\n",
    "    #print(X_global_features.shape,X_scores.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scores=get_probab(X_global_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2942996\n"
     ]
    }
   ],
   "source": [
    "filename2featuresAll={img_name:(global_features,scores) for img_name,global_features,scores in zip(img_names,X_global_features,X_scores)}\n",
    "print(len(filename2featuresAll))\n",
    "#cropped 2942996, aligned 2941546"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save/load features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_best_vgaf_cropped.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "num_classes=8\n",
    "#model_name='enet_b2_8_best'\n",
    "model_name='enet_b0_8_best_vgaf'\n",
    "#model_name='mobilevit_mtl'\n",
    "#model_name='mbf_va'\n",
    "\n",
    "#model_name='ddamfnet_8' #affectnet8_epoch4_acc0.6462\n",
    "#model_name='ddamfnet_8_mtl' #affectnet8_epoch6_acc0\n",
    "\n",
    "#model_name='enet_b0_8_va_mtl'\n",
    "#MODEL2FEATURES=model_name+'_aligned_112.pickle'\n",
    "MODEL2FEATURES=model_name+'_cropped.pickle' \n",
    "\n",
    "print(MODEL2FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    with open(MODEL2FEATURES, 'wb') as handle:\n",
    "        pickle.dump(filename2featuresAll, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../abaw5/enet_b0_8_best_vgaf_cropped.pickle 2942996\n"
     ]
    }
   ],
   "source": [
    "#filename=MODEL2FEATURES\n",
    "filename='../abaw5/'+MODEL2FEATURES\n",
    "with open(filename, 'rb') as handle:\n",
    "    filename2featuresAll=pickle.load(handle)\n",
    "print(filename,len(filename2featuresAll))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for filename in filename2featuresAll:\n",
    "        filename2featuresAll[filename]=(filename2featuresAll[filename][0].astype(np.float16),filename2featuresAll[filename][1].astype(np.float16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27-60-1280x720 2933\n",
      "video39 10679\n",
      "77-30-1280x720 5673\n",
      "91-30-1920x1080 10922\n",
      "360 3510\n",
      "136 4488\n",
      "197 1870\n",
      "291 1831\n",
      "16-30-1920x1080 5474\n",
      "video2 2065\n",
      "89-30-1080x1920 631\n",
      "408 2979\n",
      "110-30-270x480 9979\n",
      "324 5615\n",
      "14-30-1920x1080 5311\n",
      "129-24-1280x720 6154\n",
      "153 3678\n",
      "314 2261\n",
      "255 1692\n",
      "284 4055\n",
      "298 2837\n",
      "206 4477\n",
      "video84 526\n",
      "387 2912\n",
      "286 2678\n",
      "55-25-1280x720 1506\n",
      "336 4345\n",
      "video52 10680\n",
      "60-30-1920x1080 4565\n",
      "120 3592\n",
      "267 3842\n",
      "121-24-1920x1080 10629\n",
      "349 4055\n",
      "46-30-484x360 2945\n",
      "218 3850\n",
      "video55 8420\n",
      "368 2930\n",
      "9-15-1920x1080 47435\n",
      "384 3452\n",
      "228 2156\n",
      "video3 7802\n",
      "106-30-720x1280 1405\n",
      "64-24-640x360 4919\n",
      "244 2322\n",
      "28-30-1280x720-2 397\n",
      "235 3683\n",
      "video86_3 403\n",
      "92-24-1920x1080 8164\n",
      "376 3570\n",
      "185 4053\n",
      "157 2605\n",
      "38-30-1920x1080 2432\n",
      "video87 1823\n",
      "57-25-426x240 301\n",
      "4-30-1920x1080 8261\n",
      "video86_2 887\n",
      "video45_5 415\n",
      "143 10103\n",
      "114 2450\n",
      "243 4121\n",
      "133 461\n",
      "video64 6101\n",
      "125-25-1280x720 6842\n",
      "video81 8434\n",
      "274 3527\n",
      "113 15021\n",
      "video66 155\n",
      "171 3977\n",
      "446 2249\n",
      "126-30-1080x1920 4595\n",
      "168 2979\n",
      "video33 7554\n",
      "201 1361\n",
      "video61 117\n",
      "236 3674\n",
      "119 4577\n",
      "116 2518\n",
      "82-25-854x480 5403\n",
      "15-24-1920x1080 3593\n",
      "87-25-1920x1080 1803\n",
      "36-24-1280x720 5261\n",
      "130-25-1280x720 8462\n",
      "219 3892\n",
      "123-25-1920x1080 27242\n",
      "318 4108\n",
      "133-30-1280x720 2404\n",
      "26-60-1280x720 2066\n",
      "266 2466\n",
      "7-60-1920x1080 23149\n",
      "70-30-720x1280 2784\n",
      "261 2867\n",
      "video9 3795\n",
      "199 2918\n",
      "282 3615\n",
      "305 4579\n",
      "5-60-1920x1080-4 4893\n",
      "116-30-1280x720 6184\n",
      "video91 711\n",
      "19-24-1920x1080 6634\n",
      "video21 6809\n",
      "196 5454\n",
      "10-60-1280x720 2502\n",
      "385 2977\n",
      "video8 5368\n",
      "video44 7786\n",
      "video83 2703\n",
      "202 941\n",
      "32-60-1920x1080 4460\n",
      "video90 3571\n",
      "323 2937\n",
      "198 2285\n",
      "78-30-960x720 4443\n",
      "video63 275\n",
      "359 3862\n",
      "386 1752\n",
      "373 2705\n",
      "225 1463\n",
      "48-30-720x1280 1593\n",
      "382 2714\n",
      "video41 3495\n",
      "176 6416\n",
      "165 4568\n",
      "31-30-1920x1080 4723\n",
      "24-30-1920x1080-1 1913\n",
      "214 2556\n",
      "434 5233\n",
      "426 2780\n",
      "449 3553\n",
      "149 15659\n",
      "307 3311\n",
      "video56 10696\n",
      "video35 3568\n",
      "319 2138\n",
      "video74 18190\n",
      "video45_6 309\n",
      "video5 2469\n",
      "347 2925\n",
      "138-30-1280x720 3332\n",
      "312 5110\n",
      "video15 4288\n",
      "326 4718\n",
      "207 3039\n",
      "204 5926\n",
      "135-24-1920x1080 9424\n",
      "video27 16419\n",
      "358 325\n",
      "video53 7980\n",
      "208 5160\n",
      "39-25-424x240 4591\n",
      "137 4787\n",
      "video14 7586\n",
      "227 4418\n",
      "155 3114\n",
      "112 5916\n",
      "video89 2242\n",
      "402 4423\n",
      "video67 1850\n",
      "video38 2945\n",
      "105 10077\n",
      "134 1790\n",
      "100-29-1080x1920 2640\n",
      "167 4718\n",
      "277 5172\n",
      "346 5694\n",
      "128 6287\n",
      "269 4698\n",
      "425 5071\n",
      "video24 5205\n",
      "103 26618\n",
      "415 2904\n",
      "393 4917\n",
      "203 3965\n",
      "439 2309\n",
      "450 9908\n",
      "110 5505\n",
      "365 1068\n",
      "395 5154\n",
      "75-30-960x720 1954\n",
      "398 3270\n",
      "375 2958\n",
      "258 1465\n",
      "147 19695\n",
      "video23 8790\n",
      "83-24-1920x1080 5344\n",
      "video93 444\n",
      "58-30-640x480 2877\n",
      "429 1674\n",
      "63-30-1920x1080 2413\n",
      "video46 3173\n",
      "115-30-1280x720 4082\n",
      "187 4405\n",
      "111 7247\n",
      "video10_1 4257\n",
      "124-30-720x1280 10495\n",
      "210 3239\n",
      "video36 2425\n",
      "364 3319\n",
      "81-30-576x360 3604\n",
      "328 2715\n",
      "122-60-1920x1080-3 9244\n",
      "186 4166\n",
      "video45_7 180\n",
      "22-30-1920x1080 5336\n",
      "175 2503\n",
      "video13 10567\n",
      "80-30-320x240 5674\n",
      "video25 3645\n",
      "388 4159\n",
      "112-30-640x360 6003\n",
      "video85 7947\n",
      "96-30-1280x720 5604\n",
      "video34 10282\n",
      "293 2111\n",
      "234 2920\n",
      "353 2857\n",
      "288 3200\n",
      "292 4704\n",
      "424 4433\n",
      "53-30-360x480 1053\n",
      "122-60-1920x1080-1 7863\n",
      "128-24-1920x1080 3813\n",
      "179 4451\n",
      "315 3938\n",
      "148 18145\n",
      "181 5862\n",
      "194 4537\n",
      "video77 3005\n",
      "video86_1 1772\n",
      "37-30-1280x720 2707\n",
      "268 4367\n",
      "290 3163\n",
      "71-30-1920x1080 8002\n",
      "399 5200\n",
      "video75 641\n",
      "8-30-1280x720 9114\n",
      "video72 129\n",
      "102-30-640x360 2984\n",
      "177 3127\n",
      "144 15606\n",
      "123 9777\n",
      "374 1213\n",
      "348 4445\n",
      "video12 5580\n",
      "video7 3378\n",
      "322 2429\n",
      "309 2499\n",
      "107-30-640x480 74\n",
      "189 3855\n",
      "372 2043\n",
      "245 2531\n",
      "229 3563\n",
      "61-24-1920x1080 9157\n",
      "159 3459\n",
      "240 6792\n",
      "195 6118\n",
      "394 2336\n",
      "84-30-1920x1080 2584\n",
      "256 3337\n",
      "273 4620\n",
      "35-30-1920x1080 20808\n",
      "278 4287\n",
      "17-24-1920x1080 5788\n",
      "246 1346\n",
      "257 4389\n",
      "275 2448\n",
      "220 5026\n",
      "334 3399\n",
      "131-30-1920x1080 8013\n",
      "video1 14588\n",
      "18-24-1920x1080 4831\n",
      "226 4097\n",
      "109-30-1280x720 1046\n",
      "335 3279\n",
      "99-30-720x720 1801\n",
      "video92 2554\n",
      "418 2907\n",
      "389 4557\n",
      "260 2405\n",
      "355 1632\n",
      "357 1374\n",
      "28-30-1280x720-1 263\n",
      "59-30-1280x720 7742\n",
      "25-25-600x480 5744\n",
      "211 2163\n",
      "105-30-1280x720 1502\n",
      "241 3513\n",
      "video73 5952\n",
      "2-30-640x360 19353\n",
      "254 3387\n",
      "107 5316\n",
      "137-30-1920x1080 8553\n",
      "285 2989\n",
      "200 5040\n",
      "221 5125\n",
      "video26 11021\n",
      "video45_4 1039\n",
      "172 11645\n",
      "354 5390\n",
      "391 3584\n",
      "video60 1920\n",
      "video82 10672\n",
      "40-30-1280x720 9660\n",
      "50-30-1920x1080 2700\n",
      "252 2757\n",
      "381 1266\n",
      "video29 11260\n",
      "65-30-400x228 6668\n",
      "108-15-640x480 479\n",
      "447 3994\n",
      "video45_1 813\n",
      "video51 4408\n",
      "118-30-640x480 2421\n",
      "190 5427\n",
      "106 8164\n",
      "294 3289\n",
      "video54 3592\n",
      "140 4583\n",
      "141 4406\n",
      "253 2277\n",
      "127-30-1280x720 2214\n",
      "247 2271\n",
      "11-24-1920x1080 5390\n",
      "289 4204\n",
      "371 681\n",
      "161 1729\n",
      "47-30-654x480 4034\n",
      "140-30-632x360 6755\n",
      "317 1686\n",
      "182 4356\n",
      "85-24-1280x720 2665\n",
      "345 2345\n",
      "97-29-1920x1080 3367\n",
      "video11 4380\n",
      "45-24-1280x720 6082\n",
      "212 4563\n",
      "28-30-1280x720-4 277\n",
      "251 2107\n",
      "129 9014\n",
      "120-30-1280x720 15042\n",
      "30-30-1920x1080 3063\n",
      "166 4515\n",
      "56-30-1080x1920 4301\n",
      "295 3770\n",
      "video20 11272\n",
      "320 4739\n",
      "5-60-1920x1080-1 6154\n",
      "117-25-1920x1080 4082\n",
      "403 2166\n",
      "440 2521\n",
      "213 6398\n",
      "video88 8851\n",
      "232 2373\n",
      "104-17-720x480 2426\n",
      "29-24-1280x720 3684\n",
      "224 2234\n",
      "331 2955\n",
      "264 4745\n",
      "video30 8218\n",
      "341 3097\n",
      "215 3410\n",
      "94-30-1920x1080 2102\n",
      "421 3616\n",
      "138 5584\n",
      "117 5466\n",
      "video42 9227\n",
      "6-30-1920x1080 7986\n",
      "332 4666\n",
      "409 3609\n",
      "44-25-426x240 301\n",
      "154 3363\n",
      "407 3818\n",
      "41-24-1280x720 6161\n",
      "5-60-1920x1080-3 6334\n",
      "158 3032\n",
      "43-30-406x720 2874\n",
      "video94 697\n",
      "392 3551\n",
      "video19 785\n",
      "183 2770\n",
      "video6 5325\n",
      "video65 4572\n",
      "250 2929\n",
      "5-60-1920x1080-2 6214\n",
      "3-25-1920x1080 6189\n",
      "363 3241\n",
      "233 4480\n",
      "52-30-1280x720 1925\n",
      "299 2337\n",
      "135 3592\n",
      "329 5087\n",
      "video37 9187\n",
      "video62 5580\n",
      "423 5266\n",
      "416 6512\n",
      "122 4128\n",
      "21-24-1920x1080 5231\n",
      "369 4439\n",
      "video16 12487\n",
      "223 2798\n",
      "video48 2543\n",
      "134-30-1280x720 3876\n",
      "114-30-1280x720 3663\n",
      "126 6287\n",
      "54-30-1080x1920 6446\n",
      "122-60-1920x1080-5 12066\n",
      "209 2857\n",
      "119-30-848x480 1652\n",
      "146 4851\n",
      "51-30-1280x720 2500\n",
      "339 4633\n",
      "72-30-1280x720 7572\n",
      "23-24-1920x1080 5412\n",
      "49-30-1280x720 848\n",
      "98-30-360x360 6646\n",
      "113-60-1280x720 4023\n",
      "79-30-960x720 2495\n",
      "162 7935\n",
      "303 3951\n",
      "378 3481\n",
      "101-30-1080x1920 5154\n",
      "283 4769\n",
      "118 588\n",
      "video22 10470\n",
      "370 1940\n",
      "131 4778\n",
      "76-30-640x280 1774\n",
      "111-25-1920x1080 772\n",
      "132-30-426x240 993\n",
      "419 6964\n",
      "1-30-1280x720 10356\n",
      "132 5660\n",
      "12-24-1920x1080 5686\n",
      "265 6720\n",
      "367 4170\n",
      "video4 1551\n",
      "103-30-384x480 772\n",
      "video76 4275\n",
      "74-25-1920x1080 5042\n",
      "20-24-1920x1080 5275\n",
      "184 3791\n",
      "231 4208\n",
      "304 2694\n",
      "video96 8047\n",
      "130 4002\n",
      "248 2268\n",
      "380 2376\n",
      "361 4603\n",
      "video69 8623\n",
      "230 3971\n",
      "160 838\n",
      "34-25-1920x1080 7758\n",
      "297 3289\n",
      "259 2394\n",
      "125 4366\n",
      "428 3230\n",
      "262 4754\n",
      "66-25-1080x1920 2914\n",
      "271 2224\n",
      "237 5435\n",
      "video58 304\n",
      "435 1951\n",
      "441 2702\n",
      "362 4913\n",
      "121 4414\n",
      "330 4569\n",
      "327 4157\n",
      "28-30-1280x720-3 277\n",
      "video78 420\n",
      "306 2297\n",
      "88-30-360x480 3723\n",
      "video80 420\n",
      "13-30-1920x1080 7400\n",
      "427 1223\n",
      "139-14-720x480 10014\n",
      "24-30-1920x1080-2 4173\n",
      "86-24-1920x1080 4996\n",
      "video32 2776\n",
      "169 2863\n",
      "287 1273\n",
      "42-30-480x480 1395\n",
      "321 3556\n",
      "412 1474\n",
      "281 7012\n",
      "239 1965\n",
      "127 8124\n",
      "93-24-640x360 2582\n",
      "video59 6703\n",
      "69-25-854x480 18782\n",
      "313 3140\n",
      "136-30-1920x1080 7530\n",
      "33-30-1920x1080 10807\n",
      "68-24-1920x1080 7190\n",
      "279 2213\n",
      "156 4926\n",
      "video95 10856\n",
      "406 3067\n",
      "308 4652\n",
      "188 5987\n",
      "67-24-640x360 3462\n",
      "62-30-654x480 12034\n",
      "122-60-1920x1080-2 7173\n",
      "102 4778\n",
      "420 3151\n",
      "192 3599\n",
      "video47 821\n",
      "337 2807\n",
      "video49 6122\n",
      "433 4311\n",
      "video17 21938\n",
      "448 4158\n",
      "325 3223\n",
      "377 3445\n",
      "249 2622\n",
      "276 1584\n",
      "383 2555\n",
      "163 3938\n",
      "164 7044\n",
      "191 5249\n",
      "193 3984\n",
      "video45_2 1096\n",
      "video18 3784\n",
      "video71 11205\n",
      "430 1835\n",
      "242 7011\n",
      "90-30-1080x1920 7414\n",
      "video70 11869\n",
      "video45_3 295\n",
      "151 965\n",
      "video79 4098\n",
      "238 3013\n",
      "178 5841\n",
      "95-24-1920x1080 2884\n",
      "video40 5877\n",
      "311 1931\n",
      "296 6487\n",
      "150 13016\n",
      "video28 8728\n",
      "122-60-1920x1080-4 7684\n",
      "272 3334\n",
      "350 2016\n",
      "216 458\n",
      "108 4679\n",
      "video57 8380\n",
      "400 2641\n",
      "344 4264\n",
      "280 3946\n",
      "139 8166\n",
      "270 3938\n"
     ]
    }
   ],
   "source": [
    "d=os.path.join(DATA_DIR,'../../videos')\n",
    "video2len={}\n",
    "for filename in os.listdir(d):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    vid=os.path.join(d,filename)\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video2len[fn]=total_frames+1 #FIX ME!!! NEED TO ADD 1 to the number of frames for consistency with challeng's organizer\n",
    "    print(fn,video2len[fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454 27789\n",
      "471 5934\n",
      "479 6080\n",
      "463 22511\n",
      "461 7677\n",
      "453 4946\n",
      "495 2907\n",
      "478 10190\n",
      "499 6564\n",
      "459 3686\n",
      "475 9559\n",
      "483 14632\n",
      "491 10212\n",
      "489 11980\n",
      "493 871\n",
      "465 25064\n",
      "455 779\n",
      "480 4809\n",
      "477 8236\n",
      "497 6328\n",
      "468 10229\n",
      "500 3120\n",
      "469 18249\n",
      "474 7953\n",
      "494 1700\n",
      "496 7233\n",
      "451 9125\n",
      "458 23633\n",
      "481 4701\n",
      "482 6331\n",
      "486 20200\n",
      "498 2200\n",
      "452 11545\n",
      "457 14957\n",
      "467 15186\n",
      "464 14578\n",
      "462 3758\n",
      "473 10352\n",
      "488 6017\n",
      "476 8260\n",
      "470 9102\n",
      "487 11919\n",
      "485 9481\n",
      "456 6303\n",
      "490 7312\n",
      "472 9750\n",
      "460 9766\n",
      "466 22919\n",
      "492 510\n",
      "484 3596\n"
     ]
    }
   ],
   "source": [
    "d=os.path.join(DATA_DIR,'../../new_vids')\n",
    "#video2len={}\n",
    "for filename in os.listdir(d):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    vid=os.path.join(d,filename)\n",
    "    cap = cv2.VideoCapture(vid)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    video2len[fn]=total_frames+1 #FIX ME!!! NEED TO ADD 1 to the number of frames for consistency with challeng's organizer\n",
    "    print(fn,video2len[fn])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454.mp4\n",
      "471.avi\n",
      "479.avi\n",
      "463.avi\n",
      "461.mp4\n",
      "453.avi\n",
      "495.avi\n",
      "478.avi\n",
      "499.avi\n",
      "459.avi\n",
      "475.avi\n",
      "483.mp4\n",
      "491.avi\n",
      "489.avi\n",
      "493.avi\n",
      "465.avi\n",
      "455.avi\n",
      "480.avi\n",
      "477.avi\n",
      "497.mp4\n",
      "468.mp4\n",
      "500.avi\n",
      "469.mp4\n",
      "474.avi\n",
      "494.mp4\n",
      "496.avi\n",
      "451.avi\n",
      "458.avi\n",
      "481.avi\n",
      "482.avi\n",
      "486.avi\n",
      "498.avi\n",
      "452.avi\n",
      "457.avi\n",
      "467.mp4\n",
      "464.avi\n",
      "462.avi\n",
      "473.avi\n",
      "488.avi\n",
      "476.avi\n",
      "470.avi\n",
      "487.avi\n",
      "485.avi\n",
      "456.avi\n",
      "490.avi\n",
      "472.avi\n",
      "460.mp4\n",
      "466.avi\n",
      "492.mp4\n",
      "484.avi\n"
     ]
    }
   ],
   "source": [
    "import wave, struct\n",
    "from fnmatch import fnmatch\n",
    "video_dir=os.path.join(DATA_DIR,'../../new_vids')\n",
    "audio_dir=os.path.join(DATA_DIR,'../../new_vids_audios')\n",
    "for filename in os.listdir(video_dir):\n",
    "    print(filename)\n",
    "    video_path=os.path.join(video_dir,filename)\n",
    "    fn=os.path.splitext(filename)[0]\n",
    "    waveFile = os.path.join(audio_dir, fn+'.wav')\n",
    "    command = \"ffmpeg -i \"+video_path+\" -ac 1 -ar 16000 -vn \"+waveFile\n",
    "    #print(command)\n",
    "    os.system(command=command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/huggingface_hub/file_download.py:795: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HubertModel(\n",
       "  (feature_extractor): HubertFeatureEncoder(\n",
       "    (conv_layers): ModuleList(\n",
       "      (0): HubertLayerNormConvLayer(\n",
       "        (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (1-4): 4 x HubertLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (5-6): 2 x HubertLayerNormConvLayer(\n",
       "        (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "        (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (feature_projection): HubertFeatureProjection(\n",
       "    (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): HubertEncoderStableLayerNorm(\n",
       "    (pos_conv_embed): HubertPositionalConvEmbedding(\n",
       "      (conv): Conv1d(1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16)\n",
       "      (padding): HubertSamePadLayer()\n",
       "      (activation): GELUActivation()\n",
       "    )\n",
       "    (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x HubertEncoderLayerStableLayerNorm(\n",
       "        (attention): HubertAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): HubertFeedForward(\n",
       "          (intermediate_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "          (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2Model,AutoProcessor, HubertModel\n",
    "import torchaudio\n",
    "import torch\n",
    "if False:\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "    model = Wav2Vec2Model.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
    "else:\n",
    "    processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "    model = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-30-1280x720 16000 (17259, 768) 320.0136160843618\n"
     ]
    }
   ],
   "source": [
    "AUDIO_DIR=DATA_DIR+'/../../audios'\n",
    "videoname2audiofeatures={}\n",
    "for filename in sorted(os.listdir(AUDIO_DIR)):\n",
    "    videoname,_=os.path.splitext(filename)\n",
    "    array, fs = torchaudio.load(os.path.join(AUDIO_DIR,filename))\n",
    "    inp = processor(array.squeeze(), sampling_rate=fs, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inp)\n",
    "    videoname2audiofeatures[videoname]=outputs.last_hidden_state.numpy()[0]\n",
    "    print(videoname,fs,videoname2audiofeatures[videoname].shape,inp['input_values'].shape[1]/len(videoname2audiofeatures[videoname]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/548 [02:22<21:35:18, 142.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-30-1280x720 16000 (10356, 1024) (17259, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/548 [02:33<9:52:33, 65.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-60-1280x720 16000 (2502, 1024) (4167, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 3/548 [02:45<6:11:35, 40.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100-29-1080x1920 16000 (2640, 1024) (4401, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 4/548 [03:25<6:07:07, 40.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101-30-1080x1920 16000 (5154, 1024) (8594, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 5/548 [03:40<4:43:38, 31.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102-30-640x360 16000 (2984, 1024) (4978, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 6/548 [04:29<5:36:34, 37.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 16000 (4778, 1024) (9553, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|         | 7/548 [04:30<3:51:06, 25.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103-30-384x480 16000 (772, 1024) (1287, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|         | 8/548 [10:17<19:10:06, 127.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 16000 (26618, 1024) (44359, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 9/548 [10:27<13:38:39, 91.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104-17-720x480 16000 (2426, 1024) (4052, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 10/548 [10:32<9:37:50, 64.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105-30-1280x720 16000 (1502, 1024) (2502, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 11/548 [12:46<12:48:10, 85.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105 16000 (10077, 1024) (16809, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|         | 12/548 [12:51<9:05:01, 61.01s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106-30-720x1280 16000 (1405, 1024) (2342, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|         | 14/548 [15:09<8:45:05, 59.00s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 16000 (8164, 1024) (17023, 1024)\n",
      "107-30-640x480 16000 (74, 1024) (130, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 15/548 [15:51<7:57:11, 53.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 16000 (5316, 1024) (8866, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 16/548 [15:51<5:35:03, 37.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108-15-640x480 16000 (479, 1024) (808, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 17/548 [16:41<6:05:11, 41.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108 16000 (4679, 1024) (9755, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 18/548 [16:43<4:21:53, 29.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109-30-1280x720 16000 (1046, 1024) (1747, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|         | 19/548 [17:27<4:58:58, 33.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11-24-1920x1080 16000 (5390, 1024) (8982, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|         | 20/548 [19:42<9:23:47, 64.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110-30-270x480 16000 (9979, 1024) (16632, 1024)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "AUDIO_DIR=DATA_DIR+'/../../audios'\n",
    "videoname2audiofeatures={}\n",
    "for filename in tqdm(sorted(os.listdir(AUDIO_DIR))):\n",
    "    videoname,_=os.path.splitext(filename)\n",
    "    filepath=os.path.join(AUDIO_DIR,filename)\n",
    "    fs=librosa.get_samplerate(filepath)\n",
    "    stream = librosa.stream(\n",
    "        filepath,\n",
    "        block_length=360,\n",
    "        frame_length=16000,\n",
    "        hop_length=16000\n",
    "    )\n",
    "    total_outputs=None\n",
    "    for speech in stream:\n",
    "        if len(speech.shape) > 1:\n",
    "            speech = speech[:, 0] + speech[:, 1]\n",
    "\n",
    "        inp = processor(speech, sampling_rate=16000, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inp)\n",
    "        outputs=outputs.last_hidden_state.numpy()[0]\n",
    "        if total_outputs is None:\n",
    "            total_outputs=outputs\n",
    "        else:\n",
    "            total_outputs=np.concatenate((total_outputs,outputs),axis=0)\n",
    "    frames_count=video2len[videoname]\n",
    "    audio_scale=len(total_outputs)/frames_count\n",
    "    audio_features=np.zeros((frames_count,total_outputs.shape[1]))\n",
    "    for frame_number in range(frames_count):\n",
    "        ind=int(frame_number*audio_scale)\n",
    "        audio_features[frame_number]=total_outputs[ind]\n",
    "    \n",
    "    videoname2audiofeatures[videoname]=audio_features.astype(np.float16)\n",
    "    print(videoname,fs,videoname2audiofeatures[videoname].shape,total_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'video7'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-7271c7f873db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL2AUDIOFEATURES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mvideoname2audiofeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideoname2audiofeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvideoname2audiofeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'video7'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'video7'"
     ]
    }
   ],
   "source": [
    "#MODEL2AUDIOFEATURES='../abaw6/affwild2_wav2vec2.pickle'\n",
    "MODEL2AUDIOFEATURES='affwild2_hubert.pickle'\n",
    "\n",
    "if False:\n",
    "    with open(MODEL2AUDIOFEATURES, 'wb') as handle:\n",
    "        pickle.dump(videoname2audiofeatures, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(MODEL2AUDIOFEATURES, 'rb') as handle:\n",
    "        videoname2audiofeatures=pickle.load(handle)\n",
    "print(len(videoname2audiofeatures),videoname2audiofeatures['video7'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "AUDIO_DIR=os.path.join(DATA_DIR,'../../new_vids_audios')\n",
    "#videoname2audiofeatures={}\n",
    "for filename in tqdm(sorted(os.listdir(AUDIO_DIR))):\n",
    "    videoname,_=os.path.splitext(filename)\n",
    "    filepath=os.path.join(AUDIO_DIR,filename)\n",
    "    fs=librosa.get_samplerate(filepath)\n",
    "    stream = librosa.stream(\n",
    "        filepath,\n",
    "        block_length=300, #360\n",
    "        frame_length=16000,\n",
    "        hop_length=16000\n",
    "    )\n",
    "    total_outputs=None\n",
    "    for speech in stream:\n",
    "        if len(speech.shape) > 1:\n",
    "            speech = speech[:, 0] + speech[:, 1]\n",
    "\n",
    "        inp = processor(speech, sampling_rate=16000, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inp)\n",
    "        outputs=outputs.last_hidden_state.numpy()[0]\n",
    "        if total_outputs is None:\n",
    "            total_outputs=outputs\n",
    "        else:\n",
    "            total_outputs=np.concatenate((total_outputs,outputs),axis=0)\n",
    "    frames_count=video2len[videoname]\n",
    "    audio_scale=len(total_outputs)/frames_count\n",
    "    audio_features=np.zeros((frames_count,total_outputs.shape[1]))\n",
    "    for frame_number in range(frames_count):\n",
    "        ind=int(frame_number*audio_scale)\n",
    "        audio_features[frame_number]=total_outputs[ind]\n",
    "    \n",
    "    videoname2audiofeatures[videoname]=audio_features\n",
    "    print(videoname,fs,videoname2audiofeatures[videoname].shape,total_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename2audio_features={}\n",
    "for videoname in videoname2audiofeatures:\n",
    "    audio_features=videoname2audiofeatures[videoname]\n",
    "    for i,af in enumerate(audio_features):\n",
    "        imagename=videoname+'/'+get_names(i+1)+'.jpg'\n",
    "        filename2audio_features[imagename]=af\n",
    "print(len(filename2audio_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3091661\n"
     ]
    }
   ],
   "source": [
    "MODEL2AUDIOFEATURES='../abaw6/affwild2_file2wav2vec2.pickle'\n",
    "#MODEL2AUDIOFEATURES='affwild2_file2hubert.pickle'\n",
    "\n",
    "if False:\n",
    "    with open(MODEL2AUDIOFEATURES, 'wb') as handle:\n",
    "        pickle.dump(filename2audio_features, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open(MODEL2AUDIOFEATURES, 'rb') as handle:\n",
    "        filename2audio_features=pickle.load(handle)\n",
    "print(len(filename2audio_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    for filename in filename2audio_features:\n",
    "        filename2audio_features[filename]=filename2audio_features[filename].astype(np.float16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,Sequential, load_model,model_from_json\n",
    "from tensorflow.keras.applications import mobilenet,mobilenet_v2,densenet,inception_resnet_v2,inception_v3,vgg16,resnet_v2,resnet\n",
    "#from tensorflow.keras.applications import efficientnet as enet\n",
    "import efficientnet.tfkeras as enet\n",
    "#from tensorflow.keras.utils.generic_utils import CustomObjectScope\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout,GlobalAveragePooling2D,Activation, Conv2D, Reshape,DepthwiseConv2D,Input\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, Callback, CSVLogger, EarlyStopping\n",
    "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "print(tf.__version__)\n",
    "from tensorflow.compat.v1.keras.backend import set_session \n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess=tf.compat.v1.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "class SaveBestModel(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, save_best_metric='val_loss', this_max=False):\n",
    "        self.save_best_metric = save_best_metric\n",
    "        self.max = this_max\n",
    "        if this_max:\n",
    "            self.best = float('-inf')\n",
    "        else:\n",
    "            self.best = float('inf')\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        metric_value = logs[self.save_best_metric]\n",
    "        if self.max:\n",
    "            if metric_value > self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = deepcopy(self.model.get_weights())\n",
    "\n",
    "        else:\n",
    "            if metric_value < self.best:\n",
    "                self.best = metric_value\n",
    "                self.best_model_weights = deepcopy(self.model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_transfer(label,class_num):\n",
    "    return np.eye(class_num)[label]\n",
    "\n",
    "def metric_for_Exp(gt,pred,class_num=8):\n",
    "    # compute_acc\n",
    "    acc = accuracy_score(gt,pred)\n",
    "    # compute_F1\n",
    "    gt = one_hot_transfer(gt,class_num)\n",
    "    pred = one_hot_transfer(pred,class_num)\n",
    "    F1 = []\n",
    "    for i in range(class_num):\n",
    "        gt_ = gt[:,i]\n",
    "        pred_ = pred[:,i]\n",
    "        F1.append(f1_score(gt_.flatten(), pred_))\n",
    "    F1_mean = np.mean(F1)\n",
    "    return F1_mean,acc,F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCC_score(x, y):\n",
    "    vx = x - np.mean(x)\n",
    "    vy = y - np.mean(y)\n",
    "    rho = np.sum(vx * vy) / (np.sqrt(np.sum(vx**2)) * np.sqrt(np.sum(vy**2)))\n",
    "    x_m = np.mean(x)\n",
    "    y_m = np.mean(y)\n",
    "    x_s = np.std(x)\n",
    "    y_s = np.std(y)\n",
    "    ccc = 2*rho*x_s*y_s/(x_s**2 + y_s**2 + (x_m - y_m)**2)\n",
    "    return ccc\n",
    "\n",
    "def metric_for_VA(gt_V,gt_A,pred_V,pred_A):\n",
    "    ccc_V,ccc_A = CCC_score(gt_V,pred_V),CCC_score(gt_A,pred_A)\n",
    "    return ccc_V,ccc_A, 0.5*(ccc_V+ccc_A)\n",
    "\n",
    "def CCC_numpy(y_true, y_pred):\n",
    "    '''Reference numpy implementation of Lin's Concordance correlation coefficient'''\n",
    "    \n",
    "    # covariance between y_true and y_pred\n",
    "    s_xy = np.cov([y_true, y_pred])[0,1]\n",
    "    # means\n",
    "    x_m = np.mean(y_true)\n",
    "    y_m = np.mean(y_pred)\n",
    "    # variances\n",
    "    s_x_sq = np.var(y_true)\n",
    "    s_y_sq = np.var(y_pred)\n",
    "    \n",
    "    # condordance correlation coefficient\n",
    "    ccc = (2.0*s_xy) / (s_x_sq + s_y_sq + (x_m-y_m)**2)\n",
    "    \n",
    "    return ccc\n",
    "\n",
    "def CCC(y_true, y_pred):\n",
    "    '''Lin's Concordance correlation coefficient: https://en.wikipedia.org/wiki/Concordance_correlation_coefficient\n",
    "    \n",
    "    The concordance correlation coefficient is the correlation between two variables that fall on the 45 degree line through the origin.\n",
    "    \n",
    "    It is a product of\n",
    "    - precision (Pearson correlation coefficient) and\n",
    "    - accuracy (closeness to 45 degree line)\n",
    "\n",
    "    Interpretation:\n",
    "    - `rho_c =  1` : perfect agreement\n",
    "    - `rho_c =  0` : no agreement\n",
    "    - `rho_c = -1` : perfect disagreement \n",
    "    \n",
    "    Args: \n",
    "    - y_true: ground truth\n",
    "    - y_pred: predicted values\n",
    "    \n",
    "    Returns:\n",
    "    - concordance correlation coefficient (float)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # covariance between y_true and y_pred\n",
    "    #N = K.int_shape(y_pred)[-1]\n",
    "    #s_xy = 1.0 / (N - 1.0 + K.epsilon()) * K.sum((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred)))\n",
    "    #s_xy = K.mean(K.sum((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred))))\n",
    "    s_xy = K.mean((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred)))\n",
    "    # means\n",
    "    x_m = K.mean(y_true)\n",
    "    y_m = K.mean(y_pred)\n",
    "    # variances\n",
    "    s_x_sq = K.var(y_true)\n",
    "    s_y_sq = K.var(y_pred)\n",
    "    \n",
    "    # condordance correlation coefficient\n",
    "    ccc = (2.0*s_xy) / (s_x_sq + s_y_sq + (x_m-y_m)**2+K.epsilon())\n",
    "    #print(s_xy,s_x_sq,s_y_sq,x_m,y_m)\n",
    "    return ccc\n",
    "\n",
    "def CCC_VA(y_true, y_pred):\n",
    "    return 1-0.5*(CCC(y_true[:,0], y_pred[:,0])+CCC(y_true[:,1], y_pred[:,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def f1_score_max_for_AU_one_class(gt, pred, thresh,type=0):\n",
    "    gt = gt[:,type]\n",
    "    pred = pred[:,type]\n",
    "    P = []\n",
    "    R = []\n",
    "    ACC = []\n",
    "    F1 = []\n",
    "    for i in thresh:\n",
    "        new_pred = ((pred >= i) * 1).flatten()\n",
    "        P.append(precision_score(gt.flatten(), new_pred))\n",
    "        R.append(recall_score(gt.flatten(), new_pred))\n",
    "        ACC.append(accuracy_score(gt.flatten(), new_pred))\n",
    "        F1.append(f1_score(gt.flatten(), new_pred))\n",
    "\n",
    "    F1_MAX = max(F1)\n",
    "    if F1_MAX < 0 or math.isnan(F1_MAX):\n",
    "        F1_MAX = 0\n",
    "        F1_THRESH = 0\n",
    "        accuracy = 0\n",
    "    else:\n",
    "        idx_thresh = np.argmax(F1)\n",
    "        F1_THRESH = thresh[idx_thresh]\n",
    "        accuracy = ACC[idx_thresh]\n",
    "    return F1,F1_MAX,F1_THRESH,accuracy\n",
    "\n",
    "def f1_score_max(gt, pred, thresh,c=12):\n",
    "    F1_s = []\n",
    "    F1_t = []\n",
    "    ACC = []\n",
    "    from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "    for i in range(c):\n",
    "        F1, F1_MAX, F1_THRESH,acc = f1_score_max_for_AU_one_class(gt,pred,thresh,i)\n",
    "        F1_s.append(F1_MAX)\n",
    "        F1_t.append(F1_THRESH)\n",
    "        ACC.append(acc)\n",
    "    F1_s=np.array(F1_s)\n",
    "    F1_t=np.array(F1_t)\n",
    "    ACC=np.array(ACC)\n",
    "    return F1_s.mean(),F1_t.mean(),F1_s,F1_t,ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AffectNet: {'Angry': 0, 'Contempt': 1, 'Disgust': 2, 'Fear': 3, 'Happy': 4, 'Neutral': 5, 'Sad': 6, 'Surprise': 7}\n",
      "[5 0 2 3 4 6 7 1]\n"
     ]
    }
   ],
   "source": [
    "idx_to_class={0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprise'}\n",
    "class_to_idx={cls:idx for idx,cls in idx_to_class.items()}\n",
    "print('AffectNet:',class_to_idx)\n",
    "\n",
    "#idx_to_class_2={0: 'Neutral', 1:'Angry', 2:'Disgust', 3:'Fear', 4:'Happy', 5:'Sad', 6:'Surprised', 7:'Other'} #ABAW\n",
    "#idx_to_class={0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprised'} #AffectNet\n",
    "AFFECTNET2MTL=np.array([5,0,2,3,4,6,7,1])\n",
    "print(AFFECTNET2MTL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(597357, 768) (597357,) 4\n",
      "(280532, 768) (280532,) 3698\n"
     ]
    }
   ],
   "source": [
    "def get_image2ExprAudio(dirname):\n",
    "    dirpath=os.path.join(DATA_DIR,'EXPR_Recognition_Challenge/',dirname)\n",
    "    num_missed=0\n",
    "    X,y=[],[]\n",
    "    for filename in os.listdir(dirpath):\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        fn_short=fn\n",
    "        if fn.endswith('_left'):\n",
    "            fn_short=fn[:-5]\n",
    "        elif fn.endswith('_right'):\n",
    "            fn_short=fn[:-6]\n",
    "        if ext.lower()=='.txt':\n",
    "            with open(os.path.join(dirpath,filename)) as f:\n",
    "                lines = f.read().splitlines()\n",
    "                for i,line in enumerate(lines):\n",
    "                    if i>0:\n",
    "                        expression=int(line)\n",
    "                        if expression>=0:\n",
    "                            imagename_short=fn_short+'/'+get_names(i)+'.jpg'\n",
    "                            imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                            has_image=imagename_short in filename2audio_features\n",
    "                            if dirname=='Validation_Set':\n",
    "                                has_frame=os.path.exists(os.path.join(DATA_DIR,'cropped',imagename))\n",
    "                                if has_image:\n",
    "                                    has_image=has_frame\n",
    "                                elif has_frame:\n",
    "                                    #print(imagename,imagename in filename2audio_features,imagename in filename2featuresAll)\n",
    "                                    imagename_short=fn_short+'/'+get_names(i-1)+'.jpg'\n",
    "                                    has_image=imagename_short in filename2audio_features\n",
    "                            if has_image:\n",
    "                                X.append(filename2audio_features[imagename_short])\n",
    "                                y.append(expression)\n",
    "                            else:\n",
    "                                num_missed+=1\n",
    "                                #print(imagename)\n",
    "    X=np.array(X).astype(np.float16)\n",
    "    y=np.array(y)\n",
    "    print(X.shape,y.shape,num_missed)\n",
    "    return X,y\n",
    "\n",
    "X_train,y_train=get_image2ExprAudio('Train_Set')\n",
    "X_val,y_val=get_image2ExprAudio('Validation_Set')\n",
    "TRAIN_VAL=False\n",
    "batch_size=256 #128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585317, 1280) (585317,) 12044\n",
      "(280532, 1280) (280532,) 3698\n"
     ]
    }
   ],
   "source": [
    "def get_image2Expr(dirname):\n",
    "    dirpath=os.path.join(DATA_DIR,'EXPR_Recognition_Challenge/',dirname)\n",
    "    num_missed=0\n",
    "    X,y=[],[]\n",
    "    for filename in os.listdir(dirpath):\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        if ext.lower()=='.txt':\n",
    "            with open(os.path.join(dirpath,filename)) as f:\n",
    "                lines = f.read().splitlines()\n",
    "                for i,line in enumerate(lines):\n",
    "                    if i>0:\n",
    "                        expression=int(line)\n",
    "                        if expression>=0:\n",
    "                            imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                            if imagename in filename2featuresAll:\n",
    "                                X.append(filename2featuresAll[imagename][0])\n",
    "                                #X.append(filename2featuresAll[imagename][1])\n",
    "                                y.append(expression)\n",
    "                            else:\n",
    "                                num_missed+=1\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    print(X.shape,y.shape,num_missed)\n",
    "    return X,y\n",
    "\n",
    "X_train,y_train=get_image2Expr('Train_Set')\n",
    "X_val,y_val=get_image2Expr('Validation_Set')\n",
    "TRAIN_VAL=False\n",
    "batch_size=256 #128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(877889, 768) (877889,)\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    TRAIN_VAL=True\n",
    "    X_train=np.concatenate((X_train,X_val))\n",
    "    y_train=np.concatenate((y_train,y_val))\n",
    "    print(X_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_expr(X=X_val,y=y_val):\n",
    "    y_val_preds=mlpModel.predict(X,verbose=0)\n",
    "    y_pred=np.argmax(y_val_preds,axis=1)\n",
    "    print('Acc:',(y_pred==y).mean(), 'F1:',f1_score(y_true=y,y_pred=y_pred, average=\"macro\"))\n",
    "    print(metric_for_Exp(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[259456  22699  16067  17488 129974 103908  43947 272310] {0: 1.0495421188949188, 1: 11.99656372527424, 2: 16.948403560092117, 3: 15.571248856358647, 4: 2.095111329958299, 5: 2.6206836817184436, 6: 6.19632739436139, 7: 1.0} 8 [0 1 2 3 4 5 6 7]\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([ 82258,   6126,   5296,   8408,  34511,  25157,  12332, 106444]))\n"
     ]
    }
   ],
   "source": [
    "(unique, counts) = np.unique(y_train, return_counts=True)\n",
    "num_classes=len(unique)\n",
    "cw=1/counts\n",
    "cw/=cw.min()\n",
    "class_weights = {i:cwi for i,cwi in zip(unique,cw)}\n",
    "print(counts, class_weights, num_classes, unique)\n",
    "print(np.unique(y_val, return_counts=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpModel=Sequential()\n",
    "num_classes=8\n",
    "if False:\n",
    "    mlpModel.add(Dense(num_classes, input_shape=X_val.shape[1:],activation='softmax',use_bias=True,kernel_regularizer=tf.keras.regularizers.l2(1.0/batch_size)))\n",
    "else:\n",
    "    mlpModel.add(Dense(128, input_shape=X_val.shape[1:],activation='relu')) #256\n",
    "    #mlpModel.add(Dense(128, input_shape=(1280,),activation='relu')) #256\n",
    "    mlpModel.add(Dense(num_classes,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45467"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 128)               98432     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 8)                 1032      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 99464 (388.53 KB)\n",
      "Trainable params: 99464 (388.53 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "3430/3430 [==============================] - 22s 6ms/step - loss: 3.9801 - accuracy: 0.3498 - val_loss: 1.4831 - val_accuracy: 0.4485\n",
      "Epoch 2/2\n",
      "3430/3430 [==============================] - 21s 6ms/step - loss: 3.3271 - accuracy: 0.4734 - val_loss: 1.3881 - val_accuracy: 0.5027\n",
      "0.5026805996894836\n"
     ]
    }
   ],
   "source": [
    "mlpModel.compile(optimizer=Adam(learning_rate=1e-3), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "mlpModel.summary()\n",
    "\n",
    "save_best_model = SaveBestModel('val_accuracy',True)\n",
    "mlpModel.fit(X_train,y_train, batch_size=batch_size, epochs=2 if TRAIN_VAL else 10, verbose=1, shuffle=True,\n",
    "             callbacks=[save_best_model], validation_data=(X_val,y_val),class_weight=class_weights)\n",
    "best_model_weights = save_best_model.best_model_weights\n",
    "print(save_best_model.best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    #mlpModel.save_weights('expr_enet0_vgaf_train_val_new.h5')\n",
    "    mlpModel.save_weights('expr_wav2vec_train_val_new.h5')\n",
    "elif True:\n",
    "    mlpModel.load_weights('expr_enet0_vgaf_train_val.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.4474498452939415 F1: 0.3534379977160974\n",
      "(0.3534379977160974, 0.4474498452939415, [0.5050543210026993, 0.13419216317767044, 0.560565275908479, 0.036674410886159976, 0.4447339182406805, 0.4692188778757843, 0.2012156400254014, 0.4758493746119046])\n",
      "Best weights:\n",
      "Acc: 0.4859766443756862 F1: 0.3771706981857585\n",
      "(0.3771706981857585, 0.4859766443756862, [0.571038931925175, 0.17630948305374874, 0.47358237833010863, 0.03297045101088646, 0.4677675659099146, 0.5217275333970527, 0.27579590676520754, 0.49817333509397427])\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    print_expr()\n",
    "    print('Best weights:')\n",
    "    mlpModel.set_weights(best_model_weights)\n",
    "print_expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    #mlpModel.save_weights('expr_enet0_vgaf.h5')#Acc: 0.48984429583790795 F1: 0.3828262567771098\n",
    "    mlpModel.save_weights('expr_wav2vec2.h5')#Acc: 0.410110076568805 F1: 0.29090239611199764\n",
    "else:\n",
    "    #mlpModel.load_weights('../expr_enet0_vgaf.h5') #Acc: 0.500285172458044 F1: 0.3807067519117502\n",
    "    mlpModel.load_weights('../abaw5/expr_enet0_vgaf.h5') #Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
    "    print_expr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.49544793463847264 F1: 0.38445558136937796\n",
      "(0.38445558136937796, 0.49544793463847264, [0.5975372028718637, 0.18703154959037824, 0.5204209286923246, 0.017722567287784676, 0.47926124957534205, 0.48604448320976884, 0.28961248144521995, 0.4980141882823414])\n"
     ]
    }
   ],
   "source": [
    "mlpModel.load_weights('../abaw5/expr_enet0_vgaf.h5')\n",
    "y_val_preds=mlpModel.predict(X_val,verbose=0)\n",
    "y_pred=np.argmax(y_val_preds,axis=1)\n",
    "print('Acc:',(y_pred==y_val).mean(), 'F1:',f1_score(y_true=y_val,y_pred=y_pred, average=\"macro\"))\n",
    "print(metric_for_Exp(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "enet_b0_8_best_vgaf\n",
    "aligned\n",
    "112\n",
    "Acc: 0.36997808749986594 F1: 0.21352704404593095\n",
    "(0.21352704404593095, 0.36997808749986594, [0.45700583162587527, 0.07635619242579324, 0.003076194983435873, 0.009468317552804079, 0.34928095010272137, 0.21187660892709106, 0.1647308567096285, 0.4364214000400981])\n",
    "\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.20843684874655494 F1: 0.0910746772554131\n",
    "\n",
    "\n",
    "224\n",
    "Acc: 0.47395701146384794 F1: 0.3045351324629094\n",
    "(0.3045351324629094, 0.47395701146384794, [0.5518323928131282, 0.11104639875752281, 0.028970239662891757, 0.029782898346265387, 0.42825757737346165, 0.5113845517526626, 0.2515561703388993, 0.5234508306584433])\n",
    "\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.42862351608048643 F1: 0.3395506137533413\n",
    "\n",
    "\n",
    "cropped\n",
    "Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
    "(0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.500285172458044 F1: 0.3807067519117502\n",
    "(0.3807067519117502, 0.500285172458044, [0.608643679809698, 0.15128569174948728, 0.5162256615077384, 0.01599360255897641, 0.4778312968664514, 0.4611138100075078, 0.3029224246739377, 0.5116378481202044])\n",
    "\n",
    "\n",
    "enet_b0_8_va_mtl\n",
    "aligned\n",
    "112\n",
    "Acc: 0.36310406828978836 F1: 0.21416588541497295\n",
    "(0.21416588541497295, 0.36310406828978836, [0.5104795189391993, 0.1258546760922471, 0.010939722131057872, 0.009548019096038193, 0.33523095946425735, 0.18541315145321896, 0.19094959313671342, 0.3449114430070513])\n",
    "\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.17444566379147022 F1: 0.09599142979803564\n",
    "\n",
    "\n",
    "224\n",
    "\n",
    "cropped\n",
    "Acc: 0.44668344431294826 F1: 0.3355545672821115\n",
    "(0.3355545672821115, 0.44668344431294826, [0.510145234564414, 0.16641097373883224, 0.3162162162162162, 0.0352055352055352, 0.5013185136754931, 0.4799950349621416, 0.2053190850693402, 0.4698259448249195])\n",
    "../expr_enet0_vgaf.h5\n",
    "Acc: 0.4230711647869049 F1: 0.30920724751192785\n",
    "\n",
    "\n",
    "mobilevit\n",
    "cropped\n",
    "224\n",
    "Acc: 0.46147320091825533 F1: 0.3560574896064487\n",
    "(0.3560574896064487, 0.46147320091825533, [0.5428998117005389, 0.15102462545204065, 0.44947762979503947, 0.12488323632966876, 0.47030709895410744, 0.40287070773986966, 0.20392039203920392, 0.5030764148411208])\n",
    "\n",
    "mbf_va\n",
    "cropped\n",
    "112\n",
    "Acc: 0.46184392511371253 F1: 0.32738624577811665\n",
    "(0.32738624577811665, 0.46184392511371253, [0.5275200664106117, 0.13163163163163163, 0.4120108948382383, 0.02459419576979833, 0.47229383600629454, 0.3058296783625731, 0.21955208437635595, 0.5256575788294297])\n",
    "\n",
    "aligned\n",
    "Acc: 0.41698808574829577 F1: 0.2605325777277917\n",
    "(0.2605325777277917, 0.41698808574829577, [0.5104076268095435, 0.08551319648093843, 0.03246321784527765, 0.04267053701015965, 0.4294620130290349, 0.2965347390252333, 0.2095684295882512, 0.47764086203389466])\n",
    "\n",
    "\n",
    "enet_b2_best\n",
    "Acc: 0.4377147705074644 F1: 0.32046977297192947\n",
    "(0.32046977297192947, 0.4377147705074644, [0.5279750265857089, 0.18667230205691746, 0.32060923369823896, 0.022576492722051686, 0.457802371541502, 0.3702839197046216, 0.23979880986115049, 0.438040027605245])\n",
    "\n",
    "\n",
    "ddamfnet_8\n",
    "Acc: 0.43266721800008556 F1: 0.30837374615523644\n",
    "(0.30837374615523644, 0.43266721800008556, [0.5215368741365138, 0.1129685025514693, 0.3387109850020268, 0.05675889328063242, 0.4707923787344315, 0.29412395223701415, 0.21788596803993387, 0.4542124152598697])\n",
    "\n",
    "ddamfnet_8_mtl\n",
    "Acc: 0.4619865113427345 F1: 0.33872014801701744\n",
    "(0.33872014801701744, 0.4619865113427345, [0.5691907822979275, 0.1422720413882302, 0.2694043321299639, 0.06790817145609246, 0.5095350810593541, 0.4453414505029116, 0.25683655334518146, 0.449272771956478])\n",
    "\n",
    "Acc: 0.46895184863045924 F1: 0.351079601079747\n",
    "(0.351079601079747, 0.46895184863045924, [0.5672248538336185, 0.0777629408530359, 0.43501871284949, 0.08656489442592268, 0.4938491272202964, 0.41942100601370563, 0.256280299691494, 0.4725149737504132])\n",
    "\n",
    "\n",
    "wav2vec2\n",
    "Acc: 0.410110076568805 F1: 0.29090239611199764\n",
    "(0.29090239611199764, 0.410110076568805, [0.4758486812936623, 0.047472429043273805, 0.5612936880542514, 0.15109275511960077, 0.13438885152032565, 0.3119477387658142, 0.10830172777075431, 0.5368732973282989])\n",
    "\n",
    "hubert:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.4101172058802561 F1: 0.2908597184585734\n"
     ]
    }
   ],
   "source": [
    "mlpModel.load_weights('../abaw6/expr_wav2vec2.h5')\n",
    "y_val_expr_preds_audio=mlpModel.predict(X_val,verbose=0)\n",
    "#y_val_expr_preds_audio=y_val_preds\n",
    "\n",
    "y_pred=np.argmax(y_val_expr_preds_audio,axis=1)\n",
    "print('Acc:',(y_pred==y_val).mean(), 'F1:',f1_score(y_true=y_val,y_pred=y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280532, 8)\n",
      "Acc: 0.410110076568805 F1: 0.29090239611199764\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    with open('y_val_expr_preds_audio.pickle', 'wb') as handle:\n",
    "        pickle.dump(y_val_expr_preds_audio, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('y_val_expr_preds_audio.pickle', 'rb') as handle:\n",
    "        y_val_expr_preds_audio=pickle.load(handle)\n",
    "print(y_val_expr_preds_audio.shape)\n",
    "y_pred=np.argmax(y_val_expr_preds_audio,axis=1)\n",
    "print('Acc:',(y_pred==y_val).mean(), 'F1:',f1_score(y_true=y_val,y_pred=y_pred, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Acc: 0.410110076568805 F1: 0.29090239611199764\n",
      "0.1\n",
      "Acc: 0.43592887798896385 F1: 0.3141889443420316\n",
      "0.2\n",
      "Acc: 0.46409678753226014 F1: 0.3439200559542131\n",
      "0.30000000000000004\n",
      "Acc: 0.4903932528196427 F1: 0.3723581978456718\n",
      "0.4\n",
      "Acc: 0.5081238503985285 F1: 0.3910699591929091\n",
      "0.5\n",
      "Acc: 0.5203149729799096 F1: 0.4030154928467773\n",
      "0.6000000000000001\n",
      "Acc: 0.5178197139720245 F1: 0.4033380362792486\n",
      "0.7000000000000001\n",
      "Acc: 0.5115958250752143 F1: 0.3989305928956265\n",
      "0.8\n",
      "Acc: 0.5050725050974577 F1: 0.39334207090252027\n",
      "0.9\n",
      "Acc: 0.49983959049235027 F1: 0.3883340065997216\n",
      "1.0\n",
      "Acc: 0.49544436998274705 F1: 0.3844313672414089\n"
     ]
    }
   ],
   "source": [
    "for w in np.linspace(0,1,11):\n",
    "    print(w)\n",
    "    y_ensemble=w*y_val_preds+(1-w)*y_val_expr_preds_audio\n",
    "    y_pred=np.argmax(y_ensemble,axis=1)\n",
    "    print('Acc:',(y_pred==y_val).mean(), 'F1:',f1_score(y_true=y_val,y_pred=y_pred, average=\"macro\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280532, 8) (280532,) 3698\n",
      "w/o Other (0.38315520007157966, 0.5219142043104636, [0.5941131445271728, 0.11673050704408232, 0.2563962686160057, 0.1146315414738341, 0.6221359518916038, 0.574566439059762, 0.40351254788859714])\n",
      "with Other: (0.2574340560684253, 0.32562417121754383, [0.47261988187005705, 0.08159349444926674, 0.16895322458679918, 0.08013937282229966, 0.462785267165087, 0.4738317407716553, 0.28230688149375094, 0.037242585388486384])\n"
     ]
    }
   ],
   "source": [
    "dirpath=os.path.join(DATA_DIR,'EXPR_Recognition_Challenge/Validation_Set')\n",
    "num_missed=0\n",
    "y_scores_all,y_val=[],[]\n",
    "\n",
    "for filename in os.listdir(dirpath):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    expression=int(line)\n",
    "                    #if expression>=0:\n",
    "                    if expression>=0:\n",
    "                        imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                        if imagename in filename2featuresAll:\n",
    "                            scores=filename2featuresAll[imagename][1]\n",
    "                            if False:\n",
    "                                scores=scores[:-2]\n",
    "                            y_scores_all.append(scores[AFFECTNET2MTL])\n",
    "                            y_val.append(expression)\n",
    "                        else:\n",
    "                            num_missed+=1\n",
    "y_scores_all=np.array(y_scores_all)\n",
    "y_val=np.array(y_val)\n",
    "print(y_scores_all.shape,y_val.shape,num_missed)\n",
    "\n",
    "y_scores=np.argmax(y_scores_all[y_val!=7,:7],axis=1)\n",
    "print('w/o Other',metric_for_Exp(y_val[y_val!=7],y_scores,7))\n",
    "y_scores=np.argmax(y_scores_all,axis=1)\n",
    "print('with Other:',metric_for_Exp(y_val,y_scores,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embeddings:\n",
    "Acc: 0.4961929476851126 F1: 0.3822393283107972\n",
    "(0.3822393283107972, 0.4961929476851126, [0.5816358825689002, 0.19165239340124404, 0.4775824331003319, 0.06514293702383449, 0.4966704252920027, 0.4404618154856478, 0.27396940324652574, 0.5307993363678905])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
      "(0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809])\n"
     ]
    }
   ],
   "source": [
    "#y_val_preds=mlpModel.predict(X_val,verbose=0)\n",
    "y_pred=np.argmax(y_val_preds,axis=1)\n",
    "print('Acc:',(y_pred==y_val).mean(), 'F1:',f1_score(y_true=y_val,y_pred=y_pred, average=\"macro\"))\n",
    "print(metric_for_Exp(y_val,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores2probabs(x):\n",
    "    e_x = np.exp(x - np.max(x))#[np.newaxis])\n",
    "    e_x = e_x / e_x.sum(axis=1)[:,None]\n",
    "    return e_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.24244377e-01 3.35698426e-02 3.62046719e-01 ... 3.47988039e-01\n",
      "  1.85106192e-02 2.83648036e-02]\n",
      " [1.08953334e-01 3.82212065e-02 3.71574074e-01 ... 3.60739708e-01\n",
      "  1.69553831e-02 2.36208811e-02]\n",
      " [1.04377650e-01 3.58219035e-02 3.63524914e-01 ... 3.76680374e-01\n",
      "  1.79313309e-02 2.13590246e-02]\n",
      " ...\n",
      " [9.49333087e-02 1.18450960e-02 1.37146823e-02 ... 8.56873155e-01\n",
      "  1.38443382e-03 2.01118737e-03]\n",
      " [5.32542281e-02 9.44525655e-03 1.81043278e-02 ... 9.00745928e-01\n",
      "  5.90948097e-04 8.60838452e-04]\n",
      " [1.20561913e-01 1.66836120e-02 1.92864668e-02 ... 8.15231144e-01\n",
      "  1.07049837e-03 1.43829477e-03]]\n"
     ]
    }
   ],
   "source": [
    "y_probabs_all=scores2probabs(y_scores_all)\n",
    "print(y_probabs_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 (0.25318654349366876, 0.32388105456774985, [0.4769210717411138, 0.07942046910199213, 0.16737295680353265, 0.08012607830126078, 0.4677859391395593, 0.47200883604909466, 0.2818569968127969, 0.0]) 280532\n",
      "0.1 (0.25326521499390486, 0.32394521837080975, [0.4769440824179234, 0.07981262153084674, 0.16737295680353265, 0.08012607830126078, 0.4679755022608895, 0.47201469383702754, 0.2818569968127969, 1.878798696113705e-05]) 280462\n",
      "0.2 (0.2537128102109227, 0.32443001154948453, [0.47691840013896725, 0.08047557783594339, 0.1676061362825544, 0.08006305484111839, 0.46909122173501844, 0.4717336839233002, 0.2819764819103185, 0.0018379250201609125]) 279373\n",
      "0.30000000000000004 (0.2646285128636536, 0.33743387563629107, [0.4819260656917997, 0.08364286696932177, 0.17715617715617715, 0.08296426222319667, 0.4743061909118633, 0.4758355916892502, 0.28597466508703184, 0.05522228318058766]) 266226\n",
      "0.4 (0.29731775443903014, 0.37889438638016343, [0.5108383904282426, 0.09784817381336945, 0.21327354260089687, 0.08629012192087585, 0.48754064904969435, 0.49103652961986405, 0.3047786831094473, 0.18693594496985036]) 223246\n",
      "0.5 (0.3341138859172802, 0.42675345415139804, [0.5464613673322574, 0.12323832395879418, 0.28484647669538327, 0.08073209072535369, 0.5013775162470121, 0.5113284671532846, 0.3148566009352824, 0.31007024429087393]) 169355\n",
      "0.6000000000000001 (0.3646250954387064, 0.4615088474755108, [0.5702171044740314, 0.15332711219582226, 0.3742264752791069, 0.07628607277289837, 0.5105847992804851, 0.5296257376121575, 0.3141029911398308, 0.38863047075531926]) 123940\n",
      "0.7000000000000001 (0.38344287894300466, 0.48343860949909456, [0.5841198600752426, 0.16571905086801608, 0.45384942577626547, 0.0608154803040774, 0.516523150003421, 0.5414029676115514, 0.306828003457217, 0.4382850934482464]) 88085\n",
      "0.8 (0.39420142699710226, 0.49767940912266695, [0.5925241322653523, 0.17099309359371276, 0.504965392717424, 0.052925211097708084, 0.5180873590387551, 0.5430461022308776, 0.29710239937065686, 0.4739677256623313]) 57725\n",
      "0.9 (0.39514172618166177, 0.5024489184834529, [0.5972222222222223, 0.17946127946127946, 0.5282507156847973, 0.039237758301841286, 0.5129298377820966, 0.5196103132611068, 0.29170937980522804, 0.49271230293472223]) 32438\n",
      "1.0 (0.3844313672414089, 0.49544436998274705, [0.5975792617828053, 0.18688981868898186, 0.5203826342899192, 0.01771963235902956, 0.4792554615273745, 0.4860550818814191, 0.289585043895661, 0.4979840035060809]) 0\n"
     ]
    }
   ],
   "source": [
    "#y_scores=np.argmax(y_scores_all[y_val!=7,:7],axis=1)\n",
    "y_pred_scores=np.argmax(y_probabs_all[:,:7],axis=1)\n",
    "\n",
    "for t in np.linspace(0,1,11):\n",
    "    y_pred_all=np.argmax(y_val_preds,axis=1)\n",
    "    criterion=np.array([y_p[y_s]>t for y_p,y_s in zip(y_probabs_all,y_pred_scores)])\n",
    "    #criterion=y_pred_all!=7\n",
    "    y_pred_all[criterion]=y_pred_scores[criterion]\n",
    "    print(t,metric_for_Exp(y_val,y_pred_all,8),criterion.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smooth validation predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    mlpModel=Sequential()\n",
    "    mlpModel.add(Dense(128, input_shape=(1280,),activation='relu')) #256\n",
    "    mlpModel.add(Dense(8,activation='softmax'))\n",
    "    mlpModel.load_weights('../ABAW5/expr_enet0_vgaf.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 70/70 [00:41<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir=os.path.join(DATA_DIR,'faces')\n",
    "dirpath=os.path.join(DATA_DIR,'EXPR_Recognition_Challenge/Validation_Set')\n",
    "test_videos={}\n",
    "for filename in tqdm(os.listdir(dirpath)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,expressions,scores=[],[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                    if imagename in filename2featuresAll:\n",
    "                        X.append(filename2featuresAll[imagename][0])\n",
    "                        indices.append(i)\n",
    "                        expressions.append(int(line))\n",
    "                        scores.append(filename2featuresAll[imagename][1][AFFECTNET2MTL])\n",
    "        test_videos[fn]=(mlpModel.predict(np.array(X),verbose=0),indices,np.array(expressions),np.array(scores))\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean 0 Acc: 0.4377147705074644 F1: 0.32046977297192947\n",
      "mean 2 Acc: 0.4502053241697917 F1: 0.3308365959569308\n",
      "median 2 Acc: 0.4485655825360387 F1: 0.3292047135773658\n",
      "mean 7 Acc: 0.46036815764333483 F1: 0.33783569428081117\n",
      "median 7 Acc: 0.4585787004691087 F1: 0.3357647927368673\n"
     ]
    }
   ],
   "source": [
    "hyperparams=[(isMean,delta) for delta in [0,2,7]  for isMean in [1,0] if not (isMean==0 and delta==0)]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(hyperparams))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    for hInd,(isMean,delta) in enumerate(hyperparams):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            if isMean:\n",
    "                proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            else:\n",
    "                proba=np.median(preds_proba[i1:i+delta+1],axis=0)\n",
    "            preds.append(np.argmax(proba))\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,(isMean,delta) in enumerate(hyperparams):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print('mean' if isMean else 'median',delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
      "5 Acc: 0.5147327221136982 F1: 0.4004462320756203\n",
      "15 Acc: 0.5290448148517816 F1: 0.41233892932451965\n",
      "25 Acc: 0.5351189882081189 F1: 0.41821548069619524\n",
      "50 Acc: 0.5424194031340454 F1: 0.4236679637523476\n",
      "100 Acc: 0.5408010494346456 F1: 0.41968206198832886\n",
      "200 Acc: 0.539617583733763 F1: 0.4195667528908445\n",
      "500 Acc: 0.530777237534399 F1: 0.4032242437980253\n"
     ]
    }
   ],
   "source": [
    "#deltas=[0,1,5,7,15]\n",
    "deltas=[0,5,15,25,50,100,200,500]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "            else:\n",
    "                w=1-(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            preds.append(np.argmax(proba))\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print(delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0 Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
    "5 Acc: 0.5147255928022472 F1: 0.40041647458913604\n",
    "15 Acc: 0.5290234269174283 F1: 0.41233375265784433\n",
    "25 Acc: 0.5352187985684342 F1: 0.41830667436931435\n",
    "50 Acc: 0.542572683330244 F1: 0.4236698679610459\n",
    "100 Acc: 0.5408224373689989 F1: 0.4197549134058517\n",
    "200 Acc: 0.5397387820284317 F1: 0.41970605922798776\n",
    "500 Acc: 0.5307736728786734 F1: 0.4031952312654022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Acc: 0.49767940912266695 F1: 0.39420142699710226\n",
      "5 Acc: 0.5209886929120385 F1: 0.41445194418026476\n",
      "15 Acc: 0.5361776909586072 F1: 0.4275109020140136\n",
      "25 Acc: 0.5422768169050233 F1: 0.4330901402834371\n",
      "50 Acc: 0.5462549726947371 F1: 0.4343184315522313\n",
      "100 Acc: 0.5418383642507807 F1: 0.4260578994232742\n",
      "200 Acc: 0.5382202386893474 F1: 0.41917871154835207\n",
      "500 Acc: 0.5281180043631386 F1: 0.40132874798491425\n"
     ]
    }
   ],
   "source": [
    "deltas=[0,5,15,25,50,100,200,500]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "\n",
    "    pretrained_scores_probabs=scores2probabs(scores)\n",
    "    cur_ind=0\n",
    "    preds_proba,pretrained_preds_proba=[],[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "                pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "            else:\n",
    "                w=1-(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "                \n",
    "                s=w*pretrained_scores_probabs[cur_ind-1]+(1-w)*pretrained_scores_probabs[cur_ind]\n",
    "                pretrained_preds_proba.append(s)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    pretrained_preds_proba=np.array(pretrained_preds_proba)\n",
    "    \n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            pred=np.argmax(proba)\n",
    "            \n",
    "            pretrained_proba=np.mean(pretrained_preds_proba[i1:i+delta+1],axis=0)\n",
    "            pretrained_pred=np.argmax(pretrained_proba[:7])\n",
    "            if pretrained_proba[pretrained_pred]>0.8:\n",
    "                pred=pretrained_pred\n",
    "            \n",
    "            preds.append(pred)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print(delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 Acc: 0.3547901843639941 F1: 0.2768972468723374\n",
      "0.1 Acc: 0.3547901843639941 F1: 0.2768972468723374\n",
      "0.2 Acc: 0.3553961758373376 F1: 0.2774307894069533\n",
      "0.30000000000000004 Acc: 0.3920693539417963 F1: 0.3091697700675562\n",
      "0.4 Acc: 0.4600009981036032 F1: 0.3626075313169596\n",
      "0.5 Acc: 0.5122374631058132 F1: 0.4070930183009853\n",
      "0.6000000000000001 Acc: 0.5351902813226299 F1: 0.43217040242047583\n",
      "0.7000000000000001 Acc: 0.5428828083783668 F1: 0.43835013947562684\n",
      "0.8 Acc: 0.546247843383286 F1: 0.43428887590742027\n",
      "0.9 Acc: 0.5458165200404945 F1: 0.4282005950922094\n",
      "1.0 Acc: 0.5424158384783198 F1: 0.42366109129065965\n"
     ]
    }
   ],
   "source": [
    "thresholds=np.linspace(0,1,11)\n",
    "\n",
    "delta=50\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(thresholds))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "\n",
    "    pretrained_scores_probabs=scores2probabs(scores)\n",
    "    cur_ind=0\n",
    "    preds_proba,pretrained_preds_proba=[],[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "                pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "            else:\n",
    "                w=1-(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "                \n",
    "                s=w*pretrained_scores_probabs[cur_ind-1]+(1-w)*pretrained_scores_probabs[cur_ind]\n",
    "                pretrained_preds_proba.append(s)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    pretrained_preds_proba=np.array(pretrained_preds_proba)\n",
    "    \n",
    "    for hInd,t in enumerate(thresholds):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            pred=np.argmax(proba)\n",
    "            \n",
    "            pretrained_proba=np.mean(pretrained_preds_proba[i1:i+delta+1],axis=0)\n",
    "            pretrained_pred=np.argmax(pretrained_proba[:7])\n",
    "            if pretrained_proba[pretrained_pred]>t:\n",
    "                pred=pretrained_pred\n",
    "            \n",
    "            preds.append(pred)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,t in enumerate(thresholds):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print(t,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    mlpModelAudio=mlpModel\n",
    "else:\n",
    "    mlpModelAudio=Sequential()\n",
    "    mlpModelAudio.add(Dense(128, input_shape=(768,),activation='relu')) #256\n",
    "    mlpModelAudio.add(Dense(8,activation='softmax'))\n",
    "    mlpModelAudio.load_weights('../abaw6/expr_wav2vec2.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 70/70 [00:39<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir=os.path.join(DATA_DIR,'faces')\n",
    "dirpath=os.path.join(DATA_DIR,'EXPR_Recognition_Challenge/Validation_Set')\n",
    "test_audios={}\n",
    "for filename in tqdm(os.listdir(dirpath)):\n",
    "    fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "    fn_short=fn\n",
    "    if fn.endswith('_left'):\n",
    "        fn_short=fn[:-5]\n",
    "    elif fn.endswith('_right'):\n",
    "        fn_short=fn[:-6]\n",
    "    if ext.lower()=='.txt':\n",
    "        X,indices,expressions,scores=[],[],[],[]\n",
    "        with open(os.path.join(dirpath,filename)) as f:\n",
    "            lines = f.read().splitlines()\n",
    "            prev_val=None\n",
    "            for i,line in enumerate(lines):\n",
    "                if i>0:\n",
    "                    imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                    imagename_short=fn_short+'/'+get_names(i)+'.jpg'\n",
    "                    imagename=fn+'/'+get_names(i)+'.jpg'\n",
    "                    has_image=imagename_short in filename2audio_features\n",
    "                    has_frame=os.path.exists(os.path.join(DATA_DIR,'cropped',imagename))\n",
    "                    if has_image:\n",
    "                        has_image=has_frame\n",
    "                    elif has_frame:\n",
    "                        #print(imagename,imagename in filename2audio_features,imagename in filename2featuresAll)\n",
    "                        imagename_short=fn_short+'/'+get_names(i-1)+'.jpg'\n",
    "                        has_image=imagename_short in filename2audio_features\n",
    "                    if has_image:\n",
    "                        X.append(filename2audio_features[imagename_short])\n",
    "                        indices.append(i)\n",
    "                        expressions.append(int(line))\n",
    "                        scores.append(filename2featuresAll[imagename][1][AFFECTNET2MTL])\n",
    "        test_audios[fn]=(mlpModelAudio.predict(np.array(X),verbose=0),indices,np.array(expressions),np.array(scores))\n",
    "print(len(test_audios))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Acc: 0.410110076568805 F1: 0.29090239611199764\n",
      "5 Acc: 0.4806474840659889 F1: 0.33263223831368627\n",
      "15 Acc: 0.5046732636561961 F1: 0.34164236744431886\n",
      "25 Acc: 0.513214178774614 F1: 0.3457739134483474\n",
      "50 Acc: 0.5193703392126389 F1: 0.3521084905477545\n",
      "100 Acc: 0.5205038997333638 F1: 0.35453723394331516\n",
      "200 Acc: 0.5206037100936791 F1: 0.3551542666808812\n",
      "500 Acc: 0.5236229734932201 F1: 0.3595042852144297\n"
     ]
    }
   ],
   "source": [
    "#deltas=[0,1,5,7,15]\n",
    "deltas=[0,5,15,25,50,100,200,500]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_audios.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "            else:\n",
    "                w=1-(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            preds.append(np.argmax(proba))\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print(delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0 Acc: 0.410110076568805 F1: 0.29090239611199764\n",
      "5 Acc: 0.4806474840659889 F1: 0.33263223831368627\n",
      "15 Acc: 0.5046732636561961 F1: 0.34164236744431886\n",
      "25 Acc: 0.513214178774614 F1: 0.3457739134483474\n",
      "50 Acc: 0.5193703392126389 F1: 0.3521084905477545\n",
      "100 Acc: 0.5205038997333638 F1: 0.35453723394331516\n",
      "200 Acc: 0.5206037100936791 F1: 0.3551542666808812\n",
      "500 Acc: 0.5236229734932201 F1: 0.3595042852144297\n",
      "\n",
      "0.1\n",
      "0 Acc: 0.43592887798896385 F1: 0.3141889443420316\n",
      "5 Acc: 0.5027733021544779 F1: 0.3563857812809881\n",
      "15 Acc: 0.522806667332069 F1: 0.36445956300269716\n",
      "25 Acc: 0.531885845465045 F1: 0.3692206390706086\n",
      "50 Acc: 0.5371579712831335 F1: 0.374503014447069\n",
      "100 Acc: 0.5369440919396005 F1: 0.3757623082995216\n",
      "200 Acc: 0.5277651034463091 F1: 0.36969726350868176\n",
      "500 Acc: 0.5231132277244663 F1: 0.3658137189900791\n",
      "\n",
      "0.2\n",
      "0 Acc: 0.46409678753226014 F1: 0.3439200559542131\n",
      "5 Acc: 0.5192241883278913 F1: 0.3826124760034294\n",
      "15 Acc: 0.5344630915546177 F1: 0.3892371889323604\n",
      "25 Acc: 0.5388476180970442 F1: 0.3890356128085686\n",
      "50 Acc: 0.5388226655069653 F1: 0.3889338672833958\n",
      "100 Acc: 0.537557212724395 F1: 0.38260401241599074\n",
      "200 Acc: 0.5342741648011635 F1: 0.3819239886457537\n",
      "500 Acc: 0.5273729913164986 F1: 0.37798223509612416\n",
      "\n",
      "0.30000000000000004\n",
      "0 Acc: 0.4903932528196427 F1: 0.3723581978456718\n",
      "5 Acc: 0.5303245262572541 F1: 0.39906339256970785\n",
      "15 Acc: 0.539728088061255 F1: 0.40111597087058626\n",
      "25 Acc: 0.5424015798554176 F1: 0.40209350691942997\n",
      "50 Acc: 0.5442658947998802 F1: 0.4010813676852769\n",
      "100 Acc: 0.5391292258993626 F1: 0.39479008191025045\n",
      "200 Acc: 0.5287917242952676 F1: 0.3850989853168463\n",
      "500 Acc: 0.5293050347197468 F1: 0.3812094521737948\n",
      "\n",
      "0.4\n",
      "0 Acc: 0.5081238503985285 F1: 0.3910699591929091\n",
      "5 Acc: 0.5360707512868407 F1: 0.409764149233344\n",
      "15 Acc: 0.5449075328304792 F1: 0.41451451451244126\n",
      "25 Acc: 0.5476950936078594 F1: 0.41671201483863657\n",
      "50 Acc: 0.5496734775355396 F1: 0.41870347533879104\n",
      "100 Acc: 0.542825773886758 F1: 0.41029885566325486\n",
      "200 Acc: 0.5335505396888769 F1: 0.3920856150725254\n",
      "500 Acc: 0.5238796287054597 F1: 0.38740144117892644\n",
      "\n",
      "0.5\n",
      "0 Acc: 0.5203149729799096 F1: 0.4030154928467773\n",
      "5 Acc: 0.5410184934339042 F1: 0.41841457901092405\n",
      "15 Acc: 0.5519192106426362 F1: 0.4261400174235115\n",
      "25 Acc: 0.5565283104957723 F1: 0.42927113978669706\n",
      "50 Acc: 0.5566744613805199 F1: 0.42744238920986\n",
      "100 Acc: 0.5596937247800607 F1: 0.42587833100755634\n",
      "200 Acc: 0.5523683572640554 F1: 0.4176653231341543\n",
      "500 Acc: 0.5374110618396475 F1: 0.3934275264502991\n",
      "\n",
      "0.6000000000000001\n",
      "0 Acc: 0.5178197139720245 F1: 0.4033380362792486\n",
      "5 Acc: 0.5386515620321389 F1: 0.4194348500409003\n",
      "15 Acc: 0.5522293356907589 F1: 0.4288105701561039\n",
      "25 Acc: 0.5562787845949838 F1: 0.43206046228355444\n",
      "50 Acc: 0.5597008540915118 F1: 0.43420116624657257\n",
      "100 Acc: 0.5616828026749177 F1: 0.43272013152378835\n",
      "200 Acc: 0.5566459441347155 F1: 0.42441301318703506\n",
      "500 Acc: 0.5411753382858283 F1: 0.395676995267757\n",
      "\n",
      "0.7000000000000001\n",
      "0 Acc: 0.5115958250752143 F1: 0.3989305928956265\n",
      "5 Acc: 0.5326237292002338 F1: 0.41589592974786316\n",
      "15 Acc: 0.5472352530192633 F1: 0.4261846824269405\n",
      "25 Acc: 0.5517623657907119 F1: 0.42894420904279734\n",
      "50 Acc: 0.5567421898393053 F1: 0.4342519419312401\n",
      "100 Acc: 0.5588738539631842 F1: 0.43234887602293315\n",
      "200 Acc: 0.5550561076811201 F1: 0.42779433051120586\n",
      "500 Acc: 0.5402485277971854 F1: 0.4030461477136221\n",
      "\n",
      "0.8\n",
      "0 Acc: 0.5050725050974577 F1: 0.39334207090252027\n",
      "5 Acc: 0.5265139092866411 F1: 0.4110254267178063\n",
      "15 Acc: 0.54157457972709 F1: 0.42255745133330447\n",
      "25 Acc: 0.5463583477107781 F1: 0.42660042224292605\n",
      "50 Acc: 0.5530064306389288 F1: 0.4321363986189741\n",
      "100 Acc: 0.5521117020518158 F1: 0.42795455722963094\n",
      "200 Acc: 0.5500655896653501 F1: 0.42537496071268277\n",
      "500 Acc: 0.5408580839262545 F1: 0.41197470732788216\n",
      "\n",
      "0.9\n",
      "0 Acc: 0.49983959049235027 F1: 0.3883340065997216\n",
      "5 Acc: 0.5202864557341051 F1: 0.4053792003855108\n",
      "15 Acc: 0.5352508804699642 F1: 0.41721602274565783\n",
      "25 Acc: 0.5403340795345986 F1: 0.4222736144951802\n",
      "50 Acc: 0.5478305505254303 F1: 0.4284203007293773\n",
      "100 Acc: 0.546247843383286 F1: 0.42403027308344277\n",
      "200 Acc: 0.5434103774257483 F1: 0.42025066297892066\n",
      "500 Acc: 0.5361028331883707 F1: 0.4044914963721008\n",
      "\n",
      "1.0\n",
      "0 Acc: 0.49544436998274705 F1: 0.3844313672414089\n",
      "5 Acc: 0.5147327221136982 F1: 0.4004462320756203\n",
      "15 Acc: 0.5290448148517816 F1: 0.41233892932451965\n",
      "25 Acc: 0.5351189882081189 F1: 0.41821548069619524\n",
      "50 Acc: 0.5424194031340454 F1: 0.4236679637523476\n",
      "100 Acc: 0.5408010494346456 F1: 0.41968206198832886\n",
      "200 Acc: 0.539617583733763 F1: 0.4195667528908445\n",
      "500 Acc: 0.530777237534399 F1: 0.4032242437980253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ensemble\n",
    "deltas=[0,5,15,25,50,100,200,500]\n",
    "for weight in np.linspace(0,1,11):\n",
    "    total_true=[]\n",
    "    total_preds=[[] for _ in range(len(deltas))]\n",
    "    for videoname,(y_pred_expr,indices,expressions,_) in test_videos.items():\n",
    "        y_pred_expr_audio,_,_,_=test_audios[videoname]\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_true.append(expressions[i])\n",
    "        cur_ind=0\n",
    "        preds_proba=[]\n",
    "        y_ensemble=weight*y_pred_expr + (1-weight)*y_pred_expr_audio\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                cur_pred=y_ensemble[cur_ind]\n",
    "                preds_proba.append(cur_pred)\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds_proba.append(y_ensemble[cur_ind])\n",
    "                else:\n",
    "                    w=1-(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_ensemble[cur_ind-1]+(1-w)*y_ensemble[cur_ind]\n",
    "                    preds_proba.append(pred)\n",
    "\n",
    "        preds_proba=np.array(preds_proba)\n",
    "        for hInd,delta in enumerate(deltas):\n",
    "            preds=[]\n",
    "            for i in range(len(preds_proba)):\n",
    "                i1=max(i-delta,0)\n",
    "                proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "                preds.append(np.argmax(proba))\n",
    "            for i,ind in enumerate(indices):\n",
    "                if expressions[i]>=0:\n",
    "                    total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "    total_true=np.array(total_true)\n",
    "    print(weight)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        preds=np.array(total_preds[hInd])\n",
    "        print(delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5 Acc: 0.5345593372592075 F1: 0.41248830720304686\n",
      "0.6 Acc: 0.5548101464360572 F1: 0.42396717744619905\n",
      "0.7 Acc: 0.5547459826329973 F1: 0.4199674277881535\n",
      "0.8 Acc: 0.5428115152638558 F1: 0.40376213627384594\n",
      "0.9 Acc: 0.5273694266607731 F1: 0.37575897320527984\n",
      "1.0 Acc: 0.51937746852409 F1: 0.35211269341760687\n",
      "\n",
      "0.1\n",
      "0.5 Acc: 0.5420771961843925 F1: 0.4175389398022777\n",
      "0.6 Acc: 0.5646806781401053 F1: 0.4322326958234649\n",
      "0.7 Acc: 0.5677248941297249 F1: 0.43109571235292327\n",
      "0.8 Acc: 0.5571129140347625 F1: 0.4161933155374388\n",
      "0.9 Acc: 0.5431715454921364 F1: 0.3906061112686796\n",
      "1.0 Acc: 0.5371579712831335 F1: 0.3745089484818034\n",
      "\n",
      "0.2\n",
      "0.5 Acc: 0.5391007086535582 F1: 0.4157700687458627\n",
      "0.6 Acc: 0.5631763934239231 F1: 0.43462188528178486\n",
      "0.7 Acc: 0.5671973250823436 F1: 0.4352077835045166\n",
      "0.8 Acc: 0.5583926254402349 F1: 0.42234143934991075\n",
      "0.9 Acc: 0.5461765502687751 F1: 0.40051848435931264\n",
      "1.0 Acc: 0.5388440534413186 F1: 0.38897485868167003\n",
      "\n",
      "0.30000000000000004\n",
      "0.5 Acc: 0.5373575920037643 F1: 0.4155364962612554\n",
      "0.6 Acc: 0.5625098028032453 F1: 0.43747486578849615\n",
      "0.7 Acc: 0.5672507949182268 F1: 0.4392537028894537\n",
      "0.8 Acc: 0.5603781386793664 F1: 0.42805206562095766\n",
      "0.9 Acc: 0.5499729086164858 F1: 0.40912710155977305\n",
      "1.0 Acc: 0.5442552008327036 F1: 0.40107931071467473\n",
      "\n",
      "0.4\n",
      "0.5 Acc: 0.5358533072875822 F1: 0.417722480667408\n",
      "0.6 Acc: 0.5606775697603126 F1: 0.4427682176985339\n",
      "0.7 Acc: 0.5654969843012562 F1: 0.44704572489896144\n",
      "0.8 Acc: 0.5603460567778364 F1: 0.43770409107431674\n",
      "0.9 Acc: 0.554011663553534 F1: 0.424112438099614\n",
      "1.0 Acc: 0.5496734775355396 F1: 0.4186490813554008\n",
      "\n",
      "0.5\n",
      "0.5 Acc: 0.533065746510202 F1: 0.41746687693654383\n",
      "0.6 Acc: 0.5581823107524275 F1: 0.44417493353749815\n",
      "0.7 Acc: 0.5649765445653259 F1: 0.4490753836280086\n",
      "0.8 Acc: 0.5644739281080233 F1: 0.4421275482000595\n",
      "0.9 Acc: 0.560460125761054 F1: 0.4322481260980985\n",
      "1.0 Acc: 0.5566673320690688 F1: 0.42743871462080896\n",
      "\n",
      "0.6000000000000001\n",
      "0.5 Acc: 0.5294012804243367 F1: 0.41645801820061445\n",
      "0.6 Acc: 0.5543182239459313 F1: 0.44347880412380325\n",
      "0.7 Acc: 0.560998388775612 F1: 0.4489334257535035\n",
      "0.8 Acc: 0.5643634237805313 F1: 0.4452612991646087\n",
      "0.9 Acc: 0.5627735873269359 F1: 0.4380281251385963\n",
      "1.0 Acc: 0.5597079834029629 F1: 0.4342068528678106\n",
      "\n",
      "0.7000000000000001\n",
      "0.5 Acc: 0.5253767841101906 F1: 0.41441380385894344\n",
      "0.6 Acc: 0.5499657793050348 F1: 0.4413647705103574\n",
      "0.7 Acc: 0.5570237976416238 F1: 0.44763248294545865\n",
      "0.8 Acc: 0.5609092723824733 F1: 0.44475756375854575\n",
      "0.9 Acc: 0.559850569631985 F1: 0.43815421738957483\n",
      "1.0 Acc: 0.5567421898393053 F1: 0.43425788615947614\n",
      "\n",
      "0.8\n",
      "0.5 Acc: 0.521270300714357 F1: 0.4129958743051243\n",
      "0.6 Acc: 0.5457701795160623 F1: 0.4397910183296017\n",
      "0.7 Acc: 0.5531917927366575 F1: 0.44596303284019945\n",
      "0.8 Acc: 0.5570237976416238 F1: 0.44303759562883993\n",
      "0.9 Acc: 0.5562431380377283 F1: 0.43646478812279416\n",
      "1.0 Acc: 0.5530064306389288 F1: 0.4321361874786348\n",
      "\n",
      "0.9\n",
      "0.5 Acc: 0.5166255543039653 F1: 0.4099261178846991\n",
      "0.6 Acc: 0.5404980536979739 F1: 0.4361877800673365\n",
      "0.7 Acc: 0.5481798867865342 F1: 0.44251232859169837\n",
      "0.8 Acc: 0.5517944476922418 F1: 0.43940443989253714\n",
      "0.9 Acc: 0.5512134088089772 F1: 0.43293267564689986\n",
      "1.0 Acc: 0.5478269858697047 F1: 0.42841775070808386\n",
      "\n",
      "1.0\n",
      "0.5 Acc: 0.5122374631058132 F1: 0.4070930183009853\n",
      "0.6 Acc: 0.5351902813226299 F1: 0.43217040242047583\n",
      "0.7 Acc: 0.5428828083783668 F1: 0.43835013947562684\n",
      "0.8 Acc: 0.546247843383286 F1: 0.43428887590742027\n",
      "0.9 Acc: 0.5458165200404945 F1: 0.4282005950922094\n",
      "1.0 Acc: 0.5424158384783198 F1: 0.42366109129065965\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Ensemble\n",
    "#deltas=[0,5,15,25,50,100,200,500]\n",
    "thresholds=[0.5, 0.6, 0.7, 0.8, 0.9, 1.0]#np.linspace(0,1,11)\n",
    "delta=50\n",
    "for weight in np.linspace(0,1,11):\n",
    "    total_true=[]\n",
    "    total_preds=[[] for _ in range(len(thresholds))]\n",
    "    for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_true.append(expressions[i])\n",
    "        \n",
    "        y_pred_expr_audio,_,_,_=test_audios[videoname]\n",
    "        y_ensemble=weight*y_pred_expr + (1-weight)*y_pred_expr_audio\n",
    "        pretrained_scores_probabs=scores2probabs(scores)\n",
    "        cur_ind=0\n",
    "        preds_proba,pretrained_preds_proba=[],[]\n",
    "        for i in range(indices[-1]):\n",
    "            if indices[cur_ind]-1==i:\n",
    "                preds_proba.append(y_ensemble[cur_ind])\n",
    "                pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "                cur_ind+=1\n",
    "            else:\n",
    "                if cur_ind==0:\n",
    "                    preds_proba.append(y_ensemble[cur_ind])\n",
    "                    pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "                else:\n",
    "                    w=1-(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                    pred=w*y_ensemble[cur_ind-1]+(1-w)*y_ensemble[cur_ind]\n",
    "                    preds_proba.append(pred)\n",
    "\n",
    "                    s=w*pretrained_scores_probabs[cur_ind-1]+(1-w)*pretrained_scores_probabs[cur_ind]\n",
    "                    pretrained_preds_proba.append(s)\n",
    "\n",
    "        preds_proba=np.array(preds_proba)\n",
    "        pretrained_preds_proba=np.array(pretrained_preds_proba)\n",
    "\n",
    "        for hInd,t in enumerate(thresholds):\n",
    "            preds=[]\n",
    "            for i in range(len(preds_proba)):\n",
    "                i1=max(i-delta,0)\n",
    "                proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "                pred=np.argmax(proba)\n",
    "\n",
    "                pretrained_proba=np.mean(pretrained_preds_proba[i1:i+delta+1],axis=0)\n",
    "                pretrained_pred=np.argmax(pretrained_proba[:7])\n",
    "                if pretrained_proba[pretrained_pred]>t:\n",
    "                    pred=pretrained_pred\n",
    "                preds.append(pred)\n",
    "\n",
    "            for i,ind in enumerate(indices):\n",
    "                if expressions[i]>=0:\n",
    "                    total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "    total_true=np.array(total_true)\n",
    "    print(weight)\n",
    "    for hInd,t in enumerate(thresholds):\n",
    "        preds=np.array(total_preds[hInd])\n",
    "        print(t,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))\n",
    "    print()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Acc: 0.49302753340082417 F1: 0.3830806902655762\n",
      "5 Acc: 0.5112928293385425 F1: 0.3984449112888923\n",
      "15 Acc: 0.5252484565040708 F1: 0.4102184763684504\n",
      "25 Acc: 0.5313440177947614 F1: 0.4164778611208603\n",
      "50 Acc: 0.5389545577688107 F1: 0.42223307250557535\n",
      "100 Acc: 0.5359317297135443 F1: 0.41796605670219833\n",
      "200 Acc: 0.5328589964781202 F1: 0.4164616736756614\n",
      "500 Acc: 0.5271769352515934 F1: 0.4067049624885466\n"
     ]
    }
   ],
   "source": [
    "#deltas=[0,1,5,7,15]\n",
    "deltas=[0,5,15,25,50,100,200,500]\n",
    "total_true=[]\n",
    "total_preds=[[] for _ in range(len(deltas))]\n",
    "for videoname,(y_pred_expr,indices,expressions,scores) in test_videos.items():\n",
    "    for i,ind in enumerate(indices):\n",
    "        if expressions[i]>=0:\n",
    "            total_true.append(expressions[i])\n",
    "    cur_ind=0\n",
    "    preds_proba=[]\n",
    "    for i in range(indices[-1]):\n",
    "        if indices[cur_ind]-1==i:\n",
    "            preds_proba.append(y_pred_expr[cur_ind])\n",
    "            cur_ind+=1\n",
    "        else:\n",
    "            if cur_ind==0:\n",
    "                preds_proba.append(y_pred_expr[cur_ind])\n",
    "            else:\n",
    "                w=(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                preds_proba.append(pred)\n",
    "    \n",
    "    preds_proba=np.array(preds_proba)\n",
    "    for hInd,delta in enumerate(deltas):\n",
    "        preds=[]\n",
    "        for i in range(len(preds_proba)):\n",
    "            i1=max(i-delta,0)\n",
    "            proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "            best_ind=np.argmax(proba)\n",
    "            best_ind_no_other=np.argmax(proba[:7])\n",
    "            if best_ind==7 and proba[best_ind]-proba[best_ind_no_other]<0.05:\n",
    "                best_ind=best_ind_no_other\n",
    "            preds.append(best_ind)\n",
    "        for i,ind in enumerate(indices):\n",
    "            if expressions[i]>=0:\n",
    "                total_preds[hInd].append(preds[ind-1])\n",
    "\n",
    "total_true=np.array(total_true)\n",
    "for hInd,delta in enumerate(deltas):\n",
    "    preds=np.array(total_preds[hInd])\n",
    "    print(delta,'Acc:',(preds==total_true).mean(), 'F1:',f1_score(y_true=total_true,y_pred=preds, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save test results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022656 ['image_location,Neutral,Anger,Disgust,Fear,Happiness,Sadness,Surprise,Other', '14-30-1920x1080/00001.jpg,0', '14-30-1920x1080/00002.jpg,0', '14-30-1920x1080/00003.jpg,0', '14-30-1920x1080/00004.jpg,0']\n",
      "228\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join(DATA_DIR,'test_set_examples/CVPR_6th_ABAW_Expr_test_set_example.txt'),'r') as f:\n",
    "    test_set_sample=f.read().splitlines()\n",
    "print(len(test_set_sample),test_set_sample[:5])\n",
    "\n",
    "test_set_videos={}\n",
    "for s in test_set_sample[1:]:\n",
    "    videoname,img_name=s[:-2].split('/')\n",
    "    if videoname not in test_set_videos:\n",
    "        test_set_videos[videoname]=[]\n",
    "    test_set_videos[videoname].append(img_name)\n",
    "    \n",
    "print(len(test_set_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mlpModel.load_weights('expr_enet0_vgaf_train_val.h5')\n",
    "mlpModel.load_weights('expr_enet0_vgaf_train_val_new.h5')\n",
    "mlpModelAudio.load_weights('expr_wav2vec_train_val_new.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 228/228 [01:24<00:00,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_videos={}\n",
    "test_videos_num_frames={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    X,indices,filenames,scores=[],[],[],[]\n",
    "    num_present=num_missed=0\n",
    "    for img_name in img_files:\n",
    "        k=videoname+'/'+img_name\n",
    "        if k in filename2featuresAll:\n",
    "            X.append(filename2featuresAll[k][0])\n",
    "            indices.append(int(img_name[:-4]))\n",
    "            filenames.append(k)\n",
    "            scores.append(filename2featuresAll[k][1][AFFECTNET2MTL])\n",
    "            num_present+=1\n",
    "        else:\n",
    "            num_missed+=1\n",
    "    test_videos[videoname]=(mlpModel.predict(np.array(X),verbose=0),indices,filenames,np.array(scores))\n",
    "    test_videos_num_frames[videoname]=(num_present,num_missed)\n",
    "print(len(test_videos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 228/228 [01:17<00:00,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_audios={}\n",
    "test_audios_num_frames={}\n",
    "for videoname,img_files in tqdm(test_set_videos.items()):\n",
    "    X,indices,filenames,scores=[],[],[],[]\n",
    "    num_present=num_missed=0\n",
    "    fn_short=videoname\n",
    "    if videoname.endswith('_left'):\n",
    "        fn_short=videoname[:-5]\n",
    "    elif videoname.endswith('_right'):\n",
    "        fn_short=videoname[:-6]\n",
    "    for img_name in img_files:\n",
    "        k=fn_short+'/'+img_name\n",
    "        if k in filename2audio_features:\n",
    "            X.append(filename2audio_features[k])\n",
    "            indices.append(int(img_name[:-4]))\n",
    "            filenames.append(k)\n",
    "            num_present+=1\n",
    "        else:\n",
    "            num_missed+=1\n",
    "    test_audios[videoname]=(mlpModelAudio.predict(np.array(X),verbose=0),indices,filenames,np.array(scores))\n",
    "    test_audios_num_frames[videoname]=(num_present,num_missed)\n",
    "print(len(test_audios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    with open('expr_test_audios.pickle', 'wb') as handle:\n",
    "        pickle.dump(test_audios, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    with open('../abaw6/expr_test_audios.pickle', 'rb') as handle:\n",
    "        test_audios=pickle.load(handle)\n",
    "print(len(test_audios))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/HDD6TB/datasets/emotions/ABAW/ABAW_8/8th_ABAW_Annotations/test_results/EXPR/abaw8\n"
     ]
    }
   ],
   "source": [
    "delta=50 # 0 2 4 7\n",
    "OUTPUT_DIR=DATA_DIR+'/test_results/EXPR/abaw8'\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.mkdir(OUTPUT_DIR)\n",
    "print(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66661 1022655\n",
      "27906 1022655\n",
      "11813 1022655\n"
     ]
    }
   ],
   "source": [
    "#for t in np.linspace(0.5,1,6):\n",
    "for t in [0.7, 0.8, 0.9]:\n",
    "#for t in [0.9]:\n",
    "    num_changed_frames,num_frames=0,0\n",
    "    with open(os.path.join(OUTPUT_DIR,'predictions_'+str(t)+'_train_val.txt'), 'w') as f:\n",
    "    #with open(os.path.join(OUTPUT_DIR,'predictions_'+str(t)+'.txt'), 'w') as f:\n",
    "        f.write(test_set_sample[0]+'\\n')\n",
    "        for videoname,(y_pred_expr,indices,filenames,scores) in test_videos.items():\n",
    "            pretrained_scores_probabs=scores2probabs(scores)\n",
    "            cur_ind=0\n",
    "            preds_proba,pretrained_preds_proba=[],[]\n",
    "            for i in range(indices[-1]):\n",
    "                if indices[cur_ind]-1==i:\n",
    "                    preds_proba.append(y_pred_expr[cur_ind])\n",
    "                    pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "                    cur_ind+=1\n",
    "                else:\n",
    "                    if cur_ind==0:\n",
    "                        preds_proba.append(y_pred_expr[cur_ind])\n",
    "                        pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "                    else:\n",
    "                        w=1-(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                        pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                        preds_proba.append(pred)\n",
    "\n",
    "                        s=w*pretrained_scores_probabs[cur_ind-1]+(1-w)*pretrained_scores_probabs[cur_ind]\n",
    "                        pretrained_preds_proba.append(s)\n",
    "\n",
    "            pred=y_pred_expr[cur_ind-1]\n",
    "            pretrained_pred=pretrained_scores_probabs[cur_ind-1]\n",
    "            for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "                preds_proba.append(pred)\n",
    "                pretrained_preds_proba.append(pretrained_pred)\n",
    "\n",
    "            preds_proba=np.array(preds_proba)\n",
    "            pretrained_preds_proba=np.array(pretrained_preds_proba)\n",
    "            for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "                i1=max(i-delta,0)\n",
    "                proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "                pred=np.argmax(proba)\n",
    "\n",
    "                pretrained_proba=np.mean(pretrained_preds_proba[i1:i+delta+1],axis=0)\n",
    "                pretrained_pred=np.argmax(pretrained_proba[:7])\n",
    "                if pretrained_proba[pretrained_pred]>t:\n",
    "                    if pred!=pretrained_pred:\n",
    "                        num_changed_frames+=1\n",
    "                    pred=pretrained_pred\n",
    "                num_frames+=1\n",
    "                f.write(videoname+'/'+img_name+','+str(pred)+'\\n')\n",
    "    print(num_changed_frames,num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 0.5 235868 1022655\n",
      "0.5 0.6 131933 1022655\n",
      "0.5 0.7 67209 1022655\n",
      "0.5 0.8 29048 1022655\n",
      "0.5 0.9 12420 1022655\n",
      "0.6 0.5 235307 1022655\n",
      "0.6 0.6 131752 1022655\n",
      "0.6 0.7 67043 1022655\n",
      "0.6 0.8 28616 1022655\n",
      "0.6 0.9 12163 1022655\n",
      "0.7 0.5 233706 1022655\n",
      "0.7 0.6 130129 1022655\n",
      "0.7 0.7 65598 1022655\n",
      "0.7 0.8 27326 1022655\n",
      "0.7 0.9 11475 1022655\n",
      "0.8 0.5 234807 1022655\n",
      "0.8 0.6 130724 1022655\n",
      "0.8 0.7 65907 1022655\n",
      "0.8 0.8 27464 1022655\n",
      "0.8 0.9 11581 1022655\n",
      "0.9 0.5 235781 1022655\n",
      "0.9 0.6 131263 1022655\n",
      "0.9 0.7 66223 1022655\n",
      "0.9 0.8 27614 1022655\n",
      "0.9 0.9 11690 1022655\n"
     ]
    }
   ],
   "source": [
    "#weight=0.7\n",
    "for weight in [0.5, 0.6, 0.7, 0.8, 0.9]:#[0.6, 0.9]:\n",
    "    for t in [0.5, 0.6, 0.7, 0.8, 0.9]:\n",
    "        num_changed_frames,num_frames=0,0\n",
    "        with open(os.path.join(OUTPUT_DIR,'predictions_'+str(weight)+'_'+str(t)+'_train_val_audio.txt'), 'w') as f:\n",
    "        #with open(os.path.join(OUTPUT_DIR,'predictions_'+str(t)+'.txt'), 'w') as f:\n",
    "            f.write(test_set_sample[0]+'\\n')\n",
    "            for videoname,(y_pred_expr,indices,filenames,scores) in test_videos.items():\n",
    "                y_pred_expr_audio,indices_audio,filenames_audio,_=test_audios[videoname]\n",
    "\n",
    "                pretrained_scores_probabs=scores2probabs(scores)\n",
    "                cur_ind=0\n",
    "                preds_proba,pretrained_preds_proba=[],[]\n",
    "                for i in range(indices[-1]):\n",
    "                    if indices[cur_ind]-1==i:\n",
    "                        preds_proba.append(y_pred_expr[cur_ind])\n",
    "                        pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "                        cur_ind+=1\n",
    "                    else:\n",
    "                        if cur_ind==0:\n",
    "                            preds_proba.append(y_pred_expr[cur_ind])\n",
    "                            pretrained_preds_proba.append(pretrained_scores_probabs[cur_ind])\n",
    "                        else:\n",
    "                            w=1-(i-indices[cur_ind-1]+1)/(indices[cur_ind]-indices[cur_ind-1])\n",
    "                            pred=w*y_pred_expr[cur_ind-1]+(1-w)*y_pred_expr[cur_ind]\n",
    "                            preds_proba.append(pred)\n",
    "\n",
    "                            s=w*pretrained_scores_probabs[cur_ind-1]+(1-w)*pretrained_scores_probabs[cur_ind]\n",
    "                            pretrained_preds_proba.append(s)\n",
    "\n",
    "                pred=y_pred_expr[cur_ind-1]\n",
    "                pretrained_pred=pretrained_scores_probabs[cur_ind-1]\n",
    "                for _ in range(indices[-1],len(test_set_videos[videoname])):\n",
    "                    preds_proba.append(pred)\n",
    "                    pretrained_preds_proba.append(pretrained_pred)\n",
    "\n",
    "                preds_proba=np.array(preds_proba)\n",
    "                preds_proba=weight*preds_proba+(1-weight)*y_pred_expr_audio\n",
    "                pretrained_preds_proba=np.array(pretrained_preds_proba)\n",
    "                for i,img_name in enumerate(test_set_videos[videoname]):\n",
    "                    i1=max(i-delta,0)\n",
    "                    proba=np.mean(preds_proba[i1:i+delta+1],axis=0)\n",
    "                    pred=np.argmax(proba)\n",
    "\n",
    "                    pretrained_proba=np.mean(pretrained_preds_proba[i1:i+delta+1],axis=0)\n",
    "                    pretrained_pred=np.argmax(pretrained_proba[:7])\n",
    "                    if pretrained_proba[pretrained_pred]>t:\n",
    "                        if pred!=pretrained_pred:\n",
    "                            num_changed_frames+=1\n",
    "                        pred=pretrained_pred\n",
    "                    num_frames+=1\n",
    "                    f.write(videoname+'/'+img_name+','+str(pred)+'\\n')\n",
    "        print(weight,t,num_changed_frames,num_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
