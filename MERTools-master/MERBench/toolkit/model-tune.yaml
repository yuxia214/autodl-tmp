tfn:
  hidden_dim: [64, 128]
  dropout: [0.2, 0.3, 0.4, 0.5]
  grad_clip: [-1.0]
  lr: [1e-3, 1e-4]

lmf:
  hidden_dim: [32, 64, 128, 256]
  dropout: [0.2, 0.3, 0.4, 0.5]
  rank: [3, 4, 5, 6]
  grad_clip: [-1.0]
  lr: [1e-3, 1e-4]

mmim:
  hidden_dim: [64, 128, 256]
  dropout: [0.0, 0.1, 0.2, 0.3]
  cpc_layers: [1, 2, 3, 4]
  alpha: [0.0, 0.1, 0.2]
  beta:  [0.0, 0.1, 0.2]
  grad_clip: [0.6, 0.8, 1.0]
  lr: [1e-3, 1e-4]

misa:
  dropout: [0.2, 0.3, 0.4, 0.5]
  hidden_dim: [64, 128, 256]
  sim_weight: [0.0, 0.1, 0.2]
  diff_weight: [0.0, 0.1, 0.2]
  recon_weight: [0.0, 0.1, 0.2]
  grad_clip: [-1.0, 0.8, 1.0]
  lr: [1e-3, 1e-4]

mfn:
  hidden_dim: [128, 256]
  mem_dim: [128]
  dropout: [0.0, 0.3, 0.5, 0.7]
  window_dim: [2]
  grad_clip: [-1.0]
  lr: [1e-3, 1e-4]

graph_mfn:
  hidden_dim: [128, 256]
  mem_dim: [128]
  dropout: [0.0, 0.3, 0.5, 0.7]
  grad_clip: [-1.0]
  lr: [1e-3, 1e-4]

mfm:
  hidden_dim: [128, 256]
  mem_dim: [128]
  dropout: [0.0, 0.3, 0.5, 0.7]
  window_dim: [2]
  lda_xl:  [0.01, 0.1, 0.5, 1.0]
  lda_xa:  [0.01, 0.1, 0.5, 1.0]
  lda_xv:  [0.01, 0.1, 0.5, 1.0]
  lda_mmd: [10, 50, 100]
  grad_clip: [-1.0]
  lr: [1e-3, 1e-4]

mult:
  layers: [2, 4, 6]
  dropout: [0.0, 0.1, 0.2, 0.3]
  num_heads: [8]
  hidden_dim: [64, 128, 256]
  conv1d_kernel_size: [1, 3]
  grad_clip: [0.6, 0.8, 1.0]
  lr: [1e-3, 1e-4]

mctn:
  hidden_dim: [64, 128, 256]
  dropout: [0.0, 0.1, 0.2, 0.3]
  teacher_forcing_ratio: [0.3, 0.5]
  loss_weight: [0.1, 0.3, 0.5, 0.8, 1.0]
  grad_clip: [0.6, 0.8, 1.0]
  lr: [1e-3, 1e-4]

attention:
  hidden_dim: [64, 128, 256]
  dropout: [0.2, 0.3, 0.4, 0.5]
  grad_clip: [-1.0]
  lr: [1e-3, 1e-4]

# 针对模态缺失场景优化的attention模型
attention_robust:
  hidden_dim: [128, 256]
  dropout: [0.4, 0.5, 0.6]
  grad_clip: [0.8, 1.0]
  lr: [5e-4, 1e-4]
  modality_dropout: [0.2, 0.3, 0.4]
  use_modality_dropout: [true]

# AttentionRobustV2 - 基于P-RMF的概率化多模态融合模型
# 核心改进：VAE编码器 + 不确定性加权融合 + 代理模态跨模态注意力
attention_robust_v2:
  # 基础参数
  hidden_dim: [128]
  dropout: [0.3, 0.35, 0.4]
  grad_clip: [1.0]
  lr: [5e-4, 1e-4]
  
  # VAE参数
  use_vae: [true]
  kl_weight: [0.005, 0.01, 0.02]        # KL散度权重
  recon_weight: [0.05, 0.1, 0.2]        # 重建损失权重
  cross_kl_weight: [0.005, 0.01]        # 跨模态KL权重
  
  # 代理模态参数
  use_proxy_attention: [true, false]     # 是否使用代理模态注意力
  fusion_temperature: [0.5, 1.0, 2.0]    # 温度参数
  num_attention_heads: [4]               # 注意力头数
  
  # 模态dropout参数
  modality_dropout: [0.1, 0.15, 0.2]
  use_modality_dropout: [true]
  modality_dropout_warmup: [20, 30]
