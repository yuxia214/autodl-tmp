====== Params Pre-analysis =======
args:  Namespace(audio_feature='chinese-hubert-large-UTT', batch_size=32, contrastive_temperature=0.07, contrastive_weight=0.1, cross_kl_weight=0.01, dataset='MER2023', debug=False, dropout=0.35, e2e_dim=None, e2e_name=None, early_stopping_patience=30, epochs=100, feat_scale=1, feat_type='utt', focal_gamma=2.0, fusion_temperature=1.0, gate_alpha=0.5, gpu=0, grad_clip=1.0, hidden_dim=128, hyper_path=None, kl_warmup_epochs=20, kl_weight=0.01, l2=5e-05, label_smoothing=0.1, lr=0.0005, lr_adjust='case1', lr_factor=0.5, lr_patience=10, mixup_alpha=0.4, modality_dropout=0.15, modality_dropout_warmup=20, model='attention_robust_v5', n_classes=None, num_attention_heads=4, num_workers=0, print_iters=100000000.0, recon_weight=0.1, save_iters=100000000.0, save_root='./saved-trimodal', savemodel=False, test_dataset=None, text_feature='Baichuan-13B-Base-UTT', train_dataset=None, use_contrastive=True, use_dynamic_kl=True, use_gated_fusion=True, use_mixup=False, use_modality_dropout=True, use_proxy_attention=False, use_vae=True, video_feature='clip-vit-large-patch14-UTT')
====== Reading Data =======
train: sample number 3373
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/3373 [00:00<?, ?it/s]  2%|▏         | 64/3373 [00:00<00:05, 635.44it/s]  5%|▌         | 179/3373 [00:00<00:03, 936.76it/s]  8%|▊         | 273/3373 [00:00<00:04, 645.80it/s] 12%|█▏        | 410/3373 [00:00<00:03, 864.39it/s] 15%|█▌        | 507/3373 [00:00<00:03, 889.39it/s] 18%|█▊        | 603/3373 [00:00<00:03, 910.08it/s] 21%|██        | 699/3373 [00:00<00:04, 586.17it/s] 23%|██▎       | 787/3373 [00:01<00:03, 647.62it/s] 28%|██▊       | 960/3373 [00:01<00:02, 899.48it/s] 32%|███▏      | 1069/3373 [00:01<00:02, 939.05it/s] 35%|███▍      | 1177/3373 [00:01<00:02, 968.19it/s] 38%|███▊      | 1284/3373 [00:01<00:02, 798.11it/s] 41%|████      | 1376/3373 [00:01<00:02, 821.34it/s] 43%|████▎     | 1467/3373 [00:01<00:02, 843.49it/s] 46%|████▌     | 1560/3373 [00:01<00:02, 865.04it/s] 49%|████▉     | 1652/3373 [00:02<00:01, 869.17it/s] 52%|█████▏    | 1743/3373 [00:02<00:01, 879.86it/s] 54%|█████▍    | 1834/3373 [00:02<00:02, 572.60it/s] 57%|█████▋    | 1921/3373 [00:02<00:02, 633.74it/s] 59%|█████▉    | 1998/3373 [00:02<00:03, 456.37it/s] 62%|██████▏   | 2108/3373 [00:02<00:02, 574.02it/s] 65%|██████▍   | 2184/3373 [00:03<00:02, 503.33it/s] 68%|██████▊   | 2280/3373 [00:03<00:01, 591.01it/s] 70%|██████▉   | 2354/3373 [00:03<00:01, 518.16it/s] 73%|███████▎  | 2447/3373 [00:03<00:01, 602.75it/s] 75%|███████▍  | 2519/3373 [00:03<00:01, 513.62it/s] 77%|███████▋  | 2581/3373 [00:03<00:01, 531.09it/s] 79%|███████▉  | 2658/3373 [00:03<00:01, 584.69it/s] 82%|████████▏ | 2759/3373 [00:04<00:00, 686.49it/s] 85%|████████▍ | 2862/3373 [00:04<00:00, 775.39it/s] 87%|████████▋ | 2946/3373 [00:04<00:00, 790.36it/s] 90%|████████▉ | 3030/3373 [00:04<00:00, 641.80it/s] 92%|█████████▏| 3102/3373 [00:04<00:00, 650.55it/s] 94%|█████████▍| 3173/3373 [00:04<00:00, 541.75it/s] 96%|█████████▌| 3236/3373 [00:04<00:00, 561.31it/s] 99%|█████████▉| 3334/3373 [00:04<00:00, 663.37it/s]100%|██████████| 3373/3373 [00:04<00:00, 688.22it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/3373 [00:00<?, ?it/s]  1%|          | 23/3373 [00:00<00:14, 229.68it/s]  2%|▏         | 76/3373 [00:00<00:08, 402.02it/s]  4%|▎         | 121/3373 [00:00<00:07, 421.82it/s]  5%|▌         | 174/3373 [00:00<00:06, 464.14it/s]  8%|▊         | 259/3373 [00:00<00:05, 602.23it/s]  9%|▉         | 320/3373 [00:00<00:05, 600.49it/s] 12%|█▏        | 389/3373 [00:00<00:04, 624.62it/s] 14%|█▎        | 463/3373 [00:00<00:04, 660.82it/s] 16%|█▌        | 530/3373 [00:00<00:04, 661.49it/s] 18%|█▊        | 597/3373 [00:01<00:04, 661.53it/s] 20%|██        | 690/3373 [00:01<00:03, 743.03it/s] 23%|██▎       | 765/3373 [00:01<00:05, 470.23it/s] 25%|██▍       | 829/3373 [00:01<00:05, 506.30it/s] 26%|██▋       | 890/3373 [00:01<00:04, 525.93it/s] 28%|██▊       | 951/3373 [00:01<00:05, 443.14it/s] 30%|██▉       | 1003/3373 [00:01<00:05, 457.03it/s] 31%|███▏      | 1055/3373 [00:02<00:06, 383.52it/s] 33%|███▎      | 1099/3373 [00:02<00:07, 324.70it/s] 34%|███▎      | 1137/3373 [00:02<00:06, 333.71it/s] 35%|███▍      | 1175/3373 [00:02<00:06, 344.07it/s] 37%|███▋      | 1262/3373 [00:02<00:04, 469.51it/s] 39%|███▉      | 1326/3373 [00:02<00:04, 415.21it/s] 41%|████      | 1373/3373 [00:03<00:05, 346.15it/s] 42%|████▏     | 1429/3373 [00:03<00:04, 390.48it/s] 44%|████▎     | 1474/3373 [00:03<00:06, 274.73it/s] 45%|████▍     | 1510/3373 [00:03<00:06, 289.03it/s] 47%|████▋     | 1579/3373 [00:03<00:06, 264.55it/s] 48%|████▊     | 1611/3373 [00:04<00:08, 204.61it/s] 49%|████▉     | 1656/3373 [00:04<00:08, 210.57it/s] 50%|█████     | 1695/3373 [00:04<00:07, 237.17it/s] 52%|█████▏    | 1747/3373 [00:04<00:07, 212.95it/s] 53%|█████▎    | 1773/3373 [00:04<00:07, 220.42it/s] 55%|█████▌    | 1856/3373 [00:05<00:05, 282.85it/s] 56%|█████▋    | 1901/3373 [00:05<00:04, 313.50it/s] 57%|█████▋    | 1936/3373 [00:05<00:05, 266.29it/s] 59%|█████▉    | 1993/3373 [00:05<00:05, 272.38it/s] 61%|██████    | 2048/3373 [00:05<00:04, 323.08it/s] 62%|██████▏   | 2097/3373 [00:05<00:05, 250.40it/s] 64%|██████▎   | 2146/3373 [00:06<00:04, 291.67it/s] 65%|██████▍   | 2182/3373 [00:06<00:04, 256.62it/s] 66%|██████▌   | 2213/3373 [00:06<00:04, 266.21it/s] 67%|██████▋   | 2248/3373 [00:06<00:05, 197.23it/s] 68%|██████▊   | 2297/3373 [00:06<00:05, 214.77it/s] 69%|██████▉   | 2323/3373 [00:06<00:04, 222.81it/s] 70%|██████▉   | 2350/3373 [00:07<00:04, 229.76it/s] 71%|███████▏  | 2405/3373 [00:07<00:04, 207.45it/s] 72%|███████▏  | 2429/3373 [00:07<00:05, 182.72it/s] 73%|███████▎  | 2474/3373 [00:07<00:03, 229.40it/s] 74%|███████▍  | 2502/3373 [00:07<00:05, 170.87it/s] 77%|███████▋  | 2591/3373 [00:08<00:02, 292.25it/s] 78%|███████▊  | 2632/3373 [00:08<00:02, 263.96it/s] 79%|███████▉  | 2679/3373 [00:08<00:02, 302.84it/s] 81%|████████  | 2718/3373 [00:08<00:02, 268.21it/s] 82%|████████▏ | 2780/3373 [00:08<00:01, 338.92it/s] 84%|████████▍ | 2841/3373 [00:08<00:01, 393.00it/s] 86%|████████▌ | 2888/3373 [00:08<00:01, 335.61it/s] 87%|████████▋ | 2928/3373 [00:09<00:01, 346.29it/s] 88%|████████▊ | 2968/3373 [00:09<00:01, 290.72it/s] 89%|████████▉ | 3002/3373 [00:09<00:01, 249.21it/s] 90%|████████▉ | 3031/3373 [00:09<00:01, 215.47it/s] 91%|█████████ | 3068/3373 [00:09<00:01, 243.73it/s] 92%|█████████▏| 3096/3373 [00:09<00:01, 176.68it/s] 92%|█████████▏| 3119/3373 [00:10<00:01, 185.54it/s] 94%|█████████▍| 3178/3373 [00:10<00:00, 266.82it/s] 95%|█████████▌| 3212/3373 [00:10<00:00, 281.00it/s] 96%|█████████▌| 3246/3373 [00:10<00:00, 293.36it/s] 99%|█████████▉| 3351/3373 [00:10<00:00, 485.81it/s]100%|██████████| 3373/3373 [00:10<00:00, 315.26it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/3373 [00:00<?, ?it/s]  0%|          | 1/3373 [00:00<05:46,  9.74it/s]  3%|▎         | 92/3373 [00:00<00:06, 532.82it/s]  5%|▌         | 178/3373 [00:00<00:08, 365.88it/s]  7%|▋         | 236/3373 [00:00<00:07, 420.19it/s]  9%|▉         | 304/3373 [00:00<00:07, 386.37it/s] 13%|█▎        | 428/3373 [00:00<00:05, 582.78it/s] 15%|█▌        | 515/3373 [00:00<00:04, 650.69it/s] 18%|█▊        | 591/3373 [00:01<00:07, 380.89it/s] 19%|█▉        | 649/3373 [00:01<00:07, 356.27it/s] 23%|██▎       | 767/3373 [00:01<00:05, 499.80it/s] 25%|██▌       | 854/3373 [00:01<00:04, 570.44it/s] 29%|██▉       | 972/3373 [00:01<00:03, 704.74it/s] 31%|███▏      | 1060/3373 [00:02<00:03, 737.16it/s] 34%|███▍      | 1147/3373 [00:02<00:03, 626.14it/s] 37%|███▋      | 1242/3373 [00:02<00:03, 693.78it/s] 39%|███▉      | 1322/3373 [00:02<00:02, 713.60it/s] 42%|████▏     | 1401/3373 [00:02<00:03, 588.16it/s] 44%|████▎     | 1469/3373 [00:02<00:03, 500.24it/s] 45%|████▌     | 1527/3373 [00:02<00:03, 516.02it/s] 47%|████▋     | 1593/3373 [00:03<00:04, 373.91it/s] 51%|█████     | 1720/3373 [00:03<00:03, 533.15it/s] 57%|█████▋    | 1912/3373 [00:03<00:01, 818.67it/s] 60%|█████▉    | 2018/3373 [00:03<00:02, 607.96it/s] 62%|██████▏   | 2104/3373 [00:03<00:01, 653.45it/s] 65%|██████▍   | 2190/3373 [00:04<00:02, 487.94it/s] 67%|██████▋   | 2259/3373 [00:04<00:02, 390.88it/s] 69%|██████▉   | 2342/3373 [00:04<00:02, 455.93it/s] 71%|███████▏  | 2405/3373 [00:04<00:01, 484.60it/s] 73%|███████▎  | 2474/3373 [00:04<00:02, 444.42it/s] 77%|███████▋  | 2581/3373 [00:04<00:01, 561.40it/s] 79%|███████▊  | 2654/3373 [00:05<00:01, 497.11it/s] 80%|████████  | 2714/3373 [00:05<00:01, 509.45it/s] 84%|████████▎ | 2817/3373 [00:05<00:00, 625.60it/s] 86%|████████▌ | 2889/3373 [00:05<00:00, 527.89it/s] 90%|█████████ | 3049/3373 [00:05<00:00, 763.49it/s] 94%|█████████▍| 3164/3373 [00:05<00:00, 684.05it/s]100%|██████████| 3373/3373 [00:05<00:00, 571.63it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test1: sample number 411
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/411 [00:00<?, ?it/s]  0%|          | 1/411 [00:00<00:45,  9.03it/s] 32%|███▏      | 132/411 [00:00<00:00, 501.16it/s] 80%|███████▉  | 328/411 [00:00<00:00, 1012.96it/s]100%|██████████| 411/411 [00:00<00:00, 1022.68it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/411 [00:00<?, ?it/s] 20%|██        | 83/411 [00:00<00:00, 828.54it/s] 55%|█████▍    | 225/411 [00:00<00:00, 1175.69it/s]100%|██████████| 411/411 [00:00<00:00, 1487.72it/s]100%|██████████| 411/411 [00:00<00:00, 1366.86it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/411 [00:00<?, ?it/s]  5%|▍         | 19/411 [00:00<00:02, 189.90it/s] 67%|██████▋   | 277/411 [00:00<00:00, 1592.31it/s]100%|██████████| 411/411 [00:00<00:00, 1953.89it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test2: sample number 412
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/412 [00:00<?, ?it/s]  6%|▋         | 26/412 [00:00<00:01, 259.32it/s] 32%|███▏      | 133/412 [00:00<00:00, 734.42it/s] 75%|███████▌  | 310/412 [00:00<00:00, 1203.73it/s]100%|██████████| 412/412 [00:00<00:00, 1333.79it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/412 [00:00<?, ?it/s] 22%|██▏       | 89/412 [00:00<00:00, 887.29it/s] 44%|████▍     | 183/412 [00:00<00:00, 598.78it/s] 62%|██████▏   | 254/412 [00:00<00:00, 636.80it/s] 84%|████████▍ | 347/412 [00:00<00:00, 734.64it/s]100%|██████████| 412/412 [00:00<00:00, 821.63it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/412 [00:00<?, ?it/s] 19%|█▉        | 79/412 [00:00<00:00, 785.97it/s] 59%|█████▊    | 242/412 [00:00<00:00, 1275.03it/s] 97%|█████████▋| 400/412 [00:00<00:00, 1413.32it/s]100%|██████████| 412/412 [00:00<00:00, 1362.05it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test3: sample number 834
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/834 [00:00<?, ?it/s] 12%|█▏        | 99/834 [00:00<00:00, 987.47it/s] 25%|██▍       | 205/834 [00:00<00:00, 1025.23it/s] 37%|███▋      | 308/834 [00:00<00:00, 717.67it/s]  47%|████▋     | 391/834 [00:00<00:00, 752.06it/s] 57%|█████▋    | 472/834 [00:00<00:00, 764.26it/s] 72%|███████▏  | 602/834 [00:00<00:00, 926.87it/s] 84%|████████▍ | 702/834 [00:00<00:00, 741.87it/s]100%|██████████| 834/834 [00:00<00:00, 842.15it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/834 [00:00<?, ?it/s]  3%|▎         | 21/834 [00:00<00:03, 207.62it/s]  8%|▊         | 69/834 [00:00<00:02, 363.59it/s] 17%|█▋        | 140/834 [00:00<00:01, 520.07it/s] 23%|██▎       | 193/834 [00:00<00:01, 518.91it/s] 29%|██▉       | 246/834 [00:00<00:01, 396.09it/s] 35%|███▍      | 290/834 [00:00<00:01, 403.34it/s] 40%|███▉      | 333/834 [00:00<00:01, 410.57it/s] 45%|████▌     | 378/834 [00:00<00:01, 418.88it/s] 51%|█████     | 422/834 [00:01<00:00, 423.26it/s] 62%|██████▏   | 518/834 [00:01<00:00, 579.37it/s] 71%|███████   | 593/834 [00:01<00:00, 628.99it/s] 79%|███████▉  | 658/834 [00:01<00:00, 400.56it/s] 91%|█████████ | 759/834 [00:01<00:00, 527.77it/s]100%|██████████| 834/834 [00:01<00:00, 490.23it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/834 [00:00<?, ?it/s]  0%|          | 1/834 [00:00<02:40,  5.19it/s]  7%|▋         | 61/834 [00:00<00:02, 258.48it/s] 12%|█▏        | 97/834 [00:00<00:04, 167.99it/s] 29%|██▉       | 246/834 [00:00<00:01, 474.72it/s] 38%|███▊      | 319/834 [00:00<00:01, 431.30it/s] 46%|████▋     | 386/834 [00:00<00:00, 483.45it/s] 57%|█████▋    | 472/834 [00:01<00:00, 467.66it/s] 64%|██████▍   | 533/834 [00:01<00:00, 498.68it/s] 71%|███████   | 591/834 [00:01<00:00, 350.41it/s] 81%|████████  | 672/834 [00:01<00:00, 365.18it/s] 86%|████████▌ | 719/834 [00:01<00:00, 327.19it/s] 96%|█████████▋| 803/834 [00:02<00:00, 354.09it/s]100%|██████████| 834/834 [00:02<00:00, 379.31it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
train&val folder:5; test sets:3
audio dimension: 1024; text dimension: 5120; video dimension: 768
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.5205; eval:0.1966; lr:0.000500
epoch:2; metric:emoval; train:0.3093; eval:0.4593; lr:0.000500
epoch:3; metric:emoval; train:0.5185; eval:0.4469; lr:0.000500
epoch:4; metric:emoval; train:0.6016; eval:0.4648; lr:0.000500
epoch:5; metric:emoval; train:0.6862; eval:0.4957; lr:0.000500
epoch:6; metric:emoval; train:0.7225; eval:0.5077; lr:0.000500
epoch:7; metric:emoval; train:0.7615; eval:0.4775; lr:0.000500
epoch:8; metric:emoval; train:0.8006; eval:0.4929; lr:0.000500
epoch:9; metric:emoval; train:0.8201; eval:0.4806; lr:0.000500
epoch:10; metric:emoval; train:0.8487; eval:0.4731; lr:0.000500
epoch:11; metric:emoval; train:0.8627; eval:0.5016; lr:0.000500
epoch:12; metric:emoval; train:0.8702; eval:0.4913; lr:0.000500
epoch:13; metric:emoval; train:0.8795; eval:0.4999; lr:0.000500
epoch:14; metric:emoval; train:0.8902; eval:0.4450; lr:0.000500
epoch:15; metric:emoval; train:0.8926; eval:0.5188; lr:0.000500
epoch:16; metric:emoval; train:0.9105; eval:0.4974; lr:0.000500
epoch:17; metric:emoval; train:0.9109; eval:0.5165; lr:0.000500
epoch:18; metric:emoval; train:0.9147; eval:0.5016; lr:0.000500
epoch:19; metric:emoval; train:0.9229; eval:0.5017; lr:0.000500
epoch:20; metric:emoval; train:0.9127; eval:0.4430; lr:0.000500
epoch:21; metric:emoval; train:0.9228; eval:0.5096; lr:0.000500
epoch:22; metric:emoval; train:0.9276; eval:0.4817; lr:0.000500
epoch:23; metric:emoval; train:0.9184; eval:0.4864; lr:0.000500
epoch:24; metric:emoval; train:0.9162; eval:0.4953; lr:0.000500
epoch:25; metric:emoval; train:0.9021; eval:0.4658; lr:0.000500
epoch:26; metric:emoval; train:0.9038; eval:0.4617; lr:0.000250
epoch:27; metric:emoval; train:0.9285; eval:0.4805; lr:0.000250
epoch:28; metric:emoval; train:0.9411; eval:0.4696; lr:0.000250
epoch:29; metric:emoval; train:0.9439; eval:0.4746; lr:0.000250
epoch:30; metric:emoval; train:0.9407; eval:0.4738; lr:0.000250
epoch:31; metric:emoval; train:0.9377; eval:0.4930; lr:0.000250
epoch:32; metric:emoval; train:0.9302; eval:0.4854; lr:0.000250
epoch:33; metric:emoval; train:0.9297; eval:0.4696; lr:0.000250
epoch:34; metric:emoval; train:0.9285; eval:0.4739; lr:0.000250
epoch:35; metric:emoval; train:0.9284; eval:0.4880; lr:0.000250
epoch:36; metric:emoval; train:0.9198; eval:0.4675; lr:0.000250
epoch:37; metric:emoval; train:0.9176; eval:0.4418; lr:0.000125
epoch:38; metric:emoval; train:0.9163; eval:0.4842; lr:0.000125
epoch:39; metric:emoval; train:0.9203; eval:0.4774; lr:0.000125
epoch:40; metric:emoval; train:0.9204; eval:0.4914; lr:0.000125
epoch:41; metric:emoval; train:0.9105; eval:0.4601; lr:0.000125
epoch:42; metric:emoval; train:0.9303; eval:0.4584; lr:0.000125
epoch:43; metric:emoval; train:0.9129; eval:0.4725; lr:0.000125
epoch:44; metric:emoval; train:0.9156; eval:0.4257; lr:0.000125
epoch:45; metric:emoval; train:0.9175; eval:0.4526; lr:0.000125
Early stopping at epoch 45, best epoch: 15
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1-th folder, best_index: 14, duration: 2603.405003786087 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.4062; eval:0.3426; lr:0.000500
epoch:2; metric:emoval; train:0.3068; eval:0.4622; lr:0.000500
epoch:3; metric:emoval; train:0.5125; eval:0.5190; lr:0.000500
epoch:4; metric:emoval; train:0.5937; eval:0.5060; lr:0.000500
epoch:5; metric:emoval; train:0.6591; eval:0.5590; lr:0.000500
epoch:6; metric:emoval; train:0.7293; eval:0.5348; lr:0.000500
epoch:7; metric:emoval; train:0.7783; eval:0.5372; lr:0.000500
epoch:8; metric:emoval; train:0.7863; eval:0.5535; lr:0.000500
epoch:9; metric:emoval; train:0.8318; eval:0.5293; lr:0.000500
epoch:10; metric:emoval; train:0.8350; eval:0.5475; lr:0.000500
epoch:11; metric:emoval; train:0.8795; eval:0.5468; lr:0.000500
epoch:12; metric:emoval; train:0.8758; eval:0.5012; lr:0.000500
epoch:13; metric:emoval; train:0.8810; eval:0.5126; lr:0.000500
epoch:14; metric:emoval; train:0.8533; eval:0.5178; lr:0.000500
epoch:15; metric:emoval; train:0.8887; eval:0.5342; lr:0.000500
epoch:16; metric:emoval; train:0.8962; eval:0.5354; lr:0.000250
epoch:17; metric:emoval; train:0.9404; eval:0.5313; lr:0.000250
epoch:18; metric:emoval; train:0.9494; eval:0.5383; lr:0.000250
epoch:19; metric:emoval; train:0.9515; eval:0.5172; lr:0.000250
epoch:20; metric:emoval; train:0.9555; eval:0.5322; lr:0.000250
epoch:21; metric:emoval; train:0.9584; eval:0.5269; lr:0.000250
epoch:22; metric:emoval; train:0.9569; eval:0.5086; lr:0.000250
epoch:23; metric:emoval; train:0.9469; eval:0.5326; lr:0.000250
epoch:24; metric:emoval; train:0.9432; eval:0.5122; lr:0.000250
epoch:25; metric:emoval; train:0.9421; eval:0.5028; lr:0.000250
epoch:26; metric:emoval; train:0.9433; eval:0.5180; lr:0.000250
epoch:27; metric:emoval; train:0.9375; eval:0.5130; lr:0.000125
epoch:28; metric:emoval; train:0.9358; eval:0.5041; lr:0.000125
epoch:29; metric:emoval; train:0.9422; eval:0.4940; lr:0.000125
epoch:30; metric:emoval; train:0.9457; eval:0.5095; lr:0.000125
epoch:31; metric:emoval; train:0.9463; eval:0.5108; lr:0.000125
epoch:32; metric:emoval; train:0.9277; eval:0.5160; lr:0.000125
epoch:33; metric:emoval; train:0.9303; eval:0.5049; lr:0.000125
epoch:34; metric:emoval; train:0.9250; eval:0.4935; lr:0.000125
epoch:35; metric:emoval; train:0.9249; eval:0.5163; lr:0.000125
Early stopping at epoch 35, best epoch: 5
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2-th folder, best_index: 4, duration: 1973.1924765110016 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.5228; eval:0.2629; lr:0.000500
epoch:2; metric:emoval; train:0.3227; eval:0.4613; lr:0.000500
epoch:3; metric:emoval; train:0.5122; eval:0.4911; lr:0.000500
epoch:4; metric:emoval; train:0.6150; eval:0.5240; lr:0.000500
epoch:5; metric:emoval; train:0.6812; eval:0.5287; lr:0.000500
epoch:6; metric:emoval; train:0.7358; eval:0.5494; lr:0.000500
epoch:7; metric:emoval; train:0.7943; eval:0.5036; lr:0.000500
epoch:8; metric:emoval; train:0.7958; eval:0.5015; lr:0.000500
epoch:9; metric:emoval; train:0.8355; eval:0.4897; lr:0.000500
epoch:10; metric:emoval; train:0.8339; eval:0.4506; lr:0.000500
epoch:11; metric:emoval; train:0.8440; eval:0.5218; lr:0.000500
epoch:12; metric:emoval; train:0.8853; eval:0.5251; lr:0.000500
epoch:13; metric:emoval; train:0.8814; eval:0.5446; lr:0.000500
epoch:14; metric:emoval; train:0.8980; eval:0.5034; lr:0.000500
epoch:15; metric:emoval; train:0.8726; eval:0.5045; lr:0.000500
epoch:16; metric:emoval; train:0.9025; eval:0.4424; lr:0.000500
epoch:17; metric:emoval; train:0.9072; eval:0.5177; lr:0.000250
epoch:18; metric:emoval; train:0.9392; eval:0.5381; lr:0.000250
epoch:19; metric:emoval; train:0.9539; eval:0.5329; lr:0.000250
epoch:20; metric:emoval; train:0.9577; eval:0.5248; lr:0.000250
epoch:21; metric:emoval; train:0.9622; eval:0.5057; lr:0.000250
epoch:22; metric:emoval; train:0.9539; eval:0.4968; lr:0.000250
epoch:23; metric:emoval; train:0.9506; eval:0.4999; lr:0.000250
epoch:24; metric:emoval; train:0.9405; eval:0.4939; lr:0.000250
epoch:25; metric:emoval; train:0.9517; eval:0.5034; lr:0.000250
epoch:26; metric:emoval; train:0.9413; eval:0.4978; lr:0.000250
epoch:27; metric:emoval; train:0.9353; eval:0.5000; lr:0.000250
epoch:28; metric:emoval; train:0.9319; eval:0.4995; lr:0.000125
epoch:29; metric:emoval; train:0.9408; eval:0.5129; lr:0.000125
epoch:30; metric:emoval; train:0.9447; eval:0.4993; lr:0.000125
epoch:31; metric:emoval; train:0.9330; eval:0.5103; lr:0.000125
epoch:32; metric:emoval; train:0.9322; eval:0.5022; lr:0.000125
epoch:33; metric:emoval; train:0.9320; eval:0.5053; lr:0.000125
epoch:34; metric:emoval; train:0.9273; eval:0.5187; lr:0.000125
epoch:35; metric:emoval; train:0.9297; eval:0.4972; lr:0.000125
epoch:36; metric:emoval; train:0.9191; eval:0.5228; lr:0.000125
Early stopping at epoch 36, best epoch: 6
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3-th folder, best_index: 5, duration: 2001.9058454036713 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.2254; eval:0.3779; lr:0.000500
epoch:2; metric:emoval; train:0.3472; eval:0.5005; lr:0.000500
epoch:3; metric:emoval; train:0.5273; eval:0.5523; lr:0.000500
epoch:4; metric:emoval; train:0.6381; eval:0.4791; lr:0.000500
epoch:5; metric:emoval; train:0.6745; eval:0.5444; lr:0.000500
epoch:6; metric:emoval; train:0.7239; eval:0.5668; lr:0.000500
epoch:7; metric:emoval; train:0.7641; eval:0.5595; lr:0.000500
epoch:8; metric:emoval; train:0.7918; eval:0.5689; lr:0.000500
epoch:9; metric:emoval; train:0.8305; eval:0.5432; lr:0.000500
epoch:10; metric:emoval; train:0.8405; eval:0.4568; lr:0.000500
epoch:11; metric:emoval; train:0.8428; eval:0.5004; lr:0.000500
epoch:12; metric:emoval; train:0.8682; eval:0.5309; lr:0.000500
epoch:13; metric:emoval; train:0.8795; eval:0.5228; lr:0.000500
epoch:14; metric:emoval; train:0.9008; eval:0.5260; lr:0.000500
epoch:15; metric:emoval; train:0.9170; eval:0.5196; lr:0.000500
epoch:16; metric:emoval; train:0.8932; eval:0.5578; lr:0.000500
epoch:17; metric:emoval; train:0.8970; eval:0.5178; lr:0.000500
epoch:18; metric:emoval; train:0.9179; eval:0.4730; lr:0.000500
epoch:19; metric:emoval; train:0.9195; eval:0.5225; lr:0.000250
epoch:20; metric:emoval; train:0.9488; eval:0.5389; lr:0.000250
epoch:21; metric:emoval; train:0.9612; eval:0.5404; lr:0.000250
epoch:22; metric:emoval; train:0.9614; eval:0.5114; lr:0.000250
epoch:23; metric:emoval; train:0.9575; eval:0.5437; lr:0.000250
epoch:24; metric:emoval; train:0.9567; eval:0.5140; lr:0.000250
epoch:25; metric:emoval; train:0.9463; eval:0.5313; lr:0.000250
epoch:26; metric:emoval; train:0.9393; eval:0.5078; lr:0.000250
epoch:27; metric:emoval; train:0.9432; eval:0.5465; lr:0.000250
epoch:28; metric:emoval; train:0.9371; eval:0.5396; lr:0.000250
epoch:29; metric:emoval; train:0.9224; eval:0.5362; lr:0.000250
epoch:30; metric:emoval; train:0.9290; eval:0.5141; lr:0.000125
epoch:31; metric:emoval; train:0.9345; eval:0.5243; lr:0.000125
epoch:32; metric:emoval; train:0.9348; eval:0.5244; lr:0.000125
epoch:33; metric:emoval; train:0.9413; eval:0.5392; lr:0.000125
epoch:34; metric:emoval; train:0.9291; eval:0.5021; lr:0.000125
epoch:35; metric:emoval; train:0.9308; eval:0.5322; lr:0.000125
epoch:36; metric:emoval; train:0.9247; eval:0.5128; lr:0.000125
epoch:37; metric:emoval; train:0.9364; eval:0.5164; lr:0.000125
epoch:38; metric:emoval; train:0.9242; eval:0.5313; lr:0.000125
Early stopping at epoch 38, best epoch: 8
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4-th folder, best_index: 7, duration: 2101.306788444519 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.1844; eval:0.1343; lr:0.000500
epoch:2; metric:emoval; train:0.3500; eval:0.4684; lr:0.000500
epoch:3; metric:emoval; train:0.5317; eval:0.5161; lr:0.000500
epoch:4; metric:emoval; train:0.6267; eval:0.5590; lr:0.000500
epoch:5; metric:emoval; train:0.6833; eval:0.5067; lr:0.000500
epoch:6; metric:emoval; train:0.7387; eval:0.4782; lr:0.000500
epoch:7; metric:emoval; train:0.7738; eval:0.5389; lr:0.000500
epoch:8; metric:emoval; train:0.7935; eval:0.5465; lr:0.000500
epoch:9; metric:emoval; train:0.8125; eval:0.5169; lr:0.000500
epoch:10; metric:emoval; train:0.8365; eval:0.5146; lr:0.000500
epoch:11; metric:emoval; train:0.8679; eval:0.5095; lr:0.000500
epoch:12; metric:emoval; train:0.8639; eval:0.5018; lr:0.000500
epoch:13; metric:emoval; train:0.8806; eval:0.5226; lr:0.000500
epoch:14; metric:emoval; train:0.8842; eval:0.5129; lr:0.000500
epoch:15; metric:emoval; train:0.8978; eval:0.5563; lr:0.000250
epoch:16; metric:emoval; train:0.9332; eval:0.5343; lr:0.000250
epoch:17; metric:emoval; train:0.9425; eval:0.5351; lr:0.000250
epoch:18; metric:emoval; train:0.9397; eval:0.5081; lr:0.000250
epoch:19; metric:emoval; train:0.9535; eval:0.5179; lr:0.000250
epoch:20; metric:emoval; train:0.9556; eval:0.5070; lr:0.000250
epoch:21; metric:emoval; train:0.9581; eval:0.5117; lr:0.000250
epoch:22; metric:emoval; train:0.9565; eval:0.5223; lr:0.000250
epoch:23; metric:emoval; train:0.9541; eval:0.4884; lr:0.000250
epoch:24; metric:emoval; train:0.9511; eval:0.4693; lr:0.000250
epoch:25; metric:emoval; train:0.9468; eval:0.4084; lr:0.000250
epoch:26; metric:emoval; train:0.9442; eval:0.4762; lr:0.000125
epoch:27; metric:emoval; train:0.9377; eval:0.4838; lr:0.000125
epoch:28; metric:emoval; train:0.9455; eval:0.4841; lr:0.000125
epoch:29; metric:emoval; train:0.9341; eval:0.4930; lr:0.000125
epoch:30; metric:emoval; train:0.9467; eval:0.5022; lr:0.000125
epoch:31; metric:emoval; train:0.9361; eval:0.4794; lr:0.000125
epoch:32; metric:emoval; train:0.9332; eval:0.4879; lr:0.000125
epoch:33; metric:emoval; train:0.9351; eval:0.4630; lr:0.000125
epoch:34; metric:emoval; train:0.9369; eval:0.4621; lr:0.000125
Early stopping at epoch 34, best epoch: 4
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5-th folder, best_index: 3, duration: 1700.7974245548248 >>>>>
====== Prediction and Saving =======
save results in ./saved-trimodal/result/cv_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7367_acc:0.7400_val:0.7426_1770133317.70303.npz
save results in ./saved-trimodal/result/test1_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8062_acc:0.8078_val:0.6833_1770133317.70303.npz
save results in ./saved-trimodal/result/test2_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7583_acc:0.7621_val:0.6717_1770133317.70303.npz
save results in ./saved-trimodal/result/test3_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8939_acc:0.8993_val:77.9402_1770133317.70303.npz
