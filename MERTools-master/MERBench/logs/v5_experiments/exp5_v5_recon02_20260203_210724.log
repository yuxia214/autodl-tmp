====== Params Pre-analysis =======
args:  Namespace(audio_feature='chinese-hubert-large-UTT', batch_size=32, contrastive_temperature=0.07, contrastive_weight=0.1, cross_kl_weight=0.01, dataset='MER2023', debug=False, dropout=0.35, e2e_dim=None, e2e_name=None, early_stopping_patience=30, epochs=100, feat_scale=1, feat_type='utt', focal_gamma=2.0, fusion_temperature=1.0, gate_alpha=0.5, gpu=0, grad_clip=1.0, hidden_dim=128, hyper_path=None, kl_warmup_epochs=20, kl_weight=0.01, l2=5e-05, label_smoothing=0.1, lr=0.0005, lr_adjust='case1', lr_factor=0.5, lr_patience=10, mixup_alpha=0.4, modality_dropout=0.15, modality_dropout_warmup=20, model='attention_robust_v5', n_classes=None, num_attention_heads=4, num_workers=0, print_iters=100000000.0, recon_weight=0.2, save_iters=100000000.0, save_root='./saved-trimodal', savemodel=False, test_dataset=None, text_feature='Baichuan-13B-Base-UTT', train_dataset=None, use_contrastive=True, use_dynamic_kl=True, use_gated_fusion=True, use_mixup=False, use_modality_dropout=True, use_proxy_attention=True, use_vae=True, video_feature='clip-vit-large-patch14-UTT')
====== Reading Data =======
train: sample number 3373
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/3373 [00:00<?, ?it/s] 11%|█         | 367/3373 [00:00<00:00, 3655.93it/s] 22%|██▏       | 733/3373 [00:00<00:00, 3639.94it/s] 33%|███▎      | 1097/3373 [00:00<00:00, 2512.09it/s] 41%|████▏     | 1397/3373 [00:00<00:00, 2662.96it/s] 50%|████▉     | 1686/3373 [00:00<00:00, 2723.39it/s] 59%|█████▊    | 1974/3373 [00:00<00:00, 2688.78it/s] 67%|██████▋   | 2253/3373 [00:00<00:00, 2213.91it/s] 74%|███████▍  | 2508/3373 [00:00<00:00, 2298.43it/s] 82%|████████▏ | 2753/3373 [00:01<00:00, 2243.58it/s] 89%|████████▊ | 2987/3373 [00:01<00:00, 2267.36it/s] 95%|█████████▌| 3221/3373 [00:01<00:00, 1824.95it/s]100%|██████████| 3373/3373 [00:01<00:00, 2399.36it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▋         | 217/3373 [00:00<00:01, 2165.59it/s] 13%|█▎        | 434/3373 [00:00<00:01, 2119.36it/s] 19%|█▉        | 647/3373 [00:00<00:01, 2053.23it/s] 25%|██▌       | 853/3373 [00:00<00:01, 2007.64it/s] 31%|███       | 1054/3373 [00:00<00:01, 1568.66it/s] 39%|███▉      | 1317/3373 [00:00<00:01, 1859.57it/s] 45%|████▍     | 1517/3373 [00:00<00:01, 1850.65it/s] 51%|█████     | 1712/3373 [00:00<00:00, 1878.65it/s] 57%|█████▋    | 1907/3373 [00:01<00:00, 1511.89it/s] 61%|██████▏   | 2073/3373 [00:01<00:00, 1497.53it/s] 66%|██████▌   | 2233/3373 [00:01<00:00, 1499.31it/s] 71%|███████   | 2390/3373 [00:01<00:00, 1482.70it/s] 75%|███████▌  | 2543/3373 [00:01<00:00, 1238.94it/s] 80%|███████▉  | 2688/3373 [00:01<00:00, 1286.95it/s] 84%|████████▍ | 2825/3373 [00:01<00:00, 1306.26it/s] 88%|████████▊ | 2969/3373 [00:01<00:00, 1341.29it/s] 93%|█████████▎| 3128/3373 [00:02<00:00, 1409.73it/s] 99%|█████████▊| 3328/3373 [00:02<00:00, 1575.65it/s]100%|██████████| 3373/3373 [00:02<00:00, 1598.29it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 298/3373 [00:00<00:01, 2955.82it/s] 18%|█▊        | 594/3373 [00:00<00:00, 2907.80it/s] 26%|██▌       | 885/3373 [00:00<00:00, 2875.79it/s] 35%|███▌      | 1195/3373 [00:00<00:00, 2961.88it/s] 44%|████▍     | 1492/3373 [00:00<00:00, 2945.35it/s] 53%|█████▎    | 1787/3373 [00:00<00:00, 2274.69it/s] 60%|██████    | 2035/3373 [00:00<00:00, 2322.96it/s] 69%|██████▊   | 2313/3373 [00:00<00:00, 2449.30it/s] 76%|███████▋  | 2579/3373 [00:01<00:00, 2488.82it/s] 85%|████████▌ | 2880/3373 [00:01<00:00, 2638.10it/s] 95%|█████████▍| 3199/3373 [00:01<00:00, 2792.22it/s]100%|██████████| 3373/3373 [00:01<00:00, 2774.38it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test1: sample number 411
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/411 [00:00<?, ?it/s] 71%|███████   | 290/411 [00:00<00:00, 2782.19it/s]100%|██████████| 411/411 [00:00<00:00, 2256.49it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/411 [00:00<?, ?it/s] 62%|██████▏   | 253/411 [00:00<00:00, 2514.45it/s]100%|██████████| 411/411 [00:00<00:00, 2160.13it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/411 [00:00<?, ?it/s] 57%|█████▋    | 235/411 [00:00<00:00, 2348.37it/s]100%|██████████| 411/411 [00:00<00:00, 2183.08it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test2: sample number 412
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/412 [00:00<?, ?it/s] 43%|████▎     | 176/412 [00:00<00:00, 1753.60it/s]100%|██████████| 412/412 [00:00<00:00, 2073.42it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/412 [00:00<?, ?it/s] 64%|██████▎   | 262/412 [00:00<00:00, 1557.81it/s]100%|██████████| 412/412 [00:00<00:00, 2238.91it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/412 [00:00<?, ?it/s]100%|██████████| 412/412 [00:00<00:00, 4270.17it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test3: sample number 834
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/834 [00:00<?, ?it/s] 34%|███▍      | 287/834 [00:00<00:00, 2869.72it/s] 73%|███████▎  | 605/834 [00:00<00:00, 3049.86it/s]100%|██████████| 834/834 [00:00<00:00, 3857.81it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/834 [00:00<?, ?it/s] 24%|██▍       | 200/834 [00:00<00:00, 1995.98it/s] 49%|████▉     | 412/834 [00:00<00:00, 2068.70it/s] 87%|████████▋ | 728/834 [00:00<00:00, 2562.43it/s]100%|██████████| 834/834 [00:00<00:00, 2217.35it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/834 [00:00<?, ?it/s] 57%|█████▋    | 479/834 [00:00<00:00, 4787.94it/s]100%|██████████| 834/834 [00:00<00:00, 6419.33it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
train&val folder:5; test sets:3
audio dimension: 1024; text dimension: 5120; video dimension: 768
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.6083; eval:-0.1868; lr:0.000500
epoch:2; metric:emoval; train:-0.0813; eval:0.1656; lr:0.000500
epoch:3; metric:emoval; train:0.3034; eval:0.2878; lr:0.000500
epoch:4; metric:emoval; train:0.4690; eval:0.4882; lr:0.000500
epoch:5; metric:emoval; train:0.5612; eval:0.4977; lr:0.000500
epoch:6; metric:emoval; train:0.6343; eval:0.4992; lr:0.000500
epoch:7; metric:emoval; train:0.6734; eval:0.5421; lr:0.000500
epoch:8; metric:emoval; train:0.7372; eval:0.5459; lr:0.000500
epoch:9; metric:emoval; train:0.7564; eval:0.5634; lr:0.000500
epoch:10; metric:emoval; train:0.8011; eval:0.5419; lr:0.000500
epoch:11; metric:emoval; train:0.8036; eval:0.5545; lr:0.000500
epoch:12; metric:emoval; train:0.8018; eval:0.5399; lr:0.000500
epoch:13; metric:emoval; train:0.8338; eval:0.5070; lr:0.000500
epoch:14; metric:emoval; train:0.8357; eval:0.5199; lr:0.000500
epoch:15; metric:emoval; train:0.8505; eval:0.4934; lr:0.000500
epoch:16; metric:emoval; train:0.8554; eval:0.5104; lr:0.000500
epoch:17; metric:emoval; train:0.8776; eval:0.4949; lr:0.000500
epoch:18; metric:emoval; train:0.8478; eval:0.4836; lr:0.000500
epoch:19; metric:emoval; train:0.8700; eval:0.5297; lr:0.000500
epoch:20; metric:emoval; train:0.8726; eval:0.4509; lr:0.000250
epoch:21; metric:emoval; train:0.9207; eval:0.5186; lr:0.000250
epoch:22; metric:emoval; train:0.9378; eval:0.5288; lr:0.000250
epoch:23; metric:emoval; train:0.9339; eval:0.5086; lr:0.000250
epoch:24; metric:emoval; train:0.9324; eval:0.5191; lr:0.000250
epoch:25; metric:emoval; train:0.9361; eval:0.5047; lr:0.000250
epoch:26; metric:emoval; train:0.9131; eval:0.5386; lr:0.000250
epoch:27; metric:emoval; train:0.9079; eval:0.5239; lr:0.000250
epoch:28; metric:emoval; train:0.9085; eval:0.4954; lr:0.000250
epoch:29; metric:emoval; train:0.9024; eval:0.5131; lr:0.000250
epoch:30; metric:emoval; train:0.9179; eval:0.5090; lr:0.000250
epoch:31; metric:emoval; train:0.9096; eval:0.4526; lr:0.000125
epoch:32; metric:emoval; train:0.9253; eval:0.5316; lr:0.000125
epoch:33; metric:emoval; train:0.9264; eval:0.5443; lr:0.000125
epoch:34; metric:emoval; train:0.9284; eval:0.5148; lr:0.000125
epoch:35; metric:emoval; train:0.9273; eval:0.5142; lr:0.000125
epoch:36; metric:emoval; train:0.9123; eval:0.5218; lr:0.000125
epoch:37; metric:emoval; train:0.9141; eval:0.5216; lr:0.000125
epoch:38; metric:emoval; train:0.9162; eval:0.5087; lr:0.000125
epoch:39; metric:emoval; train:0.9145; eval:0.5351; lr:0.000125
Early stopping at epoch 39, best epoch: 9
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1-th folder, best_index: 8, duration: 829.6962695121765 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.4068; eval:-0.3862; lr:0.000500
epoch:2; metric:emoval; train:0.0068; eval:0.2324; lr:0.000500
epoch:3; metric:emoval; train:0.3423; eval:0.4313; lr:0.000500
epoch:4; metric:emoval; train:0.5020; eval:0.4817; lr:0.000500
epoch:5; metric:emoval; train:0.5756; eval:0.4946; lr:0.000500
epoch:6; metric:emoval; train:0.6402; eval:0.4887; lr:0.000500
epoch:7; metric:emoval; train:0.7070; eval:0.5463; lr:0.000500
epoch:8; metric:emoval; train:0.7393; eval:0.5233; lr:0.000500
epoch:9; metric:emoval; train:0.7623; eval:0.5373; lr:0.000500
epoch:10; metric:emoval; train:0.7776; eval:0.4787; lr:0.000500
epoch:11; metric:emoval; train:0.7862; eval:0.5412; lr:0.000500
epoch:12; metric:emoval; train:0.8299; eval:0.4869; lr:0.000500
epoch:13; metric:emoval; train:0.8425; eval:0.4919; lr:0.000500
epoch:14; metric:emoval; train:0.8316; eval:0.5100; lr:0.000500
epoch:15; metric:emoval; train:0.8528; eval:0.5094; lr:0.000500
epoch:16; metric:emoval; train:0.8796; eval:0.5183; lr:0.000500
epoch:17; metric:emoval; train:0.8780; eval:0.5252; lr:0.000500
epoch:18; metric:emoval; train:0.8846; eval:0.5386; lr:0.000250
epoch:19; metric:emoval; train:0.9248; eval:0.5457; lr:0.000250
epoch:20; metric:emoval; train:0.9448; eval:0.5272; lr:0.000250
epoch:21; metric:emoval; train:0.9435; eval:0.5449; lr:0.000250
epoch:22; metric:emoval; train:0.9380; eval:0.5522; lr:0.000250
epoch:23; metric:emoval; train:0.9423; eval:0.5403; lr:0.000250
epoch:24; metric:emoval; train:0.9306; eval:0.5124; lr:0.000250
epoch:25; metric:emoval; train:0.8994; eval:0.5212; lr:0.000250
epoch:26; metric:emoval; train:0.8883; eval:0.5132; lr:0.000250
