====== Params Pre-analysis =======
args:  Namespace(audio_feature='chinese-hubert-large-UTT', batch_size=32, contrastive_temperature=0.07, contrastive_weight=0.1, cross_kl_weight=0.01, dataset='MER2023', debug=False, dropout=0.35, e2e_dim=None, e2e_name=None, early_stopping_patience=30, epochs=100, feat_scale=1, feat_type='utt', focal_gamma=2.0, fusion_temperature=1.0, gate_alpha=0.5, gpu=0, grad_clip=1.0, hidden_dim=128, hyper_path=None, kl_warmup_epochs=20, kl_weight=0.01, l2=0.0001, label_smoothing=0.1, lr=0.0005, lr_adjust='case1', lr_factor=0.5, lr_patience=10, mixup_alpha=0.4, modality_dropout=0.15, modality_dropout_warmup=20, model='attention_robust_v5', n_classes=None, num_attention_heads=4, num_workers=0, print_iters=100000000.0, recon_weight=0.1, save_iters=100000000.0, save_root='./saved-trimodal', savemodel=False, test_dataset=None, text_feature='Baichuan-13B-Base-UTT', train_dataset=None, use_contrastive=True, use_dynamic_kl=True, use_gated_fusion=True, use_mixup=False, use_modality_dropout=True, use_proxy_attention=True, use_vae=True, video_feature='clip-vit-large-patch14-UTT')
====== Reading Data =======
train: sample number 3373
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/3373 [00:00<?, ?it/s]  6%|▌         | 187/3373 [00:00<00:01, 1859.70it/s] 11%|█         | 373/3373 [00:00<00:02, 1202.35it/s] 15%|█▌        | 507/3373 [00:00<00:02, 1240.40it/s] 19%|█▉        | 640/3373 [00:00<00:02, 1252.99it/s] 23%|██▎       | 787/3373 [00:00<00:01, 1318.46it/s] 27%|██▋       | 923/3373 [00:00<00:01, 1324.72it/s] 31%|███▏      | 1059/3373 [00:00<00:01, 1329.09it/s] 36%|███▌      | 1200/3373 [00:00<00:01, 1352.66it/s] 40%|███▉      | 1345/3373 [00:01<00:01, 1378.55it/s] 45%|████▍     | 1505/3373 [00:01<00:01, 1443.25it/s] 49%|████▉     | 1651/3373 [00:01<00:01, 1144.14it/s] 53%|█████▎    | 1776/3373 [00:01<00:01, 1155.69it/s] 58%|█████▊    | 1944/3373 [00:01<00:01, 1293.07it/s] 63%|██████▎   | 2140/3373 [00:01<00:00, 1473.50it/s] 68%|██████▊   | 2295/3373 [00:01<00:00, 1489.10it/s] 73%|███████▎  | 2449/3373 [00:01<00:00, 1493.49it/s] 77%|███████▋  | 2602/3373 [00:01<00:00, 1197.16it/s] 81%|████████  | 2734/3373 [00:02<00:00, 1219.56it/s] 86%|████████▌ | 2899/3373 [00:02<00:00, 1330.61it/s] 90%|█████████ | 3051/3373 [00:02<00:00, 1381.07it/s] 95%|█████████▍| 3196/3373 [00:02<00:00, 1382.35it/s]100%|██████████| 3373/3373 [00:02<00:00, 1349.54it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/3373 [00:00<?, ?it/s]  2%|▏         | 69/3373 [00:00<00:04, 688.43it/s]  4%|▍         | 142/3373 [00:00<00:04, 711.14it/s]  8%|▊         | 261/3373 [00:00<00:03, 923.71it/s] 11%|█▏        | 380/3373 [00:00<00:02, 1028.15it/s] 14%|█▍        | 483/3373 [00:00<00:02, 1021.25it/s] 19%|█▉        | 634/3373 [00:00<00:02, 1185.63it/s] 22%|██▏       | 753/3373 [00:00<00:02, 1172.41it/s] 26%|██▌       | 874/3373 [00:00<00:02, 1184.00it/s] 30%|██▉       | 1009/3373 [00:00<00:01, 1235.28it/s] 35%|███▍      | 1173/3373 [00:01<00:01, 1355.29it/s] 40%|███▉      | 1341/3373 [00:01<00:01, 1453.28it/s] 44%|████▍     | 1487/3373 [00:01<00:01, 1150.91it/s] 48%|████▊     | 1612/3373 [00:01<00:01, 1160.08it/s] 51%|█████▏    | 1735/3373 [00:01<00:01, 949.11it/s]  55%|█████▍    | 1841/3373 [00:01<00:01, 964.47it/s] 58%|█████▊    | 1946/3373 [00:01<00:01, 982.95it/s] 61%|██████▏   | 2067/3373 [00:01<00:01, 1041.87it/s] 65%|██████▍   | 2177/3373 [00:02<00:01, 1048.73it/s] 68%|██████▊   | 2301/3373 [00:02<00:00, 1101.35it/s] 72%|███████▏  | 2437/3373 [00:02<00:00, 1172.13it/s] 76%|███████▌  | 2557/3373 [00:02<00:00, 1177.75it/s] 80%|████████  | 2711/3373 [00:02<00:00, 1282.67it/s] 85%|████████▍ | 2856/3373 [00:02<00:00, 1329.64it/s] 89%|████████▊ | 2991/3373 [00:02<00:00, 1331.83it/s] 93%|█████████▎| 3141/3373 [00:02<00:00, 1100.68it/s] 99%|█████████▉| 3334/3373 [00:02<00:00, 1309.59it/s]100%|██████████| 3373/3373 [00:02<00:00, 1163.59it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/3373 [00:00<?, ?it/s]  3%|▎         | 105/3373 [00:00<00:03, 1041.70it/s]  9%|▊         | 292/3373 [00:00<00:02, 1522.94it/s] 13%|█▎        | 445/3373 [00:00<00:01, 1506.82it/s] 19%|█▊        | 631/3373 [00:00<00:01, 1643.60it/s] 24%|██▎       | 796/3373 [00:00<00:01, 1617.37it/s] 30%|██▉       | 1003/3373 [00:00<00:01, 1371.94it/s] 34%|███▍      | 1148/3373 [00:00<00:01, 1369.14it/s] 38%|███▊      | 1290/3373 [00:00<00:01, 1359.63it/s] 42%|████▏     | 1430/3373 [00:01<00:01, 1091.45it/s] 46%|████▌     | 1557/3373 [00:01<00:01, 1129.48it/s] 50%|█████     | 1703/3373 [00:01<00:01, 1202.34it/s] 59%|█████▉    | 1986/3373 [00:01<00:00, 1626.17it/s] 65%|██████▍   | 2187/3373 [00:01<00:00, 1729.17it/s] 71%|███████   | 2402/3373 [00:01<00:00, 1846.91it/s] 79%|███████▉  | 2661/3373 [00:01<00:00, 2054.69it/s] 86%|████████▌ | 2901/3373 [00:01<00:00, 2154.42it/s] 93%|█████████▎| 3121/3373 [00:01<00:00, 2165.50it/s]100%|██████████| 3373/3373 [00:02<00:00, 1685.12it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test1: sample number 411
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/411 [00:00<?, ?it/s] 44%|████▎     | 179/411 [00:00<00:00, 1786.28it/s]100%|██████████| 411/411 [00:00<00:00, 2129.06it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/411 [00:00<?, ?it/s] 35%|███▌      | 145/411 [00:00<00:00, 1448.30it/s] 77%|███████▋  | 317/411 [00:00<00:00, 1607.33it/s]100%|██████████| 411/411 [00:00<00:00, 1918.20it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/411 [00:00<?, ?it/s] 68%|██████▊   | 278/411 [00:00<00:00, 2744.41it/s]100%|██████████| 411/411 [00:00<00:00, 3830.08it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test2: sample number 412
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/412 [00:00<?, ?it/s] 54%|█████▍    | 223/412 [00:00<00:00, 2210.90it/s]100%|██████████| 412/412 [00:00<00:00, 2109.60it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/412 [00:00<?, ?it/s] 36%|███▋      | 150/412 [00:00<00:00, 1496.45it/s]100%|██████████| 412/412 [00:00<00:00, 3396.56it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/412 [00:00<?, ?it/s] 50%|█████     | 208/412 [00:00<00:00, 2075.01it/s]100%|██████████| 412/412 [00:00<00:00, 2132.69it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test3: sample number 834
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/834 [00:00<?, ?it/s]  6%|▌         | 50/834 [00:00<00:01, 498.41it/s] 19%|█▊        | 155/834 [00:00<00:00, 821.95it/s] 29%|██▊       | 238/834 [00:00<00:01, 571.73it/s] 61%|██████    | 509/834 [00:00<00:00, 1235.61it/s] 80%|████████  | 671/834 [00:00<00:00, 1349.67it/s]100%|██████████| 834/834 [00:00<00:00, 1363.48it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/834 [00:00<?, ?it/s]  5%|▌         | 42/834 [00:00<00:01, 418.77it/s] 22%|██▏       | 183/834 [00:00<00:00, 998.14it/s] 35%|███▌      | 296/834 [00:00<00:00, 1057.13it/s] 48%|████▊     | 402/834 [00:00<00:00, 1048.17it/s] 65%|██████▍   | 538/834 [00:00<00:00, 1158.58it/s] 81%|████████  | 676/834 [00:00<00:00, 1232.62it/s] 96%|█████████▌| 800/834 [00:00<00:00, 1217.93it/s]100%|██████████| 834/834 [00:00<00:00, 1049.84it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/834 [00:00<?, ?it/s] 18%|█▊        | 148/834 [00:00<00:00, 1478.31it/s] 48%|████▊     | 402/834 [00:00<00:00, 2098.98it/s] 77%|███████▋  | 641/834 [00:00<00:00, 2222.28it/s]100%|██████████| 834/834 [00:00<00:00, 2655.94it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
train&val folder:5; test sets:3
audio dimension: 1024; text dimension: 5120; video dimension: 768
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.2719; eval:0.0981; lr:0.000500
epoch:2; metric:emoval; train:0.1414; eval:0.3627; lr:0.000500
epoch:3; metric:emoval; train:0.3795; eval:0.4803; lr:0.000500
epoch:4; metric:emoval; train:0.5268; eval:0.4591; lr:0.000500
epoch:5; metric:emoval; train:0.6246; eval:0.5064; lr:0.000500
epoch:6; metric:emoval; train:0.6495; eval:0.5296; lr:0.000500
epoch:7; metric:emoval; train:0.6891; eval:0.4934; lr:0.000500
epoch:8; metric:emoval; train:0.7322; eval:0.5482; lr:0.000500
epoch:9; metric:emoval; train:0.7624; eval:0.4615; lr:0.000500
epoch:10; metric:emoval; train:0.7739; eval:0.5198; lr:0.000500
epoch:11; metric:emoval; train:0.7997; eval:0.5467; lr:0.000500
epoch:12; metric:emoval; train:0.8481; eval:0.5357; lr:0.000500
epoch:13; metric:emoval; train:0.8619; eval:0.5557; lr:0.000500
epoch:14; metric:emoval; train:0.8481; eval:0.4165; lr:0.000500
epoch:15; metric:emoval; train:0.8088; eval:0.5265; lr:0.000500
epoch:16; metric:emoval; train:0.8767; eval:0.4833; lr:0.000500
epoch:17; metric:emoval; train:0.8880; eval:0.4250; lr:0.000500
epoch:18; metric:emoval; train:0.8884; eval:0.5206; lr:0.000500
epoch:19; metric:emoval; train:0.8946; eval:0.5223; lr:0.000500
epoch:20; metric:emoval; train:0.8947; eval:0.5272; lr:0.000500
epoch:21; metric:emoval; train:0.8965; eval:0.4768; lr:0.000500
epoch:22; metric:emoval; train:0.8609; eval:0.5005; lr:0.000500
epoch:23; metric:emoval; train:0.8854; eval:0.5078; lr:0.000500
epoch:24; metric:emoval; train:0.9051; eval:0.4933; lr:0.000250
epoch:25; metric:emoval; train:0.9240; eval:0.5239; lr:0.000250
epoch:26; metric:emoval; train:0.9339; eval:0.5303; lr:0.000250
epoch:27; metric:emoval; train:0.9236; eval:0.5341; lr:0.000250
epoch:28; metric:emoval; train:0.9216; eval:0.5309; lr:0.000250
epoch:29; metric:emoval; train:0.9313; eval:0.5409; lr:0.000250
epoch:30; metric:emoval; train:0.9202; eval:0.5093; lr:0.000250
epoch:31; metric:emoval; train:0.9103; eval:0.5338; lr:0.000250
epoch:32; metric:emoval; train:0.9138; eval:0.5070; lr:0.000250
epoch:33; metric:emoval; train:0.8994; eval:0.5192; lr:0.000250
epoch:34; metric:emoval; train:0.9072; eval:0.5343; lr:0.000250
epoch:35; metric:emoval; train:0.9017; eval:0.5371; lr:0.000125
epoch:36; metric:emoval; train:0.9218; eval:0.5418; lr:0.000125
epoch:37; metric:emoval; train:0.9157; eval:0.5431; lr:0.000125
epoch:38; metric:emoval; train:0.9203; eval:0.5231; lr:0.000125
epoch:39; metric:emoval; train:0.9098; eval:0.5419; lr:0.000125
epoch:40; metric:emoval; train:0.9210; eval:0.5420; lr:0.000125
epoch:41; metric:emoval; train:0.9147; eval:0.5246; lr:0.000125
epoch:42; metric:emoval; train:0.9121; eval:0.5463; lr:0.000125
epoch:43; metric:emoval; train:0.9141; eval:0.4993; lr:0.000125
Early stopping at epoch 43, best epoch: 13
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1-th folder, best_index: 12, duration: 2400.2876255512238 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.1452; eval:0.2213; lr:0.000500
epoch:2; metric:emoval; train:0.2769; eval:0.4432; lr:0.000500
epoch:3; metric:emoval; train:0.5023; eval:0.4922; lr:0.000500
epoch:4; metric:emoval; train:0.5732; eval:0.5000; lr:0.000500
epoch:5; metric:emoval; train:0.6551; eval:0.5165; lr:0.000500
epoch:6; metric:emoval; train:0.6673; eval:0.5478; lr:0.000500
epoch:7; metric:emoval; train:0.7357; eval:0.5250; lr:0.000500
epoch:8; metric:emoval; train:0.7580; eval:0.4315; lr:0.000500
epoch:9; metric:emoval; train:0.7840; eval:0.5511; lr:0.000500
epoch:10; metric:emoval; train:0.8242; eval:0.4923; lr:0.000500
epoch:11; metric:emoval; train:0.8279; eval:0.5090; lr:0.000500
epoch:12; metric:emoval; train:0.8324; eval:0.5199; lr:0.000500
epoch:13; metric:emoval; train:0.8511; eval:0.4590; lr:0.000500
epoch:14; metric:emoval; train:0.8512; eval:0.4963; lr:0.000500
epoch:15; metric:emoval; train:0.8840; eval:0.5135; lr:0.000500
epoch:16; metric:emoval; train:0.8679; eval:0.4747; lr:0.000500
epoch:17; metric:emoval; train:0.8937; eval:0.5172; lr:0.000500
epoch:18; metric:emoval; train:0.8904; eval:0.5330; lr:0.000500
epoch:19; metric:emoval; train:0.8767; eval:0.5219; lr:0.000500
epoch:20; metric:emoval; train:0.8834; eval:0.5278; lr:0.000250
epoch:21; metric:emoval; train:0.9341; eval:0.5737; lr:0.000250
epoch:22; metric:emoval; train:0.9473; eval:0.5581; lr:0.000250
epoch:23; metric:emoval; train:0.9444; eval:0.5491; lr:0.000250
epoch:24; metric:emoval; train:0.9423; eval:0.5132; lr:0.000250
epoch:25; metric:emoval; train:0.9403; eval:0.5478; lr:0.000250
epoch:26; metric:emoval; train:0.9373; eval:0.5438; lr:0.000250
epoch:27; metric:emoval; train:0.9363; eval:0.5346; lr:0.000250
epoch:28; metric:emoval; train:0.9324; eval:0.5472; lr:0.000250
epoch:29; metric:emoval; train:0.9240; eval:0.5032; lr:0.000250
epoch:30; metric:emoval; train:0.9104; eval:0.5298; lr:0.000250
epoch:31; metric:emoval; train:0.9071; eval:0.4726; lr:0.000250
epoch:32; metric:emoval; train:0.9100; eval:0.5259; lr:0.000125
epoch:33; metric:emoval; train:0.9301; eval:0.5406; lr:0.000125
epoch:34; metric:emoval; train:0.9283; eval:0.5396; lr:0.000125
epoch:35; metric:emoval; train:0.9174; eval:0.5110; lr:0.000125
epoch:36; metric:emoval; train:0.9242; eval:0.5173; lr:0.000125
epoch:37; metric:emoval; train:0.9136; eval:0.5615; lr:0.000125
epoch:38; metric:emoval; train:0.9124; eval:0.5194; lr:0.000125
epoch:39; metric:emoval; train:0.9216; eval:0.5148; lr:0.000125
epoch:40; metric:emoval; train:0.9160; eval:0.5439; lr:0.000125
epoch:41; metric:emoval; train:0.9146; eval:0.5118; lr:0.000125
epoch:42; metric:emoval; train:0.8943; eval:0.5237; lr:0.000125
epoch:43; metric:emoval; train:0.9158; eval:0.5134; lr:0.000063
epoch:44; metric:emoval; train:0.9243; eval:0.5068; lr:0.000063
epoch:45; metric:emoval; train:0.9307; eval:0.5203; lr:0.000063
epoch:46; metric:emoval; train:0.9286; eval:0.5258; lr:0.000063
epoch:47; metric:emoval; train:0.9323; eval:0.5487; lr:0.000063
epoch:48; metric:emoval; train:0.9226; eval:0.5151; lr:0.000063
epoch:49; metric:emoval; train:0.9231; eval:0.5257; lr:0.000063
epoch:50; metric:emoval; train:0.9364; eval:0.5230; lr:0.000063
epoch:51; metric:emoval; train:0.9331; eval:0.5273; lr:0.000063
Early stopping at epoch 51, best epoch: 21
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2-th folder, best_index: 20, duration: 3151.292459487915 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3271; eval:-0.0743; lr:0.000500
epoch:2; metric:emoval; train:0.1882; eval:0.3714; lr:0.000500
epoch:3; metric:emoval; train:0.4621; eval:0.4882; lr:0.000500
epoch:4; metric:emoval; train:0.5837; eval:0.4935; lr:0.000500
epoch:5; metric:emoval; train:0.6568; eval:0.4956; lr:0.000500
epoch:6; metric:emoval; train:0.6931; eval:0.5425; lr:0.000500
epoch:7; metric:emoval; train:0.7362; eval:0.4726; lr:0.000500
epoch:8; metric:emoval; train:0.7333; eval:0.4088; lr:0.000500
epoch:9; metric:emoval; train:0.7835; eval:0.5147; lr:0.000500
epoch:10; metric:emoval; train:0.7897; eval:0.5677; lr:0.000500
epoch:11; metric:emoval; train:0.8212; eval:0.5314; lr:0.000500
epoch:12; metric:emoval; train:0.8293; eval:0.5096; lr:0.000500
epoch:13; metric:emoval; train:0.8376; eval:0.4719; lr:0.000500
epoch:14; metric:emoval; train:0.8207; eval:0.4931; lr:0.000500
epoch:15; metric:emoval; train:0.8192; eval:0.4882; lr:0.000500
epoch:16; metric:emoval; train:0.8627; eval:0.4781; lr:0.000500
epoch:17; metric:emoval; train:0.8770; eval:0.5177; lr:0.000500
epoch:18; metric:emoval; train:0.8879; eval:0.4795; lr:0.000500
epoch:19; metric:emoval; train:0.8901; eval:0.4983; lr:0.000500
epoch:20; metric:emoval; train:0.8838; eval:0.5258; lr:0.000500
epoch:21; metric:emoval; train:0.8970; eval:0.5150; lr:0.000250
epoch:22; metric:emoval; train:0.9243; eval:0.5061; lr:0.000250
epoch:23; metric:emoval; train:0.9382; eval:0.5008; lr:0.000250
epoch:24; metric:emoval; train:0.9300; eval:0.5328; lr:0.000250
epoch:25; metric:emoval; train:0.9349; eval:0.4741; lr:0.000250
epoch:26; metric:emoval; train:0.9257; eval:0.5055; lr:0.000250
epoch:27; metric:emoval; train:0.9283; eval:0.4581; lr:0.000250
epoch:28; metric:emoval; train:0.9235; eval:0.4761; lr:0.000250
epoch:29; metric:emoval; train:0.9187; eval:0.5011; lr:0.000250
epoch:30; metric:emoval; train:0.9325; eval:0.4987; lr:0.000250
epoch:31; metric:emoval; train:0.9090; eval:0.5058; lr:0.000250
epoch:32; metric:emoval; train:0.9012; eval:0.5242; lr:0.000125
epoch:33; metric:emoval; train:0.9267; eval:0.5042; lr:0.000125
epoch:34; metric:emoval; train:0.9235; eval:0.5090; lr:0.000125
epoch:35; metric:emoval; train:0.9250; eval:0.4963; lr:0.000125
epoch:36; metric:emoval; train:0.9116; eval:0.4573; lr:0.000125
epoch:37; metric:emoval; train:0.9182; eval:0.5129; lr:0.000125
epoch:38; metric:emoval; train:0.9150; eval:0.4988; lr:0.000125
epoch:39; metric:emoval; train:0.9143; eval:0.5097; lr:0.000125
epoch:40; metric:emoval; train:0.9133; eval:0.4984; lr:0.000125
Early stopping at epoch 40, best epoch: 10
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3-th folder, best_index: 9, duration: 2443.5051143169403 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.4146; eval:-0.1823; lr:0.000500
epoch:2; metric:emoval; train:0.0922; eval:0.3933; lr:0.000500
epoch:3; metric:emoval; train:0.4261; eval:0.3283; lr:0.000500
epoch:4; metric:emoval; train:0.5279; eval:0.5089; lr:0.000500
epoch:5; metric:emoval; train:0.6283; eval:0.4634; lr:0.000500
epoch:6; metric:emoval; train:0.6896; eval:0.4802; lr:0.000500
epoch:7; metric:emoval; train:0.7377; eval:0.5015; lr:0.000500
epoch:8; metric:emoval; train:0.7600; eval:0.5023; lr:0.000500
epoch:9; metric:emoval; train:0.7810; eval:0.5337; lr:0.000500
epoch:10; metric:emoval; train:0.8067; eval:0.5279; lr:0.000500
epoch:11; metric:emoval; train:0.8170; eval:0.4583; lr:0.000500
epoch:12; metric:emoval; train:0.8123; eval:0.4712; lr:0.000500
epoch:13; metric:emoval; train:0.8309; eval:0.5356; lr:0.000500
epoch:14; metric:emoval; train:0.8673; eval:0.5076; lr:0.000500
epoch:15; metric:emoval; train:0.8547; eval:0.5092; lr:0.000500
epoch:16; metric:emoval; train:0.8428; eval:0.5280; lr:0.000500
epoch:17; metric:emoval; train:0.8813; eval:0.5307; lr:0.000500
epoch:18; metric:emoval; train:0.8847; eval:0.4972; lr:0.000500
epoch:19; metric:emoval; train:0.8956; eval:0.4771; lr:0.000500
epoch:20; metric:emoval; train:0.8813; eval:0.5332; lr:0.000500
epoch:21; metric:emoval; train:0.8884; eval:0.5460; lr:0.000500
epoch:22; metric:emoval; train:0.8955; eval:0.5296; lr:0.000500
epoch:23; metric:emoval; train:0.8971; eval:0.5230; lr:0.000500
epoch:24; metric:emoval; train:0.8877; eval:0.5020; lr:0.000500
epoch:25; metric:emoval; train:0.8736; eval:0.5239; lr:0.000500
epoch:26; metric:emoval; train:0.8807; eval:0.5186; lr:0.000500
epoch:27; metric:emoval; train:0.8706; eval:0.5370; lr:0.000500
epoch:28; metric:emoval; train:0.8935; eval:0.5363; lr:0.000500
epoch:29; metric:emoval; train:0.8791; eval:0.4713; lr:0.000500
epoch:30; metric:emoval; train:0.8431; eval:0.5274; lr:0.000500
epoch:31; metric:emoval; train:0.8792; eval:0.5207; lr:0.000500
epoch:32; metric:emoval; train:0.8788; eval:0.5401; lr:0.000250
epoch:33; metric:emoval; train:0.9098; eval:0.5500; lr:0.000250
epoch:34; metric:emoval; train:0.9173; eval:0.5298; lr:0.000250
epoch:35; metric:emoval; train:0.9153; eval:0.5254; lr:0.000250
epoch:36; metric:emoval; train:0.9080; eval:0.5690; lr:0.000250
epoch:37; metric:emoval; train:0.9050; eval:0.5440; lr:0.000250
epoch:38; metric:emoval; train:0.9037; eval:0.5619; lr:0.000250
epoch:39; metric:emoval; train:0.9069; eval:0.5069; lr:0.000250
epoch:40; metric:emoval; train:0.9024; eval:0.5032; lr:0.000250
epoch:41; metric:emoval; train:0.8978; eval:0.5316; lr:0.000250
epoch:42; metric:emoval; train:0.8835; eval:0.5211; lr:0.000250
epoch:43; metric:emoval; train:0.8814; eval:0.5196; lr:0.000250
epoch:44; metric:emoval; train:0.9043; eval:0.5337; lr:0.000250
epoch:45; metric:emoval; train:0.9004; eval:0.5291; lr:0.000250
epoch:46; metric:emoval; train:0.9041; eval:0.5075; lr:0.000250
epoch:47; metric:emoval; train:0.9054; eval:0.5334; lr:0.000125
epoch:48; metric:emoval; train:0.9169; eval:0.5338; lr:0.000125
epoch:49; metric:emoval; train:0.9199; eval:0.5185; lr:0.000125
epoch:50; metric:emoval; train:0.9172; eval:0.5366; lr:0.000125
epoch:51; metric:emoval; train:0.9246; eval:0.5449; lr:0.000125
epoch:52; metric:emoval; train:0.9211; eval:0.5394; lr:0.000125
epoch:53; metric:emoval; train:0.9288; eval:0.5378; lr:0.000125
epoch:54; metric:emoval; train:0.9291; eval:0.5259; lr:0.000125
epoch:55; metric:emoval; train:0.9266; eval:0.5449; lr:0.000125
epoch:56; metric:emoval; train:0.9271; eval:0.5125; lr:0.000125
epoch:57; metric:emoval; train:0.9367; eval:0.5178; lr:0.000125
epoch:58; metric:emoval; train:0.9223; eval:0.5064; lr:0.000063
epoch:59; metric:emoval; train:0.9384; eval:0.5470; lr:0.000063
epoch:60; metric:emoval; train:0.9345; eval:0.5255; lr:0.000063
epoch:61; metric:emoval; train:0.9354; eval:0.5317; lr:0.000063
epoch:62; metric:emoval; train:0.9360; eval:0.5338; lr:0.000063
epoch:63; metric:emoval; train:0.9355; eval:0.5398; lr:0.000063
epoch:64; metric:emoval; train:0.9326; eval:0.5268; lr:0.000063
epoch:65; metric:emoval; train:0.9377; eval:0.5227; lr:0.000063
epoch:66; metric:emoval; train:0.9418; eval:0.5008; lr:0.000063
Early stopping at epoch 66, best epoch: 36
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4-th folder, best_index: 35, duration: 3532.406638145447 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3056; eval:-0.1663; lr:0.000500
epoch:2; metric:emoval; train:0.0643; eval:0.2113; lr:0.000500
epoch:3; metric:emoval; train:0.3393; eval:0.2528; lr:0.000500
epoch:4; metric:emoval; train:0.5222; eval:0.4943; lr:0.000500
epoch:5; metric:emoval; train:0.6137; eval:0.5028; lr:0.000500
epoch:6; metric:emoval; train:0.6766; eval:0.5198; lr:0.000500
epoch:7; metric:emoval; train:0.6946; eval:0.4685; lr:0.000500
epoch:8; metric:emoval; train:0.7293; eval:0.4841; lr:0.000500
epoch:9; metric:emoval; train:0.7629; eval:0.5166; lr:0.000500
epoch:10; metric:emoval; train:0.7764; eval:0.5103; lr:0.000500
epoch:11; metric:emoval; train:0.7999; eval:0.5453; lr:0.000500
epoch:12; metric:emoval; train:0.8172; eval:0.5373; lr:0.000500
epoch:13; metric:emoval; train:0.8186; eval:0.5273; lr:0.000500
epoch:14; metric:emoval; train:0.8401; eval:0.4917; lr:0.000500
epoch:15; metric:emoval; train:0.8374; eval:0.5499; lr:0.000500
epoch:16; metric:emoval; train:0.8744; eval:0.4669; lr:0.000500
epoch:17; metric:emoval; train:0.8758; eval:0.5456; lr:0.000500
epoch:18; metric:emoval; train:0.8991; eval:0.5291; lr:0.000500
epoch:19; metric:emoval; train:0.8868; eval:0.5211; lr:0.000500
epoch:20; metric:emoval; train:0.8643; eval:0.5400; lr:0.000500
epoch:21; metric:emoval; train:0.9018; eval:0.5351; lr:0.000500
epoch:22; metric:emoval; train:0.8951; eval:0.4704; lr:0.000500
epoch:23; metric:emoval; train:0.8616; eval:0.4707; lr:0.000500
epoch:24; metric:emoval; train:0.8877; eval:0.4472; lr:0.000500
epoch:25; metric:emoval; train:0.8820; eval:0.5091; lr:0.000500
epoch:26; metric:emoval; train:0.8897; eval:0.5197; lr:0.000250
epoch:27; metric:emoval; train:0.9202; eval:0.5538; lr:0.000250
epoch:28; metric:emoval; train:0.9192; eval:0.5531; lr:0.000250
epoch:29; metric:emoval; train:0.9346; eval:0.5221; lr:0.000250
epoch:30; metric:emoval; train:0.9287; eval:0.5360; lr:0.000250
epoch:31; metric:emoval; train:0.9245; eval:0.4875; lr:0.000250
epoch:32; metric:emoval; train:0.9086; eval:0.5213; lr:0.000250
epoch:33; metric:emoval; train:0.8996; eval:0.5243; lr:0.000250
epoch:34; metric:emoval; train:0.9120; eval:0.5236; lr:0.000250
epoch:35; metric:emoval; train:0.9110; eval:0.5377; lr:0.000250
epoch:36; metric:emoval; train:0.9112; eval:0.5126; lr:0.000250
epoch:37; metric:emoval; train:0.9103; eval:0.5288; lr:0.000250
epoch:38; metric:emoval; train:0.8953; eval:0.5161; lr:0.000125
epoch:39; metric:emoval; train:0.9125; eval:0.5322; lr:0.000125
epoch:40; metric:emoval; train:0.9266; eval:0.5405; lr:0.000125
epoch:41; metric:emoval; train:0.9243; eval:0.5395; lr:0.000125
epoch:42; metric:emoval; train:0.9268; eval:0.5169; lr:0.000125
epoch:43; metric:emoval; train:0.9274; eval:0.5317; lr:0.000125
epoch:44; metric:emoval; train:0.9111; eval:0.5503; lr:0.000125
epoch:45; metric:emoval; train:0.9290; eval:0.5195; lr:0.000125
epoch:46; metric:emoval; train:0.9129; eval:0.5223; lr:0.000125
epoch:47; metric:emoval; train:0.9059; eval:0.5390; lr:0.000125
epoch:48; metric:emoval; train:0.9148; eval:0.4949; lr:0.000125
epoch:49; metric:emoval; train:0.9284; eval:0.4657; lr:0.000063
epoch:50; metric:emoval; train:0.9269; eval:0.5142; lr:0.000063
epoch:51; metric:emoval; train:0.9250; eval:0.5208; lr:0.000063
epoch:52; metric:emoval; train:0.9262; eval:0.5391; lr:0.000063
epoch:53; metric:emoval; train:0.9409; eval:0.5401; lr:0.000063
epoch:54; metric:emoval; train:0.9338; eval:0.5322; lr:0.000063
epoch:55; metric:emoval; train:0.9431; eval:0.5116; lr:0.000063
epoch:56; metric:emoval; train:0.9319; eval:0.5076; lr:0.000063
epoch:57; metric:emoval; train:0.9312; eval:0.5128; lr:0.000063
Early stopping at epoch 57, best epoch: 27
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5-th folder, best_index: 26, duration: 1549.501857995987 >>>>>
====== Prediction and Saving =======
save results in ./saved-trimodal/result/cv_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7427_acc:0.7447_val:0.7150_1770135931.6022372.npz
save results in ./saved-trimodal/result/test1_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7989_acc:0.7981_val:0.6913_1770135931.6022372.npz
save results in ./saved-trimodal/result/test2_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7705_acc:0.7743_val:0.6711_1770135931.6022372.npz
save results in ./saved-trimodal/result/test3_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8835_acc:0.8849_val:78.6586_1770135931.6022372.npz
