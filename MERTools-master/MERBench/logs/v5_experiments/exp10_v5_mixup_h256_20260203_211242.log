====== Params Pre-analysis =======
args:  Namespace(audio_feature='chinese-hubert-large-UTT', batch_size=32, contrastive_temperature=0.07, contrastive_weight=0.1, cross_kl_weight=0.01, dataset='MER2023', debug=False, dropout=0.4, e2e_dim=None, e2e_name=None, early_stopping_patience=30, epochs=100, feat_scale=1, feat_type='utt', focal_gamma=2.0, fusion_temperature=1.0, gate_alpha=0.5, gpu=0, grad_clip=1.0, hidden_dim=256, hyper_path=None, kl_warmup_epochs=20, kl_weight=0.01, l2=5e-05, label_smoothing=0.1, lr=0.0003, lr_adjust='case1', lr_factor=0.5, lr_patience=10, mixup_alpha=0.3, modality_dropout=0.15, modality_dropout_warmup=20, model='attention_robust_v5', n_classes=None, num_attention_heads=4, num_workers=0, print_iters=100000000.0, recon_weight=0.1, save_iters=100000000.0, save_root='./saved-trimodal', savemodel=False, test_dataset=None, text_feature='Baichuan-13B-Base-UTT', train_dataset=None, use_contrastive=True, use_dynamic_kl=True, use_gated_fusion=True, use_mixup=True, use_modality_dropout=True, use_proxy_attention=True, use_vae=True, video_feature='clip-vit-large-patch14-UTT')
====== Reading Data =======
train: sample number 3373
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/3373 [00:00<?, ?it/s]  9%|▉         | 304/3373 [00:00<00:01, 1680.17it/s] 15%|█▌        | 507/3373 [00:00<00:01, 1834.11it/s] 22%|██▏       | 731/3373 [00:00<00:01, 1990.74it/s] 28%|██▊       | 950/3373 [00:00<00:01, 2058.31it/s] 34%|███▍      | 1160/3373 [00:00<00:01, 2005.10it/s] 40%|████      | 1364/3373 [00:00<00:01, 1981.48it/s] 46%|████▋     | 1564/3373 [00:00<00:01, 1580.61it/s] 51%|█████▏    | 1735/3373 [00:00<00:01, 1599.76it/s] 56%|█████▋    | 1904/3373 [00:01<00:00, 1578.31it/s] 64%|██████▎   | 2146/3373 [00:01<00:00, 1805.67it/s] 69%|██████▉   | 2338/3373 [00:01<00:00, 1836.82it/s] 77%|███████▋  | 2595/3373 [00:01<00:00, 1654.13it/s] 83%|████████▎ | 2809/3373 [00:01<00:00, 1773.22it/s] 89%|████████▉ | 2995/3373 [00:01<00:00, 1759.11it/s] 94%|█████████▍| 3177/3373 [00:01<00:00, 1418.60it/s] 99%|█████████▉| 3333/3373 [00:01<00:00, 1440.81it/s]100%|██████████| 3373/3373 [00:01<00:00, 1696.82it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/3373 [00:00<?, ?it/s]  2%|▏         | 62/3373 [00:00<00:05, 618.24it/s]  4%|▍         | 135/3373 [00:00<00:04, 682.09it/s]  6%|▋         | 215/3373 [00:00<00:04, 733.14it/s]  9%|▉         | 314/3373 [00:00<00:03, 834.11it/s] 12%|█▏        | 413/3373 [00:00<00:03, 889.00it/s] 15%|█▍        | 502/3373 [00:00<00:03, 881.34it/s] 18%|█▊        | 591/3373 [00:00<00:03, 873.55it/s] 20%|██        | 691/3373 [00:00<00:02, 911.18it/s] 23%|██▎       | 783/3373 [00:00<00:02, 910.78it/s] 26%|██▋       | 887/3373 [00:01<00:02, 949.30it/s] 31%|███       | 1048/3373 [00:01<00:02, 1149.21it/s] 35%|███▍      | 1164/3373 [00:01<00:01, 1134.84it/s] 38%|███▊      | 1278/3373 [00:01<00:02, 900.21it/s]  41%|████      | 1376/3373 [00:01<00:02, 739.57it/s] 45%|████▍     | 1506/3373 [00:01<00:02, 864.93it/s] 48%|████▊     | 1604/3373 [00:01<00:01, 890.21it/s] 51%|█████▏    | 1737/3373 [00:01<00:01, 1002.94it/s] 55%|█████▍    | 1845/3373 [00:02<00:01, 1020.31it/s] 58%|█████▊    | 1953/3373 [00:02<00:01, 1031.00it/s] 61%|██████    | 2060/3373 [00:02<00:01, 1029.72it/s] 64%|██████▍   | 2166/3373 [00:02<00:01, 822.35it/s]  68%|██████▊   | 2289/3373 [00:02<00:01, 921.58it/s] 71%|███████   | 2390/3373 [00:02<00:01, 939.27it/s] 74%|███████▍  | 2490/3373 [00:02<00:00, 955.44it/s] 78%|███████▊  | 2618/3373 [00:02<00:00, 1043.90it/s] 81%|████████  | 2727/3373 [00:02<00:00, 1050.71it/s] 84%|████████▍ | 2845/3373 [00:03<00:00, 1087.42it/s] 89%|████████▉ | 2995/3373 [00:03<00:00, 1207.26it/s] 92%|█████████▏| 3118/3373 [00:03<00:00, 1192.97it/s] 96%|█████████▋| 3250/3373 [00:03<00:00, 1228.85it/s]100%|██████████| 3373/3373 [00:03<00:00, 963.56it/s] 
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/3373 [00:00<?, ?it/s]  3%|▎         | 109/3373 [00:00<00:03, 1087.66it/s]  6%|▋         | 218/3373 [00:00<00:02, 1083.84it/s] 12%|█▏        | 407/3373 [00:00<00:02, 1435.66it/s] 18%|█▊        | 603/3373 [00:00<00:01, 1640.11it/s] 23%|██▎       | 767/3373 [00:00<00:01, 1620.59it/s] 29%|██▉       | 983/3373 [00:00<00:01, 1801.38it/s] 35%|███▍      | 1171/3373 [00:00<00:01, 1824.45it/s] 40%|████      | 1354/3373 [00:00<00:01, 1818.59it/s] 46%|████▌     | 1537/3373 [00:00<00:01, 1819.65it/s] 51%|█████     | 1720/3373 [00:01<00:00, 1817.95it/s] 56%|█████▋    | 1902/3373 [00:01<00:00, 1815.52it/s] 62%|██████▏   | 2084/3373 [00:01<00:00, 1783.42it/s] 68%|██████▊   | 2294/3373 [00:01<00:00, 1499.28it/s] 73%|███████▎  | 2453/3373 [00:01<00:00, 1518.01it/s] 77%|███████▋  | 2612/3373 [00:01<00:00, 1536.85it/s] 83%|████████▎ | 2801/3373 [00:01<00:00, 1629.51it/s] 88%|████████▊ | 2969/3373 [00:01<00:00, 1621.38it/s] 93%|█████████▎| 3135/3373 [00:02<00:00, 1286.22it/s]100%|██████████| 3373/3373 [00:02<00:00, 1670.22it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test1: sample number 411
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/411 [00:00<?, ?it/s] 15%|█▌        | 62/411 [00:00<00:00, 616.88it/s] 86%|████████▌ | 352/411 [00:00<00:00, 1954.29it/s]100%|██████████| 411/411 [00:00<00:00, 2005.91it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/411 [00:00<?, ?it/s] 33%|███▎      | 135/411 [00:00<00:00, 1349.61it/s] 76%|███████▌  | 312/411 [00:00<00:00, 1596.54it/s]100%|██████████| 411/411 [00:00<00:00, 1941.74it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/411 [00:00<?, ?it/s] 82%|████████▏ | 336/411 [00:00<00:00, 3355.71it/s]100%|██████████| 411/411 [00:00<00:00, 2200.38it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test2: sample number 412
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/412 [00:00<?, ?it/s] 65%|██████▌   | 268/412 [00:00<00:00, 2668.19it/s]100%|██████████| 412/412 [00:00<00:00, 3749.56it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/412 [00:00<?, ?it/s] 45%|████▍     | 185/412 [00:00<00:00, 1847.85it/s] 95%|█████████▌| 392/412 [00:00<00:00, 1977.09it/s]100%|██████████| 412/412 [00:00<00:00, 2030.50it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/412 [00:00<?, ?it/s] 32%|███▏      | 131/412 [00:00<00:00, 1309.79it/s] 94%|█████████▎| 386/412 [00:00<00:00, 2032.65it/s]100%|██████████| 412/412 [00:00<00:00, 2028.23it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test3: sample number 834
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/834 [00:00<?, ?it/s] 15%|█▍        | 121/834 [00:00<00:00, 1200.36it/s] 30%|███       | 253/834 [00:00<00:00, 1270.45it/s] 51%|█████▏    | 428/834 [00:00<00:00, 1486.13it/s] 71%|███████▏  | 595/834 [00:00<00:00, 1556.64it/s] 90%|█████████ | 751/834 [00:00<00:00, 1175.70it/s]100%|██████████| 834/834 [00:00<00:00, 1395.31it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/834 [00:00<?, ?it/s] 13%|█▎        | 105/834 [00:00<00:00, 1047.66it/s] 33%|███▎      | 279/834 [00:00<00:00, 1453.58it/s] 51%|█████     | 425/834 [00:00<00:00, 1445.27it/s] 68%|██████▊   | 570/834 [00:00<00:00, 1432.31it/s] 86%|████████▋ | 721/834 [00:00<00:00, 1457.68it/s]100%|██████████| 834/834 [00:00<00:00, 1610.91it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/834 [00:00<?, ?it/s] 32%|███▏      | 266/834 [00:00<00:00, 2592.42it/s] 63%|██████▎   | 526/834 [00:00<00:00, 2569.11it/s] 94%|█████████▍| 783/834 [00:00<00:00, 2565.86it/s]100%|██████████| 834/834 [00:00<00:00, 2676.66it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
train&val folder:5; test sets:3
audio dimension: 1024; text dimension: 5120; video dimension: 768
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3548; eval:-0.0608; lr:0.000300
epoch:2; metric:emoval; train:0.1667; eval:0.3352; lr:0.000300
epoch:3; metric:emoval; train:0.4059; eval:0.4963; lr:0.000300
epoch:4; metric:emoval; train:0.5609; eval:0.4362; lr:0.000300
epoch:5; metric:emoval; train:0.6379; eval:0.4307; lr:0.000300
epoch:6; metric:emoval; train:0.6859; eval:0.5349; lr:0.000300
epoch:7; metric:emoval; train:0.7121; eval:0.5100; lr:0.000300
epoch:8; metric:emoval; train:0.7671; eval:0.5110; lr:0.000300
epoch:9; metric:emoval; train:0.7775; eval:0.4661; lr:0.000300
epoch:10; metric:emoval; train:0.8119; eval:0.5076; lr:0.000300
epoch:11; metric:emoval; train:0.8006; eval:0.4950; lr:0.000300
epoch:12; metric:emoval; train:0.8114; eval:0.4683; lr:0.000300
epoch:13; metric:emoval; train:0.8440; eval:0.5095; lr:0.000300
epoch:14; metric:emoval; train:0.8749; eval:0.5528; lr:0.000300
epoch:15; metric:emoval; train:0.8615; eval:0.5147; lr:0.000300
epoch:16; metric:emoval; train:0.8811; eval:0.4876; lr:0.000300
epoch:17; metric:emoval; train:0.8675; eval:0.5114; lr:0.000300
epoch:18; metric:emoval; train:0.8950; eval:0.4908; lr:0.000300
epoch:19; metric:emoval; train:0.8857; eval:0.5070; lr:0.000300
epoch:20; metric:emoval; train:0.8914; eval:0.4344; lr:0.000300
epoch:21; metric:emoval; train:0.8851; eval:0.5261; lr:0.000300
epoch:22; metric:emoval; train:0.9079; eval:0.5064; lr:0.000300
epoch:23; metric:emoval; train:0.8862; eval:0.3607; lr:0.000300
epoch:24; metric:emoval; train:0.8745; eval:0.4815; lr:0.000300
epoch:25; metric:emoval; train:0.8614; eval:0.4929; lr:0.000150
epoch:26; metric:emoval; train:0.9243; eval:0.5238; lr:0.000150
epoch:27; metric:emoval; train:0.9405; eval:0.5251; lr:0.000150
epoch:28; metric:emoval; train:0.9359; eval:0.4823; lr:0.000150
epoch:29; metric:emoval; train:0.9417; eval:0.5155; lr:0.000150
epoch:30; metric:emoval; train:0.9303; eval:0.4763; lr:0.000150
epoch:31; metric:emoval; train:0.9188; eval:0.4702; lr:0.000150
epoch:32; metric:emoval; train:0.9305; eval:0.4970; lr:0.000150
epoch:33; metric:emoval; train:0.9139; eval:0.4776; lr:0.000150
epoch:34; metric:emoval; train:0.8955; eval:0.5094; lr:0.000150
epoch:35; metric:emoval; train:0.9062; eval:0.5149; lr:0.000150
epoch:36; metric:emoval; train:0.9109; eval:0.4876; lr:0.000075
epoch:37; metric:emoval; train:0.9214; eval:0.5022; lr:0.000075
epoch:38; metric:emoval; train:0.9239; eval:0.5121; lr:0.000075
epoch:39; metric:emoval; train:0.9244; eval:0.5080; lr:0.000075
epoch:40; metric:emoval; train:0.9188; eval:0.4736; lr:0.000075
epoch:41; metric:emoval; train:0.9177; eval:0.5158; lr:0.000075
epoch:42; metric:emoval; train:0.9233; eval:0.5106; lr:0.000075
epoch:43; metric:emoval; train:0.9157; eval:0.4637; lr:0.000075
epoch:44; metric:emoval; train:0.9187; eval:0.5009; lr:0.000075
Early stopping at epoch 44, best epoch: 14
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1-th folder, best_index: 13, duration: 2497.294930458069 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.2880; eval:-0.0215; lr:0.000300
epoch:2; metric:emoval; train:0.1852; eval:0.3315; lr:0.000300
epoch:3; metric:emoval; train:0.4349; eval:0.5039; lr:0.000300
epoch:4; metric:emoval; train:0.5833; eval:0.5207; lr:0.000300
epoch:5; metric:emoval; train:0.6302; eval:0.5510; lr:0.000300
epoch:6; metric:emoval; train:0.6958; eval:0.4307; lr:0.000300
epoch:7; metric:emoval; train:0.7178; eval:0.5187; lr:0.000300
epoch:8; metric:emoval; train:0.7732; eval:0.5330; lr:0.000300
epoch:9; metric:emoval; train:0.7879; eval:0.5314; lr:0.000300
epoch:10; metric:emoval; train:0.8130; eval:0.4802; lr:0.000300
epoch:11; metric:emoval; train:0.8433; eval:0.5522; lr:0.000300
epoch:12; metric:emoval; train:0.8588; eval:0.5571; lr:0.000300
epoch:13; metric:emoval; train:0.8557; eval:0.4627; lr:0.000300
epoch:14; metric:emoval; train:0.8472; eval:0.5103; lr:0.000300
epoch:15; metric:emoval; train:0.8687; eval:0.5534; lr:0.000300
epoch:16; metric:emoval; train:0.8898; eval:0.5558; lr:0.000300
epoch:17; metric:emoval; train:0.8896; eval:0.5286; lr:0.000300
epoch:18; metric:emoval; train:0.9105; eval:0.4917; lr:0.000300
epoch:19; metric:emoval; train:0.8921; eval:0.4912; lr:0.000300
epoch:20; metric:emoval; train:0.8896; eval:0.5600; lr:0.000300
epoch:21; metric:emoval; train:0.8935; eval:0.5300; lr:0.000300
epoch:22; metric:emoval; train:0.9123; eval:0.5217; lr:0.000300
epoch:23; metric:emoval; train:0.9137; eval:0.5035; lr:0.000300
epoch:24; metric:emoval; train:0.9016; eval:0.5619; lr:0.000300
epoch:25; metric:emoval; train:0.8934; eval:0.5087; lr:0.000300
epoch:26; metric:emoval; train:0.8889; eval:0.5469; lr:0.000300
epoch:27; metric:emoval; train:0.8790; eval:0.4435; lr:0.000300
epoch:28; metric:emoval; train:0.8834; eval:0.4965; lr:0.000300
epoch:29; metric:emoval; train:0.8747; eval:0.4994; lr:0.000300
epoch:30; metric:emoval; train:0.8736; eval:0.5451; lr:0.000300
epoch:31; metric:emoval; train:0.8858; eval:0.4927; lr:0.000300
epoch:32; metric:emoval; train:0.8813; eval:0.5665; lr:0.000300
epoch:33; metric:emoval; train:0.8901; eval:0.4836; lr:0.000300
epoch:34; metric:emoval; train:0.8816; eval:0.5267; lr:0.000300
epoch:35; metric:emoval; train:0.8684; eval:0.4571; lr:0.000300
epoch:36; metric:emoval; train:0.8566; eval:0.5451; lr:0.000300
epoch:37; metric:emoval; train:0.8680; eval:0.4780; lr:0.000300
epoch:38; metric:emoval; train:0.8534; eval:0.5164; lr:0.000300
epoch:39; metric:emoval; train:0.8724; eval:0.4972; lr:0.000300
epoch:40; metric:emoval; train:0.8807; eval:0.4074; lr:0.000300
epoch:41; metric:emoval; train:0.8537; eval:0.4809; lr:0.000300
epoch:42; metric:emoval; train:0.8576; eval:0.5096; lr:0.000300
epoch:43; metric:emoval; train:0.8678; eval:0.4848; lr:0.000150
epoch:44; metric:emoval; train:0.8920; eval:0.5579; lr:0.000150
epoch:45; metric:emoval; train:0.9104; eval:0.5736; lr:0.000150
epoch:46; metric:emoval; train:0.9102; eval:0.5451; lr:0.000150
epoch:47; metric:emoval; train:0.9288; eval:0.5538; lr:0.000150
epoch:48; metric:emoval; train:0.9192; eval:0.5878; lr:0.000150
epoch:49; metric:emoval; train:0.9201; eval:0.5413; lr:0.000150
epoch:50; metric:emoval; train:0.9185; eval:0.5608; lr:0.000150
epoch:51; metric:emoval; train:0.9176; eval:0.5409; lr:0.000150
epoch:52; metric:emoval; train:0.9201; eval:0.5579; lr:0.000150
epoch:53; metric:emoval; train:0.9247; eval:0.5353; lr:0.000150
epoch:54; metric:emoval; train:0.9194; eval:0.5227; lr:0.000150
epoch:55; metric:emoval; train:0.9189; eval:0.5401; lr:0.000150
epoch:56; metric:emoval; train:0.9120; eval:0.5674; lr:0.000150
epoch:57; metric:emoval; train:0.9278; eval:0.5514; lr:0.000150
epoch:58; metric:emoval; train:0.9191; eval:0.5056; lr:0.000150
epoch:59; metric:emoval; train:0.9194; eval:0.5486; lr:0.000075
epoch:60; metric:emoval; train:0.9283; eval:0.5342; lr:0.000075
epoch:61; metric:emoval; train:0.9452; eval:0.5460; lr:0.000075
epoch:62; metric:emoval; train:0.9441; eval:0.5259; lr:0.000075
epoch:63; metric:emoval; train:0.9419; eval:0.5407; lr:0.000075
epoch:64; metric:emoval; train:0.9379; eval:0.5316; lr:0.000075
epoch:65; metric:emoval; train:0.9417; eval:0.5224; lr:0.000075
epoch:66; metric:emoval; train:0.9303; eval:0.5366; lr:0.000075
epoch:67; metric:emoval; train:0.9322; eval:0.5390; lr:0.000075
epoch:68; metric:emoval; train:0.9376; eval:0.5543; lr:0.000075
epoch:69; metric:emoval; train:0.9326; eval:0.5236; lr:0.000075
epoch:70; metric:emoval; train:0.9412; eval:0.5035; lr:0.000037
epoch:71; metric:emoval; train:0.9394; eval:0.5138; lr:0.000037
epoch:72; metric:emoval; train:0.9531; eval:0.5175; lr:0.000037
epoch:73; metric:emoval; train:0.9486; eval:0.5018; lr:0.000037
epoch:74; metric:emoval; train:0.9513; eval:0.5255; lr:0.000037
epoch:75; metric:emoval; train:0.9471; eval:0.5430; lr:0.000037
epoch:76; metric:emoval; train:0.9413; eval:0.4894; lr:0.000037
epoch:77; metric:emoval; train:0.9481; eval:0.5272; lr:0.000037
epoch:78; metric:emoval; train:0.9488; eval:0.5412; lr:0.000037
Early stopping at epoch 78, best epoch: 48
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2-th folder, best_index: 47, duration: 5001.1974766254425 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.4474; eval:-0.0154; lr:0.000300
epoch:2; metric:emoval; train:0.1423; eval:0.4547; lr:0.000300
epoch:3; metric:emoval; train:0.4567; eval:0.4313; lr:0.000300
epoch:4; metric:emoval; train:0.5688; eval:0.5118; lr:0.000300
epoch:5; metric:emoval; train:0.6207; eval:0.4806; lr:0.000300
epoch:6; metric:emoval; train:0.7011; eval:0.4117; lr:0.000300
epoch:7; metric:emoval; train:0.7271; eval:0.5235; lr:0.000300
epoch:8; metric:emoval; train:0.7666; eval:0.5778; lr:0.000300
epoch:9; metric:emoval; train:0.7720; eval:0.4931; lr:0.000300
epoch:10; metric:emoval; train:0.8005; eval:0.4743; lr:0.000300
epoch:11; metric:emoval; train:0.8328; eval:0.5024; lr:0.000300
epoch:12; metric:emoval; train:0.8630; eval:0.5201; lr:0.000300
epoch:13; metric:emoval; train:0.8839; eval:0.5198; lr:0.000300
epoch:14; metric:emoval; train:0.8785; eval:0.5086; lr:0.000300
epoch:15; metric:emoval; train:0.8834; eval:0.5377; lr:0.000300
epoch:16; metric:emoval; train:0.8709; eval:0.4594; lr:0.000300
epoch:17; metric:emoval; train:0.8579; eval:0.5160; lr:0.000300
epoch:18; metric:emoval; train:0.8919; eval:0.5297; lr:0.000300
epoch:19; metric:emoval; train:0.8885; eval:0.5135; lr:0.000150
epoch:20; metric:emoval; train:0.9272; eval:0.5341; lr:0.000150
epoch:21; metric:emoval; train:0.9512; eval:0.5414; lr:0.000150
epoch:22; metric:emoval; train:0.9531; eval:0.5171; lr:0.000150
epoch:23; metric:emoval; train:0.9444; eval:0.5155; lr:0.000150
epoch:24; metric:emoval; train:0.9403; eval:0.5241; lr:0.000150
epoch:25; metric:emoval; train:0.9248; eval:0.5187; lr:0.000150
epoch:26; metric:emoval; train:0.9315; eval:0.5004; lr:0.000150
epoch:27; metric:emoval; train:0.9189; eval:0.5308; lr:0.000150
epoch:28; metric:emoval; train:0.9100; eval:0.5066; lr:0.000150
epoch:29; metric:emoval; train:0.9155; eval:0.5149; lr:0.000150
epoch:30; metric:emoval; train:0.9278; eval:0.5379; lr:0.000075
epoch:31; metric:emoval; train:0.9388; eval:0.5529; lr:0.000075
epoch:32; metric:emoval; train:0.9311; eval:0.5358; lr:0.000075
epoch:33; metric:emoval; train:0.9300; eval:0.5354; lr:0.000075
epoch:34; metric:emoval; train:0.9323; eval:0.5238; lr:0.000075
epoch:35; metric:emoval; train:0.9237; eval:0.5196; lr:0.000075
epoch:36; metric:emoval; train:0.9212; eval:0.5422; lr:0.000075
epoch:37; metric:emoval; train:0.9184; eval:0.5386; lr:0.000075
epoch:38; metric:emoval; train:0.9267; eval:0.5393; lr:0.000075
Early stopping at epoch 38, best epoch: 8
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3-th folder, best_index: 7, duration: 2230.903222799301 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3407; eval:0.1231; lr:0.000300
epoch:2; metric:emoval; train:0.2198; eval:0.4214; lr:0.000300
epoch:3; metric:emoval; train:0.4881; eval:0.3632; lr:0.000300
epoch:4; metric:emoval; train:0.5909; eval:0.5135; lr:0.000300
epoch:5; metric:emoval; train:0.6470; eval:0.5227; lr:0.000300
epoch:6; metric:emoval; train:0.6884; eval:0.5765; lr:0.000300
epoch:7; metric:emoval; train:0.7182; eval:0.5644; lr:0.000300
epoch:8; metric:emoval; train:0.7860; eval:0.5734; lr:0.000300
epoch:9; metric:emoval; train:0.8292; eval:0.4385; lr:0.000300
epoch:10; metric:emoval; train:0.8184; eval:0.5521; lr:0.000300
epoch:11; metric:emoval; train:0.8413; eval:0.5380; lr:0.000300
epoch:12; metric:emoval; train:0.8331; eval:0.4895; lr:0.000300
epoch:13; metric:emoval; train:0.8470; eval:0.5584; lr:0.000300
epoch:14; metric:emoval; train:0.8546; eval:0.5360; lr:0.000300
epoch:15; metric:emoval; train:0.8650; eval:0.4367; lr:0.000300
epoch:16; metric:emoval; train:0.8518; eval:0.5799; lr:0.000300
epoch:17; metric:emoval; train:0.8494; eval:0.5102; lr:0.000300
epoch:18; metric:emoval; train:0.8910; eval:0.4537; lr:0.000300
epoch:19; metric:emoval; train:0.8724; eval:0.4578; lr:0.000300
epoch:20; metric:emoval; train:0.8659; eval:0.5647; lr:0.000300
epoch:21; metric:emoval; train:0.8899; eval:0.5189; lr:0.000300
epoch:22; metric:emoval; train:0.8829; eval:0.5750; lr:0.000300
epoch:23; metric:emoval; train:0.8712; eval:0.4388; lr:0.000300
epoch:24; metric:emoval; train:0.8939; eval:0.5377; lr:0.000300
epoch:25; metric:emoval; train:0.8783; eval:0.5516; lr:0.000300
epoch:26; metric:emoval; train:0.8979; eval:0.4567; lr:0.000300
epoch:27; metric:emoval; train:0.8934; eval:0.4790; lr:0.000150
epoch:28; metric:emoval; train:0.9200; eval:0.4834; lr:0.000150
epoch:29; metric:emoval; train:0.9262; eval:0.5198; lr:0.000150
epoch:30; metric:emoval; train:0.9230; eval:0.5491; lr:0.000150
epoch:31; metric:emoval; train:0.9181; eval:0.5159; lr:0.000150
epoch:32; metric:emoval; train:0.9343; eval:0.5430; lr:0.000150
epoch:33; metric:emoval; train:0.9163; eval:0.5137; lr:0.000150
epoch:34; metric:emoval; train:0.9088; eval:0.5067; lr:0.000150
epoch:35; metric:emoval; train:0.9044; eval:0.5251; lr:0.000150
epoch:36; metric:emoval; train:0.9131; eval:0.4697; lr:0.000150
epoch:37; metric:emoval; train:0.9103; eval:0.5440; lr:0.000150
epoch:38; metric:emoval; train:0.9072; eval:0.5312; lr:0.000075
epoch:39; metric:emoval; train:0.9172; eval:0.5458; lr:0.000075
epoch:40; metric:emoval; train:0.9176; eval:0.5427; lr:0.000075
epoch:41; metric:emoval; train:0.9133; eval:0.5504; lr:0.000075
epoch:42; metric:emoval; train:0.9241; eval:0.5447; lr:0.000075
epoch:43; metric:emoval; train:0.9170; eval:0.5205; lr:0.000075
epoch:44; metric:emoval; train:0.9065; eval:0.5509; lr:0.000075
epoch:45; metric:emoval; train:0.9305; eval:0.5280; lr:0.000075
epoch:46; metric:emoval; train:0.9306; eval:0.5631; lr:0.000075
Early stopping at epoch 46, best epoch: 16
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4-th folder, best_index: 15, duration: 2057.699788093567 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.4578; eval:-0.1012; lr:0.000300
epoch:2; metric:emoval; train:0.1012; eval:0.3769; lr:0.000300
epoch:3; metric:emoval; train:0.4241; eval:0.4685; lr:0.000300
epoch:4; metric:emoval; train:0.5477; eval:0.5373; lr:0.000300
epoch:5; metric:emoval; train:0.6459; eval:0.4113; lr:0.000300
epoch:6; metric:emoval; train:0.6850; eval:0.5498; lr:0.000300
epoch:7; metric:emoval; train:0.7409; eval:0.5204; lr:0.000300
epoch:8; metric:emoval; train:0.7542; eval:0.4454; lr:0.000300
epoch:9; metric:emoval; train:0.7880; eval:0.5548; lr:0.000300
epoch:10; metric:emoval; train:0.8028; eval:0.5061; lr:0.000300
epoch:11; metric:emoval; train:0.8511; eval:0.5266; lr:0.000300
epoch:12; metric:emoval; train:0.8563; eval:0.5343; lr:0.000300
epoch:13; metric:emoval; train:0.8496; eval:0.4531; lr:0.000300
epoch:14; metric:emoval; train:0.8407; eval:0.4963; lr:0.000300
epoch:15; metric:emoval; train:0.8754; eval:0.4879; lr:0.000300
epoch:16; metric:emoval; train:0.8627; eval:0.5404; lr:0.000300
epoch:17; metric:emoval; train:0.8917; eval:0.5057; lr:0.000300
epoch:18; metric:emoval; train:0.8840; eval:0.5235; lr:0.000300
epoch:19; metric:emoval; train:0.8799; eval:0.4820; lr:0.000300
epoch:20; metric:emoval; train:0.9024; eval:0.5430; lr:0.000150
epoch:21; metric:emoval; train:0.9473; eval:0.5481; lr:0.000150
epoch:22; metric:emoval; train:0.9463; eval:0.5140; lr:0.000150
epoch:23; metric:emoval; train:0.9430; eval:0.5044; lr:0.000150
epoch:24; metric:emoval; train:0.9439; eval:0.5325; lr:0.000150
epoch:25; metric:emoval; train:0.9311; eval:0.5413; lr:0.000150
epoch:26; metric:emoval; train:0.9206; eval:0.5323; lr:0.000150
epoch:27; metric:emoval; train:0.9163; eval:0.5517; lr:0.000150
epoch:28; metric:emoval; train:0.9121; eval:0.5418; lr:0.000150
epoch:29; metric:emoval; train:0.9306; eval:0.4725; lr:0.000150
epoch:30; metric:emoval; train:0.9149; eval:0.5550; lr:0.000150
epoch:31; metric:emoval; train:0.9171; eval:0.4791; lr:0.000150
epoch:32; metric:emoval; train:0.9176; eval:0.5311; lr:0.000150
epoch:33; metric:emoval; train:0.9049; eval:0.4970; lr:0.000150
epoch:34; metric:emoval; train:0.9027; eval:0.5513; lr:0.000150
epoch:35; metric:emoval; train:0.9056; eval:0.4395; lr:0.000150
epoch:36; metric:emoval; train:0.8887; eval:0.5173; lr:0.000150
epoch:37; metric:emoval; train:0.8918; eval:0.5547; lr:0.000150
epoch:38; metric:emoval; train:0.8900; eval:0.5242; lr:0.000150
epoch:39; metric:emoval; train:0.8908; eval:0.5541; lr:0.000150
Early stopping at epoch 39, best epoch: 9
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5-th folder, best_index: 29, duration: 1067.6895952224731 >>>>>
====== Prediction and Saving =======
save results in ./saved-trimodal/result/cv_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7417_acc:0.7445_val:0.6843_1770136192.4064968.npz
save results in ./saved-trimodal/result/test1_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8005_acc:0.8005_val:0.6454_1770136192.4064968.npz
save results in ./saved-trimodal/result/test2_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7720_acc:0.7743_val:0.6530_1770136192.4064968.npz
save results in ./saved-trimodal/result/test3_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8742_acc:0.8765_val:79.5920_1770136192.4064968.npz
