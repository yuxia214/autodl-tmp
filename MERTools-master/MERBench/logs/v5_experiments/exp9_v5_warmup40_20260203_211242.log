====== Params Pre-analysis =======
args:  Namespace(audio_feature='chinese-hubert-large-UTT', batch_size=32, contrastive_temperature=0.07, contrastive_weight=0.1, cross_kl_weight=0.01, dataset='MER2023', debug=False, dropout=0.35, e2e_dim=None, e2e_name=None, early_stopping_patience=30, epochs=100, feat_scale=1, feat_type='utt', focal_gamma=2.0, fusion_temperature=1.0, gate_alpha=0.5, gpu=0, grad_clip=1.0, hidden_dim=128, hyper_path=None, kl_warmup_epochs=30, kl_weight=0.01, l2=5e-05, label_smoothing=0.1, lr=0.0005, lr_adjust='case1', lr_factor=0.5, lr_patience=10, mixup_alpha=0.4, modality_dropout=0.15, modality_dropout_warmup=40, model='attention_robust_v5', n_classes=None, num_attention_heads=4, num_workers=0, print_iters=100000000.0, recon_weight=0.1, save_iters=100000000.0, save_root='./saved-trimodal', savemodel=False, test_dataset=None, text_feature='Baichuan-13B-Base-UTT', train_dataset=None, use_contrastive=True, use_dynamic_kl=True, use_gated_fusion=True, use_mixup=False, use_modality_dropout=True, use_proxy_attention=True, use_vae=True, video_feature='clip-vit-large-patch14-UTT')
====== Reading Data =======
train: sample number 3373
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/3373 [00:00<?, ?it/s]  3%|▎         | 105/3373 [00:00<00:03, 981.44it/s]  8%|▊         | 264/3373 [00:00<00:02, 1329.06it/s] 12%|█▏        | 398/3373 [00:00<00:02, 1332.12it/s] 16%|█▌        | 532/3373 [00:00<00:02, 990.91it/s]  20%|█▉        | 664/3373 [00:00<00:02, 1085.75it/s] 23%|██▎       | 782/3373 [00:00<00:02, 1095.43it/s] 27%|██▋       | 898/3373 [00:00<00:02, 1106.36it/s] 32%|███▏      | 1077/3373 [00:00<00:01, 1306.15it/s] 36%|███▌      | 1212/3373 [00:01<00:01, 1297.47it/s] 40%|███▉      | 1345/3373 [00:01<00:01, 1032.31it/s] 43%|████▎     | 1459/3373 [00:01<00:01, 1046.80it/s] 47%|████▋     | 1571/3373 [00:01<00:01, 1063.36it/s] 52%|█████▏    | 1745/3373 [00:01<00:01, 1243.59it/s] 56%|█████▌    | 1893/3373 [00:01<00:01, 1309.00it/s] 62%|██████▏   | 2078/3373 [00:01<00:00, 1459.51it/s] 66%|██████▌   | 2228/3373 [00:01<00:00, 1160.45it/s] 70%|███████   | 2373/3373 [00:02<00:00, 1231.38it/s] 74%|███████▍  | 2507/3373 [00:02<00:00, 1251.87it/s] 78%|███████▊  | 2640/3373 [00:02<00:00, 1268.03it/s] 83%|████████▎ | 2791/3373 [00:02<00:00, 1332.15it/s] 87%|████████▋ | 2929/3373 [00:02<00:00, 1323.68it/s] 93%|█████████▎| 3125/3373 [00:02<00:00, 1504.28it/s]100%|██████████| 3373/3373 [00:02<00:00, 1292.71it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/3373 [00:00<?, ?it/s]  2%|▏         | 56/3373 [00:00<00:05, 559.37it/s]  5%|▍         | 160/3373 [00:00<00:03, 841.42it/s]  9%|▉         | 307/3373 [00:00<00:02, 1127.75it/s] 12%|█▏        | 420/3373 [00:00<00:02, 1120.52it/s] 16%|█▌        | 545/3373 [00:00<00:02, 1165.64it/s] 20%|█▉        | 662/3373 [00:00<00:02, 1156.93it/s] 23%|██▎       | 784/3373 [00:00<00:02, 1171.92it/s] 28%|██▊       | 951/3373 [00:00<00:01, 1328.25it/s] 33%|███▎      | 1100/3373 [00:00<00:01, 1377.33it/s] 37%|███▋      | 1238/3373 [00:01<00:01, 1366.45it/s] 41%|████      | 1375/3373 [00:01<00:01, 1084.28it/s] 44%|████▍     | 1493/3373 [00:01<00:01, 1096.84it/s] 48%|████▊     | 1610/3373 [00:01<00:01, 1099.32it/s] 51%|█████     | 1725/3373 [00:01<00:01, 898.64it/s]  55%|█████▍    | 1844/3373 [00:01<00:01, 965.56it/s] 60%|█████▉    | 2019/3373 [00:01<00:01, 1163.89it/s] 64%|██████▎   | 2145/3373 [00:01<00:01, 1185.31it/s] 69%|██████▉   | 2325/3373 [00:01<00:00, 1353.83it/s] 73%|███████▎  | 2467/3373 [00:02<00:00, 1362.54it/s] 77%|███████▋  | 2608/3373 [00:02<00:00, 1363.01it/s] 81%|████████▏ | 2748/3373 [00:02<00:00, 1364.97it/s] 86%|████████▌ | 2887/3373 [00:02<00:00, 1348.30it/s] 90%|████████▉ | 3024/3373 [00:02<00:00, 1092.18it/s] 93%|█████████▎| 3142/3373 [00:02<00:00, 1109.20it/s] 98%|█████████▊| 3302/3373 [00:02<00:00, 1236.81it/s]100%|██████████| 3373/3373 [00:02<00:00, 1203.30it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/3373 [00:00<?, ?it/s]  5%|▌         | 175/3373 [00:00<00:01, 1743.60it/s] 12%|█▏        | 395/3373 [00:00<00:01, 1968.12it/s] 18%|█▊        | 594/3373 [00:00<00:01, 1977.23it/s] 23%|██▎       | 792/3373 [00:00<00:01, 1476.26it/s] 28%|██▊       | 954/3373 [00:00<00:01, 1503.63it/s] 33%|███▎      | 1114/3373 [00:00<00:01, 1515.99it/s] 38%|███▊      | 1272/3373 [00:00<00:01, 1509.63it/s] 42%|████▏     | 1429/3373 [00:00<00:01, 1517.16it/s] 47%|████▋     | 1601/3373 [00:01<00:01, 1572.24it/s] 52%|█████▏    | 1761/3373 [00:01<00:01, 1251.49it/s] 56%|█████▋    | 1898/3373 [00:01<00:01, 1280.91it/s] 62%|██████▏   | 2090/3373 [00:01<00:00, 1446.05it/s] 67%|██████▋   | 2263/3373 [00:01<00:00, 1522.56it/s] 73%|███████▎  | 2453/3373 [00:01<00:00, 1627.58it/s] 78%|███████▊  | 2622/3373 [00:01<00:00, 1624.98it/s] 84%|████████▍ | 2838/3373 [00:01<00:00, 1773.10it/s] 90%|█████████ | 3038/3373 [00:01<00:00, 1832.54it/s] 98%|█████████▊| 3302/3373 [00:02<00:00, 2062.60it/s]100%|██████████| 3373/3373 [00:02<00:00, 1678.78it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test1: sample number 411
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/411 [00:00<?, ?it/s]  5%|▍         | 20/411 [00:00<00:01, 199.50it/s] 46%|████▌     | 189/411 [00:00<00:00, 980.63it/s]100%|██████████| 411/411 [00:00<00:00, 1297.12it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/411 [00:00<?, ?it/s] 32%|███▏      | 130/411 [00:00<00:00, 714.55it/s] 81%|████████▏ | 334/411 [00:00<00:00, 1274.94it/s]100%|██████████| 411/411 [00:00<00:00, 1387.57it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/411 [00:00<?, ?it/s] 54%|█████▍    | 221/411 [00:00<00:00, 2198.38it/s]100%|██████████| 411/411 [00:00<00:00, 2117.98it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test2: sample number 412
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/412 [00:00<?, ?it/s] 36%|███▌      | 147/412 [00:00<00:00, 1464.03it/s] 85%|████████▌ | 352/412 [00:00<00:00, 1803.52it/s]100%|██████████| 412/412 [00:00<00:00, 1999.11it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/412 [00:00<?, ?it/s]  6%|▋         | 26/412 [00:00<00:01, 257.51it/s] 33%|███▎      | 136/412 [00:00<00:00, 750.74it/s] 57%|█████▋    | 234/412 [00:00<00:00, 854.34it/s] 86%|████████▌ | 355/412 [00:00<00:00, 988.59it/s]100%|██████████| 412/412 [00:00<00:00, 827.19it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/412 [00:00<?, ?it/s] 23%|██▎       | 96/412 [00:00<00:00, 526.11it/s] 73%|███████▎  | 300/412 [00:00<00:00, 1188.43it/s]100%|██████████| 412/412 [00:00<00:00, 1419.42it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test3: sample number 834
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/834 [00:00<?, ?it/s] 14%|█▍        | 119/834 [00:00<00:00, 1182.81it/s] 29%|██▊       | 239/834 [00:00<00:00, 1187.92it/s] 47%|████▋     | 395/834 [00:00<00:00, 1356.20it/s] 69%|██████▉   | 577/834 [00:00<00:00, 1521.03it/s]100%|██████████| 834/834 [00:00<00:00, 1976.76it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/834 [00:00<?, ?it/s] 15%|█▍        | 121/834 [00:00<00:01, 674.62it/s] 36%|███▋      | 303/834 [00:00<00:00, 1180.92it/s] 53%|█████▎    | 438/834 [00:00<00:00, 1233.84it/s] 69%|██████▊   | 572/834 [00:00<00:00, 1267.76it/s] 85%|████████▍ | 706/834 [00:00<00:00, 1291.35it/s]100%|██████████| 834/834 [00:00<00:00, 1208.48it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/834 [00:00<?, ?it/s] 39%|███▉      | 327/834 [00:00<00:00, 3269.80it/s] 93%|█████████▎| 772/834 [00:00<00:00, 3962.39it/s]100%|██████████| 834/834 [00:00<00:00, 4008.42it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
train&val folder:5; test sets:3
audio dimension: 1024; text dimension: 5120; video dimension: 768
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3104; eval:0.0158; lr:0.000500
epoch:2; metric:emoval; train:0.1519; eval:0.2793; lr:0.000500
epoch:3; metric:emoval; train:0.4106; eval:0.3287; lr:0.000500
epoch:4; metric:emoval; train:0.5488; eval:0.4908; lr:0.000500
epoch:5; metric:emoval; train:0.6331; eval:0.4716; lr:0.000500
epoch:6; metric:emoval; train:0.6705; eval:0.5266; lr:0.000500
epoch:7; metric:emoval; train:0.7351; eval:0.4537; lr:0.000500
epoch:8; metric:emoval; train:0.7498; eval:0.5276; lr:0.000500
epoch:9; metric:emoval; train:0.7919; eval:0.4980; lr:0.000500
epoch:10; metric:emoval; train:0.8236; eval:0.4907; lr:0.000500
epoch:11; metric:emoval; train:0.7807; eval:0.4590; lr:0.000500
epoch:12; metric:emoval; train:0.8035; eval:0.4932; lr:0.000500
epoch:13; metric:emoval; train:0.8089; eval:0.5464; lr:0.000500
epoch:14; metric:emoval; train:0.8478; eval:0.5022; lr:0.000500
epoch:15; metric:emoval; train:0.8630; eval:0.5040; lr:0.000500
epoch:16; metric:emoval; train:0.8832; eval:0.5300; lr:0.000500
epoch:17; metric:emoval; train:0.8672; eval:0.5051; lr:0.000500
epoch:18; metric:emoval; train:0.9048; eval:0.5103; lr:0.000500
epoch:19; metric:emoval; train:0.8924; eval:0.4353; lr:0.000500
epoch:20; metric:emoval; train:0.8873; eval:0.5209; lr:0.000500
epoch:21; metric:emoval; train:0.8991; eval:0.5225; lr:0.000500
epoch:22; metric:emoval; train:0.8811; eval:0.4760; lr:0.000500
epoch:23; metric:emoval; train:0.8773; eval:0.5427; lr:0.000500
epoch:24; metric:emoval; train:0.9084; eval:0.4750; lr:0.000250
epoch:25; metric:emoval; train:0.9426; eval:0.5222; lr:0.000250
epoch:26; metric:emoval; train:0.9584; eval:0.5212; lr:0.000250
epoch:27; metric:emoval; train:0.9584; eval:0.5369; lr:0.000250
epoch:28; metric:emoval; train:0.9618; eval:0.5065; lr:0.000250
epoch:29; metric:emoval; train:0.9633; eval:0.5265; lr:0.000250
epoch:30; metric:emoval; train:0.9630; eval:0.5184; lr:0.000250
epoch:31; metric:emoval; train:0.9601; eval:0.5101; lr:0.000250
epoch:32; metric:emoval; train:0.9558; eval:0.5288; lr:0.000250
epoch:33; metric:emoval; train:0.9559; eval:0.5538; lr:0.000250
epoch:34; metric:emoval; train:0.9565; eval:0.5104; lr:0.000250
epoch:35; metric:emoval; train:0.9512; eval:0.5177; lr:0.000250
epoch:36; metric:emoval; train:0.9425; eval:0.5163; lr:0.000250
epoch:37; metric:emoval; train:0.9544; eval:0.5423; lr:0.000250
epoch:38; metric:emoval; train:0.9504; eval:0.5188; lr:0.000250
epoch:39; metric:emoval; train:0.9396; eval:0.5442; lr:0.000250
epoch:40; metric:emoval; train:0.9501; eval:0.4978; lr:0.000250
epoch:41; metric:emoval; train:0.9634; eval:0.5105; lr:0.000250
epoch:42; metric:emoval; train:0.9641; eval:0.5211; lr:0.000250
epoch:43; metric:emoval; train:0.9591; eval:0.5164; lr:0.000250
epoch:44; metric:emoval; train:0.9647; eval:0.4867; lr:0.000125
epoch:45; metric:emoval; train:0.9607; eval:0.5273; lr:0.000125
epoch:46; metric:emoval; train:0.9662; eval:0.5347; lr:0.000125
epoch:47; metric:emoval; train:0.9629; eval:0.5348; lr:0.000125
epoch:48; metric:emoval; train:0.9579; eval:0.5135; lr:0.000125
epoch:49; metric:emoval; train:0.9534; eval:0.5232; lr:0.000125
epoch:50; metric:emoval; train:0.9574; eval:0.5216; lr:0.000125
epoch:51; metric:emoval; train:0.9538; eval:0.5407; lr:0.000125
epoch:52; metric:emoval; train:0.9415; eval:0.5307; lr:0.000125
epoch:53; metric:emoval; train:0.9492; eval:0.5257; lr:0.000125
epoch:54; metric:emoval; train:0.9495; eval:0.5458; lr:0.000125
epoch:55; metric:emoval; train:0.9402; eval:0.4861; lr:0.000063
epoch:56; metric:emoval; train:0.9563; eval:0.5314; lr:0.000063
epoch:57; metric:emoval; train:0.9500; eval:0.5546; lr:0.000063
epoch:58; metric:emoval; train:0.9564; eval:0.5434; lr:0.000063
epoch:59; metric:emoval; train:0.9561; eval:0.5326; lr:0.000063
epoch:60; metric:emoval; train:0.9501; eval:0.5286; lr:0.000063
epoch:61; metric:emoval; train:0.9462; eval:0.5200; lr:0.000063
epoch:62; metric:emoval; train:0.9399; eval:0.5544; lr:0.000063
epoch:63; metric:emoval; train:0.9446; eval:0.5214; lr:0.000063
Early stopping at epoch 63, best epoch: 33
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1-th folder, best_index: 56, duration: 3571.9889957904816 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3765; eval:0.1514; lr:0.000500
epoch:2; metric:emoval; train:0.1998; eval:0.2821; lr:0.000500
epoch:3; metric:emoval; train:0.4499; eval:0.5126; lr:0.000500
epoch:4; metric:emoval; train:0.5802; eval:0.5421; lr:0.000500
epoch:5; metric:emoval; train:0.6284; eval:0.6058; lr:0.000500
epoch:6; metric:emoval; train:0.6831; eval:0.5530; lr:0.000500
epoch:7; metric:emoval; train:0.7177; eval:0.4442; lr:0.000500
epoch:8; metric:emoval; train:0.7326; eval:0.4564; lr:0.000500
epoch:9; metric:emoval; train:0.7829; eval:0.5648; lr:0.000500
epoch:10; metric:emoval; train:0.7983; eval:0.5219; lr:0.000500
epoch:11; metric:emoval; train:0.8075; eval:0.5642; lr:0.000500
epoch:12; metric:emoval; train:0.8306; eval:0.5274; lr:0.000500
epoch:13; metric:emoval; train:0.8498; eval:0.5798; lr:0.000500
epoch:14; metric:emoval; train:0.8615; eval:0.5845; lr:0.000500
epoch:15; metric:emoval; train:0.8754; eval:0.5377; lr:0.000500
epoch:16; metric:emoval; train:0.8616; eval:0.4526; lr:0.000250
epoch:17; metric:emoval; train:0.9034; eval:0.5550; lr:0.000250
epoch:18; metric:emoval; train:0.9345; eval:0.5868; lr:0.000250
epoch:19; metric:emoval; train:0.9462; eval:0.5785; lr:0.000250
epoch:20; metric:emoval; train:0.9484; eval:0.5812; lr:0.000250
epoch:21; metric:emoval; train:0.9510; eval:0.5624; lr:0.000250
epoch:22; metric:emoval; train:0.9536; eval:0.5528; lr:0.000250
epoch:23; metric:emoval; train:0.9339; eval:0.5599; lr:0.000250
epoch:24; metric:emoval; train:0.9346; eval:0.5518; lr:0.000250
epoch:25; metric:emoval; train:0.9401; eval:0.5482; lr:0.000250
epoch:26; metric:emoval; train:0.9491; eval:0.5640; lr:0.000250
epoch:27; metric:emoval; train:0.9328; eval:0.5159; lr:0.000125
epoch:28; metric:emoval; train:0.9557; eval:0.5387; lr:0.000125
epoch:29; metric:emoval; train:0.9677; eval:0.5430; lr:0.000125
epoch:30; metric:emoval; train:0.9706; eval:0.5475; lr:0.000125
epoch:31; metric:emoval; train:0.9675; eval:0.5496; lr:0.000125
epoch:32; metric:emoval; train:0.9704; eval:0.5271; lr:0.000125
epoch:33; metric:emoval; train:0.9673; eval:0.5166; lr:0.000125
epoch:34; metric:emoval; train:0.9687; eval:0.5380; lr:0.000125
epoch:35; metric:emoval; train:0.9715; eval:0.5283; lr:0.000125
Early stopping at epoch 35, best epoch: 5
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2-th folder, best_index: 4, duration: 2042.6950895786285 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3472; eval:0.1470; lr:0.000500
epoch:2; metric:emoval; train:0.1284; eval:0.4105; lr:0.000500
epoch:3; metric:emoval; train:0.3910; eval:0.5191; lr:0.000500
epoch:4; metric:emoval; train:0.5547; eval:0.5182; lr:0.000500
epoch:5; metric:emoval; train:0.6446; eval:0.3844; lr:0.000500
epoch:6; metric:emoval; train:0.6813; eval:0.5317; lr:0.000500
epoch:7; metric:emoval; train:0.7034; eval:0.5709; lr:0.000500
epoch:8; metric:emoval; train:0.7453; eval:0.5242; lr:0.000500
epoch:9; metric:emoval; train:0.7633; eval:0.5061; lr:0.000500
epoch:10; metric:emoval; train:0.7878; eval:0.5674; lr:0.000500
epoch:11; metric:emoval; train:0.7856; eval:0.4706; lr:0.000500
epoch:12; metric:emoval; train:0.8311; eval:0.5745; lr:0.000500
epoch:13; metric:emoval; train:0.8402; eval:0.5623; lr:0.000500
epoch:14; metric:emoval; train:0.8706; eval:0.5118; lr:0.000500
epoch:15; metric:emoval; train:0.8688; eval:0.4672; lr:0.000500
epoch:16; metric:emoval; train:0.8710; eval:0.4732; lr:0.000500
epoch:17; metric:emoval; train:0.8599; eval:0.5374; lr:0.000500
epoch:18; metric:emoval; train:0.8867; eval:0.5577; lr:0.000500
epoch:19; metric:emoval; train:0.8920; eval:0.4386; lr:0.000500
epoch:20; metric:emoval; train:0.9013; eval:0.5068; lr:0.000500
epoch:21; metric:emoval; train:0.8963; eval:0.5378; lr:0.000500
epoch:22; metric:emoval; train:0.8821; eval:0.4944; lr:0.000500
epoch:23; metric:emoval; train:0.9058; eval:0.5334; lr:0.000250
epoch:24; metric:emoval; train:0.9463; eval:0.5446; lr:0.000250
epoch:25; metric:emoval; train:0.9576; eval:0.5406; lr:0.000250
epoch:26; metric:emoval; train:0.9594; eval:0.5509; lr:0.000250
epoch:27; metric:emoval; train:0.9623; eval:0.5553; lr:0.000250
epoch:28; metric:emoval; train:0.9637; eval:0.5567; lr:0.000250
epoch:29; metric:emoval; train:0.9633; eval:0.5502; lr:0.000250
epoch:30; metric:emoval; train:0.9611; eval:0.5479; lr:0.000250
epoch:31; metric:emoval; train:0.9650; eval:0.5098; lr:0.000250
epoch:32; metric:emoval; train:0.9600; eval:0.5554; lr:0.000250
epoch:33; metric:emoval; train:0.9530; eval:0.5313; lr:0.000250
epoch:34; metric:emoval; train:0.9622; eval:0.5346; lr:0.000125
epoch:35; metric:emoval; train:0.9692; eval:0.5384; lr:0.000125
epoch:36; metric:emoval; train:0.9742; eval:0.5486; lr:0.000125
epoch:37; metric:emoval; train:0.9756; eval:0.5240; lr:0.000125
epoch:38; metric:emoval; train:0.9763; eval:0.5341; lr:0.000125
epoch:39; metric:emoval; train:0.9765; eval:0.5412; lr:0.000125
epoch:40; metric:emoval; train:0.9759; eval:0.5452; lr:0.000125
epoch:41; metric:emoval; train:0.9746; eval:0.5344; lr:0.000125
epoch:42; metric:emoval; train:0.9705; eval:0.5347; lr:0.000125
Early stopping at epoch 42, best epoch: 12
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3-th folder, best_index: 11, duration: 2483.901927471161 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3066; eval:0.0215; lr:0.000500
epoch:2; metric:emoval; train:0.1273; eval:0.2893; lr:0.000500
epoch:3; metric:emoval; train:0.4264; eval:0.4055; lr:0.000500
epoch:4; metric:emoval; train:0.5657; eval:0.5421; lr:0.000500
epoch:5; metric:emoval; train:0.6527; eval:0.4621; lr:0.000500
epoch:6; metric:emoval; train:0.6766; eval:0.4993; lr:0.000500
epoch:7; metric:emoval; train:0.6928; eval:0.4155; lr:0.000500
epoch:8; metric:emoval; train:0.7146; eval:0.5097; lr:0.000500
epoch:9; metric:emoval; train:0.7517; eval:0.5153; lr:0.000500
epoch:10; metric:emoval; train:0.7705; eval:0.4781; lr:0.000500
epoch:11; metric:emoval; train:0.8128; eval:0.5106; lr:0.000500
epoch:12; metric:emoval; train:0.8420; eval:0.4658; lr:0.000500
epoch:13; metric:emoval; train:0.8548; eval:0.5032; lr:0.000500
epoch:14; metric:emoval; train:0.8525; eval:0.5093; lr:0.000500
epoch:15; metric:emoval; train:0.8635; eval:0.5129; lr:0.000250
epoch:16; metric:emoval; train:0.9123; eval:0.5363; lr:0.000250
epoch:17; metric:emoval; train:0.9316; eval:0.5325; lr:0.000250
epoch:18; metric:emoval; train:0.9467; eval:0.5452; lr:0.000250
epoch:19; metric:emoval; train:0.9416; eval:0.5048; lr:0.000250
epoch:20; metric:emoval; train:0.9427; eval:0.5462; lr:0.000250
epoch:21; metric:emoval; train:0.9489; eval:0.5144; lr:0.000250
epoch:22; metric:emoval; train:0.9518; eval:0.5240; lr:0.000250
epoch:23; metric:emoval; train:0.9509; eval:0.5049; lr:0.000250
epoch:24; metric:emoval; train:0.9483; eval:0.4663; lr:0.000250
epoch:25; metric:emoval; train:0.9294; eval:0.4812; lr:0.000250
epoch:26; metric:emoval; train:0.9435; eval:0.5150; lr:0.000250
epoch:27; metric:emoval; train:0.9521; eval:0.4846; lr:0.000250
epoch:28; metric:emoval; train:0.9527; eval:0.5064; lr:0.000250
epoch:29; metric:emoval; train:0.9275; eval:0.5522; lr:0.000250
epoch:30; metric:emoval; train:0.9432; eval:0.4762; lr:0.000250
epoch:31; metric:emoval; train:0.9384; eval:0.5142; lr:0.000250
epoch:32; metric:emoval; train:0.9432; eval:0.5226; lr:0.000250
epoch:33; metric:emoval; train:0.9523; eval:0.5255; lr:0.000250
epoch:34; metric:emoval; train:0.9552; eval:0.5301; lr:0.000250
epoch:35; metric:emoval; train:0.9544; eval:0.4958; lr:0.000250
epoch:36; metric:emoval; train:0.9555; eval:0.5081; lr:0.000250
epoch:37; metric:emoval; train:0.9399; eval:0.5207; lr:0.000250
epoch:38; metric:emoval; train:0.9562; eval:0.5041; lr:0.000250
epoch:39; metric:emoval; train:0.9559; eval:0.4310; lr:0.000250
epoch:40; metric:emoval; train:0.9529; eval:0.4945; lr:0.000125
epoch:41; metric:emoval; train:0.9725; eval:0.5290; lr:0.000125
epoch:42; metric:emoval; train:0.9718; eval:0.5127; lr:0.000125
epoch:43; metric:emoval; train:0.9712; eval:0.5098; lr:0.000125
epoch:44; metric:emoval; train:0.9707; eval:0.5031; lr:0.000125
epoch:45; metric:emoval; train:0.9650; eval:0.5237; lr:0.000125
epoch:46; metric:emoval; train:0.9653; eval:0.5144; lr:0.000125
epoch:47; metric:emoval; train:0.9551; eval:0.5326; lr:0.000125
epoch:48; metric:emoval; train:0.9624; eval:0.4945; lr:0.000125
epoch:49; metric:emoval; train:0.9557; eval:0.5104; lr:0.000125
epoch:50; metric:emoval; train:0.9549; eval:0.5300; lr:0.000125
epoch:51; metric:emoval; train:0.9567; eval:0.5079; lr:0.000063
epoch:52; metric:emoval; train:0.9581; eval:0.5198; lr:0.000063
epoch:53; metric:emoval; train:0.9577; eval:0.5100; lr:0.000063
epoch:54; metric:emoval; train:0.9618; eval:0.4864; lr:0.000063
epoch:55; metric:emoval; train:0.9552; eval:0.5182; lr:0.000063
epoch:56; metric:emoval; train:0.9547; eval:0.5402; lr:0.000063
epoch:57; metric:emoval; train:0.9487; eval:0.5060; lr:0.000063
epoch:58; metric:emoval; train:0.9453; eval:0.5135; lr:0.000063
epoch:59; metric:emoval; train:0.9503; eval:0.5224; lr:0.000063
Early stopping at epoch 59, best epoch: 29
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4-th folder, best_index: 28, duration: 3075.192664861679 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3427; eval:-0.1282; lr:0.000500
epoch:2; metric:emoval; train:0.1544; eval:0.3426; lr:0.000500
epoch:3; metric:emoval; train:0.4177; eval:0.4407; lr:0.000500
epoch:4; metric:emoval; train:0.5708; eval:0.4737; lr:0.000500
epoch:5; metric:emoval; train:0.6163; eval:0.3601; lr:0.000500
epoch:6; metric:emoval; train:0.6702; eval:0.4679; lr:0.000500
epoch:7; metric:emoval; train:0.7355; eval:0.3732; lr:0.000500
epoch:8; metric:emoval; train:0.7488; eval:0.4881; lr:0.000500
epoch:9; metric:emoval; train:0.7627; eval:0.5031; lr:0.000500
epoch:10; metric:emoval; train:0.8081; eval:0.5219; lr:0.000500
epoch:11; metric:emoval; train:0.8205; eval:0.4877; lr:0.000500
epoch:12; metric:emoval; train:0.8374; eval:0.4851; lr:0.000500
epoch:13; metric:emoval; train:0.8447; eval:0.4944; lr:0.000500
epoch:14; metric:emoval; train:0.8692; eval:0.4504; lr:0.000500
epoch:15; metric:emoval; train:0.8827; eval:0.4980; lr:0.000500
epoch:16; metric:emoval; train:0.8933; eval:0.4763; lr:0.000500
epoch:17; metric:emoval; train:0.8840; eval:0.4927; lr:0.000500
epoch:18; metric:emoval; train:0.8634; eval:0.4847; lr:0.000500
epoch:19; metric:emoval; train:0.8767; eval:0.4316; lr:0.000500
epoch:20; metric:emoval; train:0.8804; eval:0.4645; lr:0.000500
epoch:21; metric:emoval; train:0.9185; eval:0.4337; lr:0.000250
epoch:22; metric:emoval; train:0.9461; eval:0.4733; lr:0.000250
epoch:23; metric:emoval; train:0.9599; eval:0.4549; lr:0.000250
epoch:24; metric:emoval; train:0.9570; eval:0.4765; lr:0.000250
epoch:25; metric:emoval; train:0.9645; eval:0.4627; lr:0.000250
epoch:26; metric:emoval; train:0.9620; eval:0.4588; lr:0.000250
epoch:27; metric:emoval; train:0.9620; eval:0.4442; lr:0.000250
epoch:28; metric:emoval; train:0.9642; eval:0.4573; lr:0.000250
epoch:29; metric:emoval; train:0.9634; eval:0.4655; lr:0.000250
epoch:30; metric:emoval; train:0.9635; eval:0.4657; lr:0.000250
epoch:31; metric:emoval; train:0.9670; eval:0.4406; lr:0.000250
epoch:32; metric:emoval; train:0.9586; eval:0.4599; lr:0.000125
epoch:33; metric:emoval; train:0.9677; eval:0.4498; lr:0.000125
epoch:34; metric:emoval; train:0.9749; eval:0.4704; lr:0.000125
epoch:35; metric:emoval; train:0.9759; eval:0.4550; lr:0.000125
epoch:36; metric:emoval; train:0.9754; eval:0.4485; lr:0.000125
epoch:37; metric:emoval; train:0.9756; eval:0.4495; lr:0.000125
epoch:38; metric:emoval; train:0.9768; eval:0.4431; lr:0.000125
epoch:39; metric:emoval; train:0.9768; eval:0.4592; lr:0.000125
epoch:40; metric:emoval; train:0.9765; eval:0.4222; lr:0.000125
Early stopping at epoch 40, best epoch: 10
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5-th folder, best_index: 9, duration: 1302.103704214096 >>>>>
====== Prediction and Saving =======
save results in ./saved-trimodal/result/cv_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7348_acc:0.7374_val:0.6919_1770135580.29796.npz
save results in ./saved-trimodal/result/test1_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7990_acc:0.8005_val:0.6928_1770135580.29796.npz
save results in ./saved-trimodal/result/test2_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7570_acc:0.7597_val:0.6429_1770135580.29796.npz
save results in ./saved-trimodal/result/test3_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8834_acc:0.8825_val:80.6938_1770135580.29796.npz
