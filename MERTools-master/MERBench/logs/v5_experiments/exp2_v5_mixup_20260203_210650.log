====== Params Pre-analysis =======
args:  Namespace(audio_feature='chinese-hubert-large-UTT', batch_size=32, contrastive_temperature=0.07, contrastive_weight=0.1, cross_kl_weight=0.01, dataset='MER2023', debug=False, dropout=0.35, e2e_dim=None, e2e_name=None, early_stopping_patience=30, epochs=100, feat_scale=1, feat_type='utt', focal_gamma=2.0, fusion_temperature=1.0, gate_alpha=0.5, gpu=0, grad_clip=1.0, hidden_dim=128, hyper_path=None, kl_warmup_epochs=20, kl_weight=0.01, l2=5e-05, label_smoothing=0.1, lr=0.0005, lr_adjust='case1', lr_factor=0.5, lr_patience=10, mixup_alpha=0.4, modality_dropout=0.15, modality_dropout_warmup=20, model='attention_robust_v5', n_classes=None, num_attention_heads=4, num_workers=0, print_iters=100000000.0, recon_weight=0.1, save_iters=100000000.0, save_root='./saved-trimodal', savemodel=False, test_dataset=None, text_feature='Baichuan-13B-Base-UTT', train_dataset=None, use_contrastive=True, use_dynamic_kl=True, use_gated_fusion=True, use_mixup=True, use_modality_dropout=True, use_proxy_attention=True, use_vae=True, video_feature='clip-vit-large-patch14-UTT')
====== Reading Data =======
train: sample number 3373
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/3373 [00:00<?, ?it/s] 34%|███▍      | 1145/3373 [00:00<00:00, 11434.06it/s] 68%|██████▊   | 2289/3373 [00:00<00:00, 11389.00it/s]100%|██████████| 3373/3373 [00:00<00:00, 7099.27it/s] 
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/3373 [00:00<?, ?it/s] 12%|█▏        | 416/3373 [00:00<00:00, 4151.04it/s] 25%|██▌       | 858/3373 [00:00<00:00, 4299.80it/s] 46%|████▋     | 1568/3373 [00:00<00:00, 5561.25it/s] 63%|██████▎   | 2124/3373 [00:00<00:00, 5212.08it/s] 79%|███████▊  | 2649/3373 [00:00<00:00, 4214.40it/s] 92%|█████████▏| 3096/3373 [00:00<00:00, 4138.73it/s]100%|██████████| 3373/3373 [00:00<00:00, 4349.85it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/3373 [00:00<?, ?it/s] 33%|███▎      | 1109/3373 [00:00<00:00, 11089.40it/s] 67%|██████▋   | 2244/3373 [00:00<00:00, 11227.42it/s]100%|█████████▉| 3367/3373 [00:00<00:00, 7735.22it/s] 100%|██████████| 3373/3373 [00:00<00:00, 8440.70it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test1: sample number 411
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/411 [00:00<?, ?it/s]100%|██████████| 411/411 [00:00<00:00, 8729.86it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/411 [00:00<?, ?it/s]100%|██████████| 411/411 [00:00<00:00, 9817.24it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/411 [00:00<?, ?it/s]100%|██████████| 411/411 [00:00<00:00, 14174.96it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test2: sample number 412
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/412 [00:00<?, ?it/s]100%|██████████| 412/412 [00:00<00:00, 13316.69it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/412 [00:00<?, ?it/s]100%|██████████| 412/412 [00:00<00:00, 11470.27it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/412 [00:00<?, ?it/s]100%|██████████| 412/412 [00:00<00:00, 12650.19it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test3: sample number 834
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/834 [00:00<?, ?it/s]100%|██████████| 834/834 [00:00<00:00, 14824.51it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/834 [00:00<?, ?it/s]100%|██████████| 834/834 [00:00<00:00, 11358.78it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/834 [00:00<?, ?it/s]100%|██████████| 834/834 [00:00<00:00, 15827.71it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
train&val folder:5; test sets:3
audio dimension: 1024; text dimension: 5120; video dimension: 768
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3425; eval:-0.0622; lr:0.000500
epoch:2; metric:emoval; train:0.0895; eval:0.2567; lr:0.000500
epoch:3; metric:emoval; train:0.3952; eval:0.4414; lr:0.000500
epoch:4; metric:emoval; train:0.5330; eval:0.4687; lr:0.000500
epoch:5; metric:emoval; train:0.6187; eval:0.4262; lr:0.000500
epoch:6; metric:emoval; train:0.6498; eval:0.4467; lr:0.000500
epoch:7; metric:emoval; train:0.7106; eval:0.5194; lr:0.000500
epoch:8; metric:emoval; train:0.7192; eval:0.5225; lr:0.000500
epoch:9; metric:emoval; train:0.7826; eval:0.4347; lr:0.000500
epoch:10; metric:emoval; train:0.7685; eval:0.4666; lr:0.000500
epoch:11; metric:emoval; train:0.7738; eval:0.5296; lr:0.000500
epoch:12; metric:emoval; train:0.8002; eval:0.5119; lr:0.000500
epoch:13; metric:emoval; train:0.8384; eval:0.5429; lr:0.000500
epoch:14; metric:emoval; train:0.8544; eval:0.4790; lr:0.000500
epoch:15; metric:emoval; train:0.8377; eval:0.4840; lr:0.000500
epoch:16; metric:emoval; train:0.8580; eval:0.5101; lr:0.000500
epoch:17; metric:emoval; train:0.8589; eval:0.4129; lr:0.000500
epoch:18; metric:emoval; train:0.8516; eval:0.5222; lr:0.000500
epoch:19; metric:emoval; train:0.8776; eval:0.4447; lr:0.000500
epoch:20; metric:emoval; train:0.8739; eval:0.5254; lr:0.000500
epoch:21; metric:emoval; train:0.8965; eval:0.5280; lr:0.000500
epoch:22; metric:emoval; train:0.8880; eval:0.4616; lr:0.000500
epoch:23; metric:emoval; train:0.8987; eval:0.4924; lr:0.000500
epoch:24; metric:emoval; train:0.8929; eval:0.4374; lr:0.000250
epoch:25; metric:emoval; train:0.9151; eval:0.5309; lr:0.000250
epoch:26; metric:emoval; train:0.9266; eval:0.5244; lr:0.000250
epoch:27; metric:emoval; train:0.9239; eval:0.4874; lr:0.000250
epoch:28; metric:emoval; train:0.9314; eval:0.5434; lr:0.000250
epoch:29; metric:emoval; train:0.9227; eval:0.5232; lr:0.000250
epoch:30; metric:emoval; train:0.9325; eval:0.5062; lr:0.000250
epoch:31; metric:emoval; train:0.9263; eval:0.5322; lr:0.000250
epoch:32; metric:emoval; train:0.9118; eval:0.5110; lr:0.000250
epoch:33; metric:emoval; train:0.9093; eval:0.5132; lr:0.000250
epoch:34; metric:emoval; train:0.8954; eval:0.5189; lr:0.000250
epoch:35; metric:emoval; train:0.9166; eval:0.5023; lr:0.000250
epoch:36; metric:emoval; train:0.9161; eval:0.5101; lr:0.000250
epoch:37; metric:emoval; train:0.8856; eval:0.5198; lr:0.000250
epoch:38; metric:emoval; train:0.9013; eval:0.5325; lr:0.000250
epoch:39; metric:emoval; train:0.8985; eval:0.5320; lr:0.000125
epoch:40; metric:emoval; train:0.8989; eval:0.5476; lr:0.000125
epoch:41; metric:emoval; train:0.9236; eval:0.5094; lr:0.000125
epoch:42; metric:emoval; train:0.9161; eval:0.5449; lr:0.000125
epoch:43; metric:emoval; train:0.9154; eval:0.5392; lr:0.000125
epoch:44; metric:emoval; train:0.9224; eval:0.5470; lr:0.000125
epoch:45; metric:emoval; train:0.9201; eval:0.5337; lr:0.000125
epoch:46; metric:emoval; train:0.9280; eval:0.5463; lr:0.000125
epoch:47; metric:emoval; train:0.9238; eval:0.5384; lr:0.000125
epoch:48; metric:emoval; train:0.9134; eval:0.5433; lr:0.000125
epoch:49; metric:emoval; train:0.9203; eval:0.5118; lr:0.000125
epoch:50; metric:emoval; train:0.9266; eval:0.5159; lr:0.000125
epoch:51; metric:emoval; train:0.9305; eval:0.5222; lr:0.000063
epoch:52; metric:emoval; train:0.9285; eval:0.5290; lr:0.000063
epoch:53; metric:emoval; train:0.9314; eval:0.5105; lr:0.000063
epoch:54; metric:emoval; train:0.9225; eval:0.5256; lr:0.000063
epoch:55; metric:emoval; train:0.9388; eval:0.5059; lr:0.000063
epoch:56; metric:emoval; train:0.9309; eval:0.5161; lr:0.000063
epoch:57; metric:emoval; train:0.9345; eval:0.5246; lr:0.000063
epoch:58; metric:emoval; train:0.9374; eval:0.5292; lr:0.000063
epoch:59; metric:emoval; train:0.9365; eval:0.5251; lr:0.000063
epoch:60; metric:emoval; train:0.9393; eval:0.5075; lr:0.000063
epoch:61; metric:emoval; train:0.9343; eval:0.5053; lr:0.000063
epoch:62; metric:emoval; train:0.9364; eval:0.5410; lr:0.000031
epoch:63; metric:emoval; train:0.9361; eval:0.5311; lr:0.000031
epoch:64; metric:emoval; train:0.9431; eval:0.5139; lr:0.000031
epoch:65; metric:emoval; train:0.9442; eval:0.5108; lr:0.000031
epoch:66; metric:emoval; train:0.9506; eval:0.5105; lr:0.000031
epoch:67; metric:emoval; train:0.9405; eval:0.5119; lr:0.000031
epoch:68; metric:emoval; train:0.9482; eval:0.5122; lr:0.000031
epoch:69; metric:emoval; train:0.9456; eval:0.4965; lr:0.000031
epoch:70; metric:emoval; train:0.9429; eval:0.5047; lr:0.000031
Early stopping at epoch 70, best epoch: 40
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1-th folder, best_index: 39, duration: 2740.1853320598602 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3559; eval:-0.0027; lr:0.000500
epoch:2; metric:emoval; train:0.1571; eval:0.3898; lr:0.000500
epoch:3; metric:emoval; train:0.4323; eval:0.4492; lr:0.000500
epoch:4; metric:emoval; train:0.5488; eval:0.5230; lr:0.000500
epoch:5; metric:emoval; train:0.6259; eval:0.5581; lr:0.000500
epoch:6; metric:emoval; train:0.6658; eval:0.4787; lr:0.000500
epoch:7; metric:emoval; train:0.7022; eval:0.4045; lr:0.000500
epoch:8; metric:emoval; train:0.7392; eval:0.5197; lr:0.000500
epoch:9; metric:emoval; train:0.7630; eval:0.4910; lr:0.000500
epoch:10; metric:emoval; train:0.7903; eval:0.4642; lr:0.000500
epoch:11; metric:emoval; train:0.8316; eval:0.5739; lr:0.000500
epoch:12; metric:emoval; train:0.8223; eval:0.4926; lr:0.000500
epoch:13; metric:emoval; train:0.8500; eval:0.5654; lr:0.000500
epoch:14; metric:emoval; train:0.8797; eval:0.5285; lr:0.000500
epoch:15; metric:emoval; train:0.8499; eval:0.5244; lr:0.000500
epoch:16; metric:emoval; train:0.8658; eval:0.4501; lr:0.000500
epoch:17; metric:emoval; train:0.8662; eval:0.5524; lr:0.000500
epoch:18; metric:emoval; train:0.8971; eval:0.5178; lr:0.000500
epoch:19; metric:emoval; train:0.9042; eval:0.5580; lr:0.000500
epoch:20; metric:emoval; train:0.9128; eval:0.5391; lr:0.000500
epoch:21; metric:emoval; train:0.8776; eval:0.4966; lr:0.000500
epoch:22; metric:emoval; train:0.8840; eval:0.5387; lr:0.000250
epoch:23; metric:emoval; train:0.9180; eval:0.5797; lr:0.000250
epoch:24; metric:emoval; train:0.9316; eval:0.5554; lr:0.000250
epoch:25; metric:emoval; train:0.9345; eval:0.5683; lr:0.000250
epoch:26; metric:emoval; train:0.9392; eval:0.5609; lr:0.000250
epoch:27; metric:emoval; train:0.9214; eval:0.5129; lr:0.000250
epoch:28; metric:emoval; train:0.9325; eval:0.5584; lr:0.000250
epoch:29; metric:emoval; train:0.9189; eval:0.5515; lr:0.000250
epoch:30; metric:emoval; train:0.9262; eval:0.5615; lr:0.000250
epoch:31; metric:emoval; train:0.9212; eval:0.5557; lr:0.000250
epoch:32; metric:emoval; train:0.9252; eval:0.5182; lr:0.000250
epoch:33; metric:emoval; train:0.8993; eval:0.5306; lr:0.000250
epoch:34; metric:emoval; train:0.9080; eval:0.5277; lr:0.000125
epoch:35; metric:emoval; train:0.9144; eval:0.5250; lr:0.000125
epoch:36; metric:emoval; train:0.9295; eval:0.5478; lr:0.000125
epoch:37; metric:emoval; train:0.9295; eval:0.5258; lr:0.000125
epoch:38; metric:emoval; train:0.9199; eval:0.5411; lr:0.000125
epoch:39; metric:emoval; train:0.9217; eval:0.5603; lr:0.000125
epoch:40; metric:emoval; train:0.9177; eval:0.5213; lr:0.000125
epoch:41; metric:emoval; train:0.9148; eval:0.5167; lr:0.000125
epoch:42; metric:emoval; train:0.9163; eval:0.5468; lr:0.000125
epoch:43; metric:emoval; train:0.9244; eval:0.5524; lr:0.000125
epoch:44; metric:emoval; train:0.9227; eval:0.5259; lr:0.000125
epoch:45; metric:emoval; train:0.9077; eval:0.5383; lr:0.000063
epoch:46; metric:emoval; train:0.9268; eval:0.5522; lr:0.000063
epoch:47; metric:emoval; train:0.9239; eval:0.5450; lr:0.000063
epoch:48; metric:emoval; train:0.9224; eval:0.5452; lr:0.000063
epoch:49; metric:emoval; train:0.9296; eval:0.5248; lr:0.000063
epoch:50; metric:emoval; train:0.9317; eval:0.5280; lr:0.000063
epoch:51; metric:emoval; train:0.9277; eval:0.5378; lr:0.000063
epoch:52; metric:emoval; train:0.9195; eval:0.5270; lr:0.000063
epoch:53; metric:emoval; train:0.9319; eval:0.5203; lr:0.000063
Early stopping at epoch 53, best epoch: 23
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2-th folder, best_index: 22, duration: 3230.3997988700867 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3629; eval:0.0430; lr:0.000500
epoch:2; metric:emoval; train:0.1465; eval:0.2725; lr:0.000500
epoch:3; metric:emoval; train:0.4083; eval:0.3510; lr:0.000500
epoch:4; metric:emoval; train:0.5539; eval:0.2239; lr:0.000500
epoch:5; metric:emoval; train:0.6223; eval:0.2771; lr:0.000500
epoch:6; metric:emoval; train:0.6618; eval:0.5568; lr:0.000500
epoch:7; metric:emoval; train:0.7192; eval:0.5234; lr:0.000500
epoch:8; metric:emoval; train:0.7437; eval:0.5389; lr:0.000500
epoch:9; metric:emoval; train:0.7775; eval:0.5280; lr:0.000500
epoch:10; metric:emoval; train:0.7854; eval:0.5541; lr:0.000500
epoch:11; metric:emoval; train:0.8239; eval:0.4705; lr:0.000500
epoch:12; metric:emoval; train:0.8443; eval:0.5635; lr:0.000500
epoch:13; metric:emoval; train:0.8473; eval:0.5587; lr:0.000500
epoch:14; metric:emoval; train:0.8517; eval:0.5384; lr:0.000500
epoch:15; metric:emoval; train:0.8737; eval:0.5394; lr:0.000500
epoch:16; metric:emoval; train:0.8802; eval:0.5270; lr:0.000500
epoch:17; metric:emoval; train:0.8794; eval:0.4807; lr:0.000500
epoch:18; metric:emoval; train:0.8631; eval:0.5143; lr:0.000500
epoch:19; metric:emoval; train:0.8721; eval:0.5063; lr:0.000500
epoch:20; metric:emoval; train:0.8953; eval:0.4801; lr:0.000500
epoch:21; metric:emoval; train:0.8677; eval:0.5450; lr:0.000500
epoch:22; metric:emoval; train:0.8907; eval:0.4986; lr:0.000500
epoch:23; metric:emoval; train:0.8775; eval:0.4050; lr:0.000250
epoch:24; metric:emoval; train:0.9220; eval:0.5588; lr:0.000250
epoch:25; metric:emoval; train:0.9368; eval:0.4754; lr:0.000250
epoch:26; metric:emoval; train:0.9246; eval:0.5470; lr:0.000250
epoch:27; metric:emoval; train:0.9308; eval:0.5299; lr:0.000250
epoch:28; metric:emoval; train:0.9272; eval:0.4569; lr:0.000250
epoch:29; metric:emoval; train:0.9101; eval:0.5333; lr:0.000250
epoch:30; metric:emoval; train:0.9338; eval:0.5071; lr:0.000250
epoch:31; metric:emoval; train:0.9148; eval:0.5472; lr:0.000250
epoch:32; metric:emoval; train:0.9154; eval:0.4849; lr:0.000250
epoch:33; metric:emoval; train:0.8965; eval:0.5650; lr:0.000250
epoch:34; metric:emoval; train:0.8966; eval:0.4437; lr:0.000250
epoch:35; metric:emoval; train:0.9105; eval:0.5265; lr:0.000250
epoch:36; metric:emoval; train:0.8944; eval:0.5274; lr:0.000250
epoch:37; metric:emoval; train:0.8949; eval:0.5398; lr:0.000250
epoch:38; metric:emoval; train:0.9103; eval:0.5420; lr:0.000250
epoch:39; metric:emoval; train:0.8959; eval:0.4862; lr:0.000250
epoch:40; metric:emoval; train:0.8996; eval:0.5179; lr:0.000250
epoch:41; metric:emoval; train:0.8920; eval:0.5066; lr:0.000250
epoch:42; metric:emoval; train:0.8940; eval:0.5117; lr:0.000250
epoch:43; metric:emoval; train:0.9032; eval:0.4177; lr:0.000250
epoch:44; metric:emoval; train:0.8826; eval:0.5078; lr:0.000125
epoch:45; metric:emoval; train:0.9044; eval:0.5275; lr:0.000125
epoch:46; metric:emoval; train:0.9050; eval:0.5121; lr:0.000125
epoch:47; metric:emoval; train:0.9187; eval:0.4782; lr:0.000125
epoch:48; metric:emoval; train:0.9296; eval:0.5281; lr:0.000125
epoch:49; metric:emoval; train:0.9145; eval:0.4915; lr:0.000125
epoch:50; metric:emoval; train:0.9275; eval:0.5313; lr:0.000125
epoch:51; metric:emoval; train:0.9092; eval:0.4999; lr:0.000125
epoch:52; metric:emoval; train:0.9180; eval:0.4956; lr:0.000125
epoch:53; metric:emoval; train:0.9378; eval:0.5243; lr:0.000125
epoch:54; metric:emoval; train:0.9291; eval:0.5215; lr:0.000125
epoch:55; metric:emoval; train:0.9197; eval:0.4922; lr:0.000063
epoch:56; metric:emoval; train:0.9383; eval:0.4958; lr:0.000063
epoch:57; metric:emoval; train:0.9265; eval:0.4855; lr:0.000063
epoch:58; metric:emoval; train:0.9336; eval:0.5118; lr:0.000063
epoch:59; metric:emoval; train:0.9333; eval:0.4867; lr:0.000063
epoch:60; metric:emoval; train:0.9320; eval:0.5011; lr:0.000063
epoch:61; metric:emoval; train:0.9328; eval:0.4926; lr:0.000063
epoch:62; metric:emoval; train:0.9323; eval:0.5159; lr:0.000063
epoch:63; metric:emoval; train:0.9381; eval:0.4881; lr:0.000063
Early stopping at epoch 63, best epoch: 33
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3-th folder, best_index: 32, duration: 3848.2983043193817 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3358; eval:-0.0766; lr:0.000500
epoch:2; metric:emoval; train:0.2020; eval:0.4312; lr:0.000500
epoch:3; metric:emoval; train:0.4544; eval:0.5548; lr:0.000500
epoch:4; metric:emoval; train:0.5807; eval:0.5325; lr:0.000500
epoch:5; metric:emoval; train:0.6505; eval:0.4933; lr:0.000500
epoch:6; metric:emoval; train:0.6633; eval:0.5199; lr:0.000500
epoch:7; metric:emoval; train:0.7283; eval:0.4713; lr:0.000500
epoch:8; metric:emoval; train:0.7596; eval:0.5480; lr:0.000500
epoch:9; metric:emoval; train:0.7759; eval:0.5209; lr:0.000500
epoch:10; metric:emoval; train:0.8066; eval:0.5378; lr:0.000500
epoch:11; metric:emoval; train:0.8259; eval:0.5355; lr:0.000500
epoch:12; metric:emoval; train:0.8420; eval:0.5684; lr:0.000500
epoch:13; metric:emoval; train:0.8515; eval:0.4714; lr:0.000500
epoch:14; metric:emoval; train:0.8075; eval:0.4877; lr:0.000500
epoch:15; metric:emoval; train:0.7947; eval:0.5027; lr:0.000500
epoch:16; metric:emoval; train:0.8473; eval:0.4993; lr:0.000500
epoch:17; metric:emoval; train:0.8698; eval:0.5450; lr:0.000500
epoch:18; metric:emoval; train:0.8930; eval:0.5242; lr:0.000500
epoch:19; metric:emoval; train:0.8860; eval:0.5170; lr:0.000500
epoch:20; metric:emoval; train:0.8690; eval:0.5481; lr:0.000500
epoch:21; metric:emoval; train:0.8919; eval:0.4855; lr:0.000500
epoch:22; metric:emoval; train:0.9054; eval:0.5574; lr:0.000500
epoch:23; metric:emoval; train:0.8751; eval:0.5011; lr:0.000250
epoch:24; metric:emoval; train:0.9267; eval:0.5399; lr:0.000250
epoch:25; metric:emoval; train:0.9233; eval:0.5203; lr:0.000250
epoch:26; metric:emoval; train:0.9390; eval:0.5392; lr:0.000250
epoch:27; metric:emoval; train:0.9303; eval:0.5552; lr:0.000250
epoch:28; metric:emoval; train:0.9416; eval:0.5327; lr:0.000250
epoch:29; metric:emoval; train:0.9289; eval:0.5289; lr:0.000250
epoch:30; metric:emoval; train:0.9312; eval:0.5532; lr:0.000250
epoch:31; metric:emoval; train:0.9215; eval:0.5188; lr:0.000250
epoch:32; metric:emoval; train:0.8926; eval:0.4673; lr:0.000250
epoch:33; metric:emoval; train:0.9145; eval:0.5312; lr:0.000250
epoch:34; metric:emoval; train:0.9053; eval:0.5288; lr:0.000125
epoch:35; metric:emoval; train:0.9182; eval:0.5312; lr:0.000125
epoch:36; metric:emoval; train:0.9236; eval:0.5508; lr:0.000125
epoch:37; metric:emoval; train:0.9163; eval:0.5399; lr:0.000125
epoch:38; metric:emoval; train:0.9138; eval:0.5432; lr:0.000125
epoch:39; metric:emoval; train:0.9280; eval:0.5168; lr:0.000125
epoch:40; metric:emoval; train:0.9145; eval:0.5391; lr:0.000125
epoch:41; metric:emoval; train:0.9104; eval:0.5390; lr:0.000125
epoch:42; metric:emoval; train:0.9014; eval:0.5257; lr:0.000125
Early stopping at epoch 42, best epoch: 12
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4-th folder, best_index: 11, duration: 1975.3979058265686 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3981; eval:-0.0620; lr:0.000500
epoch:2; metric:emoval; train:0.0331; eval:0.2783; lr:0.000500
epoch:3; metric:emoval; train:0.3848; eval:0.3420; lr:0.000500
epoch:4; metric:emoval; train:0.5262; eval:0.4583; lr:0.000500
epoch:5; metric:emoval; train:0.6165; eval:0.4848; lr:0.000500
epoch:6; metric:emoval; train:0.6813; eval:0.4475; lr:0.000500
epoch:7; metric:emoval; train:0.7211; eval:0.5442; lr:0.000500
epoch:8; metric:emoval; train:0.7592; eval:0.4280; lr:0.000500
epoch:9; metric:emoval; train:0.7764; eval:0.4817; lr:0.000500
epoch:10; metric:emoval; train:0.8106; eval:0.5165; lr:0.000500
epoch:11; metric:emoval; train:0.8034; eval:0.4867; lr:0.000500
epoch:12; metric:emoval; train:0.8580; eval:0.4477; lr:0.000500
epoch:13; metric:emoval; train:0.8591; eval:0.4549; lr:0.000500
epoch:14; metric:emoval; train:0.8455; eval:0.4707; lr:0.000500
epoch:15; metric:emoval; train:0.8768; eval:0.4619; lr:0.000500
epoch:16; metric:emoval; train:0.8898; eval:0.5090; lr:0.000500
epoch:17; metric:emoval; train:0.8962; eval:0.4899; lr:0.000500
epoch:18; metric:emoval; train:0.9076; eval:0.4792; lr:0.000250
epoch:19; metric:emoval; train:0.9254; eval:0.5264; lr:0.000250
epoch:20; metric:emoval; train:0.9485; eval:0.5026; lr:0.000250
epoch:21; metric:emoval; train:0.9568; eval:0.5003; lr:0.000250
epoch:22; metric:emoval; train:0.9513; eval:0.4913; lr:0.000250
epoch:23; metric:emoval; train:0.9401; eval:0.4797; lr:0.000250
epoch:24; metric:emoval; train:0.9279; eval:0.4738; lr:0.000250
epoch:25; metric:emoval; train:0.9369; eval:0.4939; lr:0.000250
epoch:26; metric:emoval; train:0.9142; eval:0.4365; lr:0.000250
epoch:27; metric:emoval; train:0.9020; eval:0.5140; lr:0.000250
epoch:28; metric:emoval; train:0.9103; eval:0.4648; lr:0.000250
epoch:29; metric:emoval; train:0.9208; eval:0.4889; lr:0.000125
epoch:30; metric:emoval; train:0.9324; eval:0.5277; lr:0.000125
epoch:31; metric:emoval; train:0.9384; eval:0.4706; lr:0.000125
epoch:32; metric:emoval; train:0.9362; eval:0.4997; lr:0.000125
epoch:33; metric:emoval; train:0.9281; eval:0.4977; lr:0.000125
epoch:34; metric:emoval; train:0.9232; eval:0.4852; lr:0.000125
epoch:35; metric:emoval; train:0.9310; eval:0.4954; lr:0.000125
epoch:36; metric:emoval; train:0.9239; eval:0.5047; lr:0.000125
epoch:37; metric:emoval; train:0.9349; eval:0.5006; lr:0.000125
Early stopping at epoch 37, best epoch: 7
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5-th folder, best_index: 6, duration: 1152.3159222602844 >>>>>
====== Prediction and Saving =======
save results in ./saved-trimodal/result/cv_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7274_acc:0.7255_val:0.6656_1770135815.6988297.npz
save results in ./saved-trimodal/result/test1_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8000_acc:0.8005_val:0.6392_1770135815.6988297.npz
save results in ./saved-trimodal/result/test2_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7581_acc:0.7573_val:0.5998_1770135815.6988297.npz
save results in ./saved-trimodal/result/test3_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8821_acc:0.8801_val:79.2648_1770135815.6988297.npz
