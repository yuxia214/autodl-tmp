====== Params Pre-analysis =======
args:  Namespace(audio_feature='chinese-hubert-large-UTT', batch_size=32, contrastive_temperature=0.07, contrastive_weight=0.1, cross_kl_weight=0.01, dataset='MER2023', debug=False, dropout=0.35, e2e_dim=None, e2e_name=None, early_stopping_patience=30, epochs=100, feat_scale=1, feat_type='utt', focal_gamma=2.0, fusion_temperature=1.0, gate_alpha=0.5, gpu=0, grad_clip=1.0, hidden_dim=128, hyper_path=None, kl_warmup_epochs=20, kl_weight=0.05, l2=5e-05, label_smoothing=0.1, lr=0.0005, lr_adjust='case1', lr_factor=0.5, lr_patience=10, mixup_alpha=0.4, modality_dropout=0.15, modality_dropout_warmup=20, model='attention_robust_v5', n_classes=None, num_attention_heads=4, num_workers=0, print_iters=100000000.0, recon_weight=0.1, save_iters=100000000.0, save_root='./saved-trimodal', savemodel=False, test_dataset=None, text_feature='Baichuan-13B-Base-UTT', train_dataset=None, use_contrastive=True, use_dynamic_kl=True, use_gated_fusion=True, use_mixup=False, use_modality_dropout=True, use_proxy_attention=True, use_vae=True, video_feature='clip-vit-large-patch14-UTT')
====== Reading Data =======
train: sample number 3373
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/3373 [00:00<?, ?it/s]  7%|▋         | 222/3373 [00:00<00:02, 1216.63it/s] 13%|█▎        | 443/3373 [00:00<00:01, 1650.18it/s] 18%|█▊        | 623/3373 [00:00<00:01, 1673.06it/s] 24%|██▎       | 799/3373 [00:00<00:02, 1270.87it/s] 28%|██▊       | 941/3373 [00:00<00:01, 1290.22it/s] 32%|███▏      | 1080/3373 [00:00<00:02, 1051.31it/s] 35%|███▌      | 1197/3373 [00:00<00:02, 1069.34it/s] 39%|███▉      | 1332/3373 [00:01<00:01, 1134.00it/s] 44%|████▍     | 1486/3373 [00:01<00:01, 1238.15it/s] 48%|████▊     | 1617/3373 [00:01<00:01, 1256.83it/s] 52%|█████▏    | 1756/3373 [00:01<00:01, 1292.39it/s] 56%|█████▌    | 1889/3373 [00:01<00:01, 1290.61it/s] 60%|██████    | 2038/3373 [00:01<00:00, 1347.26it/s] 64%|██████▍   | 2175/3373 [00:01<00:01, 1075.16it/s] 68%|██████▊   | 2301/3373 [00:01<00:00, 1119.30it/s] 73%|███████▎  | 2457/3373 [00:01<00:00, 1234.29it/s] 77%|███████▋  | 2588/3373 [00:02<00:00, 1240.75it/s] 81%|████████  | 2718/3373 [00:02<00:00, 1254.82it/s] 84%|████████▍ | 2848/3373 [00:02<00:00, 1261.72it/s] 88%|████████▊ | 2985/3373 [00:02<00:00, 1289.33it/s] 92%|█████████▏| 3116/3373 [00:02<00:00, 1028.75it/s]100%|██████████| 3373/3373 [00:02<00:00, 1410.24it/s]100%|██████████| 3373/3373 [00:02<00:00, 1257.64it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/3373 [00:00<?, ?it/s]  3%|▎         | 99/3373 [00:00<00:03, 989.39it/s]  6%|▌         | 198/3373 [00:00<00:04, 646.93it/s]  8%|▊         | 284/3373 [00:00<00:04, 719.04it/s] 12%|█▏        | 392/3373 [00:00<00:03, 839.13it/s] 14%|█▍        | 482/3373 [00:00<00:03, 853.29it/s] 18%|█▊        | 594/3373 [00:00<00:02, 935.82it/s] 20%|██        | 691/3373 [00:00<00:02, 942.15it/s] 24%|██▍       | 826/3373 [00:00<00:02, 1066.25it/s] 29%|██▉       | 977/3373 [00:00<00:01, 1200.58it/s] 33%|███▎      | 1099/3373 [00:01<00:01, 1182.50it/s] 37%|███▋      | 1233/3373 [00:01<00:01, 1228.83it/s] 41%|████      | 1379/3373 [00:01<00:01, 1297.46it/s] 45%|████▍     | 1510/3373 [00:01<00:01, 1033.62it/s] 49%|████▊     | 1637/3373 [00:01<00:01, 1093.17it/s] 52%|█████▏    | 1754/3373 [00:01<00:01, 1112.13it/s] 55%|█████▌    | 1871/3373 [00:01<00:01, 1118.44it/s] 59%|█████▉    | 1987/3373 [00:01<00:01, 1114.15it/s] 62%|██████▏   | 2102/3373 [00:01<00:01, 1121.23it/s] 66%|██████▌   | 2217/3373 [00:02<00:01, 1124.26it/s] 70%|███████   | 2374/3373 [00:02<00:00, 1253.06it/s] 74%|███████▍  | 2501/3373 [00:02<00:00, 1253.38it/s] 78%|███████▊  | 2628/3373 [00:02<00:00, 1251.52it/s] 82%|████████▏ | 2771/3373 [00:02<00:00, 1303.96it/s] 86%|████████▌ | 2902/3373 [00:02<00:00, 1035.06it/s] 90%|█████████ | 3047/3373 [00:02<00:00, 1138.68it/s] 94%|█████████▍| 3170/3373 [00:02<00:00, 1151.68it/s] 98%|█████████▊| 3293/3373 [00:02<00:00, 1172.89it/s]100%|██████████| 3373/3373 [00:03<00:00, 1090.36it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/3373 [00:00<?, ?it/s]  4%|▍         | 136/3373 [00:00<00:02, 1342.80it/s]  8%|▊         | 271/3373 [00:00<00:02, 1331.82it/s] 14%|█▍        | 477/3373 [00:00<00:01, 1649.71it/s] 20%|██        | 683/3373 [00:00<00:01, 1807.58it/s] 26%|██▌       | 864/3373 [00:00<00:01, 1765.33it/s] 31%|███       | 1041/3373 [00:00<00:01, 1349.73it/s] 35%|███▌      | 1189/3373 [00:00<00:01, 1370.11it/s] 40%|███▉      | 1336/3373 [00:00<00:01, 1367.39it/s] 45%|████▍     | 1508/3373 [00:01<00:01, 1200.02it/s] 50%|████▉     | 1682/3373 [00:01<00:01, 1330.69it/s] 55%|█████▍    | 1852/3373 [00:01<00:01, 1423.89it/s] 62%|██████▏   | 2079/3373 [00:01<00:00, 1637.82it/s] 70%|██████▉   | 2347/3373 [00:01<00:00, 1905.59it/s] 76%|███████▌  | 2569/3373 [00:01<00:00, 1993.65it/s] 82%|████████▏ | 2775/3373 [00:01<00:00, 1553.02it/s] 87%|████████▋ | 2949/3373 [00:01<00:00, 1565.73it/s] 95%|█████████▌| 3211/3373 [00:02<00:00, 1514.29it/s]100%|██████████| 3373/3373 [00:02<00:00, 1535.99it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test1: sample number 411
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/411 [00:00<?, ?it/s] 78%|███████▊  | 322/411 [00:00<00:00, 1896.75it/s]100%|██████████| 411/411 [00:00<00:00, 2335.68it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/411 [00:00<?, ?it/s] 34%|███▍      | 141/411 [00:00<00:00, 1397.25it/s] 85%|████████▌ | 350/411 [00:00<00:00, 1802.41it/s]100%|██████████| 411/411 [00:00<00:00, 1977.64it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/411 [00:00<?, ?it/s] 65%|██████▌   | 269/411 [00:00<00:00, 2685.35it/s]100%|██████████| 411/411 [00:00<00:00, 2178.29it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test2: sample number 412
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/412 [00:00<?, ?it/s] 43%|████▎     | 176/412 [00:00<00:00, 1754.53it/s]100%|██████████| 412/412 [00:00<00:00, 2062.92it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/412 [00:00<?, ?it/s] 39%|███▉      | 160/412 [00:00<00:00, 1589.93it/s] 91%|█████████▏| 376/412 [00:00<00:00, 1924.15it/s]100%|██████████| 412/412 [00:00<00:00, 2018.32it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/412 [00:00<?, ?it/s] 18%|█▊        | 76/412 [00:00<00:00, 754.23it/s] 76%|███████▌  | 313/412 [00:00<00:00, 1675.17it/s]100%|██████████| 412/412 [00:00<00:00, 1960.42it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
test3: sample number 834
audio feature root: /root/autodl-tmp/MERTools-master/MERBench/dataset/mer2023-dataset-process/features/chinese-hubert-large-UTT
  0%|          | 0/834 [00:00<?, ?it/s]  3%|▎         | 22/834 [00:00<00:03, 217.79it/s] 25%|██▌       | 209/834 [00:00<00:00, 1184.47it/s] 42%|████▏     | 354/834 [00:00<00:00, 1305.29it/s] 61%|██████▏   | 512/834 [00:00<00:00, 1408.30it/s] 99%|█████████▊| 823/834 [00:00<00:00, 2018.81it/s]100%|██████████| 834/834 [00:00<00:00, 1656.86it/s]
Input feature chinese-hubert-large-UTT ===> dim is (1, 1024)
  0%|          | 0/834 [00:00<?, ?it/s] 17%|█▋        | 141/834 [00:00<00:00, 1407.86it/s] 34%|███▍      | 282/834 [00:00<00:00, 1404.94it/s] 51%|█████     | 423/834 [00:00<00:00, 1353.13it/s] 68%|██████▊   | 567/834 [00:00<00:00, 1381.57it/s] 85%|████████▍ | 706/834 [00:00<00:00, 1357.89it/s]100%|██████████| 834/834 [00:00<00:00, 1364.18it/s]
Input feature Baichuan-13B-Base-UTT ===> dim is (1, 5120)
  0%|          | 0/834 [00:00<?, ?it/s] 21%|██        | 171/834 [00:00<00:00, 1704.11it/s] 53%|█████▎    | 438/834 [00:00<00:00, 2267.83it/s] 80%|███████▉  | 665/834 [00:00<00:00, 2219.84it/s]100%|██████████| 834/834 [00:00<00:00, 2101.33it/s]
Input feature clip-vit-large-patch14-UTT ===> dim is (1, 768)
train&val folder:5; test sets:3
audio dimension: 1024; text dimension: 5120; video dimension: 768
====== Training and Evaluation =======
>>>>> Cross-validation: training on the 1 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.2706; eval:-0.1309; lr:0.000500
epoch:2; metric:emoval; train:0.1342; eval:0.3562; lr:0.000500
epoch:3; metric:emoval; train:0.3850; eval:0.4457; lr:0.000500
epoch:4; metric:emoval; train:0.5172; eval:0.4741; lr:0.000500
epoch:5; metric:emoval; train:0.5751; eval:0.5077; lr:0.000500
epoch:6; metric:emoval; train:0.6661; eval:0.5036; lr:0.000500
epoch:7; metric:emoval; train:0.6759; eval:0.3687; lr:0.000500
epoch:8; metric:emoval; train:0.7039; eval:0.5322; lr:0.000500
epoch:9; metric:emoval; train:0.7388; eval:0.4833; lr:0.000500
epoch:10; metric:emoval; train:0.7613; eval:0.4324; lr:0.000500
epoch:11; metric:emoval; train:0.7541; eval:0.3992; lr:0.000500
epoch:12; metric:emoval; train:0.7615; eval:0.4634; lr:0.000500
epoch:13; metric:emoval; train:0.7962; eval:0.4692; lr:0.000500
epoch:14; metric:emoval; train:0.7984; eval:0.5113; lr:0.000500
epoch:15; metric:emoval; train:0.8201; eval:0.5665; lr:0.000500
epoch:16; metric:emoval; train:0.8277; eval:0.5061; lr:0.000500
epoch:17; metric:emoval; train:0.8474; eval:0.5108; lr:0.000500
epoch:18; metric:emoval; train:0.8467; eval:0.5087; lr:0.000500
epoch:19; metric:emoval; train:0.8111; eval:0.4755; lr:0.000500
epoch:20; metric:emoval; train:0.8544; eval:0.4653; lr:0.000500
epoch:21; metric:emoval; train:0.8666; eval:0.3198; lr:0.000500
epoch:22; metric:emoval; train:0.8596; eval:0.4813; lr:0.000500
epoch:23; metric:emoval; train:0.8806; eval:0.5012; lr:0.000500
epoch:24; metric:emoval; train:0.8578; eval:0.4508; lr:0.000500
epoch:25; metric:emoval; train:0.8320; eval:0.5486; lr:0.000500
epoch:26; metric:emoval; train:0.8279; eval:0.3762; lr:0.000250
epoch:27; metric:emoval; train:0.8885; eval:0.5048; lr:0.000250
epoch:28; metric:emoval; train:0.9028; eval:0.5342; lr:0.000250
epoch:29; metric:emoval; train:0.9060; eval:0.4887; lr:0.000250
epoch:30; metric:emoval; train:0.9063; eval:0.5422; lr:0.000250
epoch:31; metric:emoval; train:0.9085; eval:0.4316; lr:0.000250
epoch:32; metric:emoval; train:0.8986; eval:0.5026; lr:0.000250
epoch:33; metric:emoval; train:0.9014; eval:0.5305; lr:0.000250
epoch:34; metric:emoval; train:0.8901; eval:0.5236; lr:0.000250
epoch:35; metric:emoval; train:0.9007; eval:0.4939; lr:0.000250
epoch:36; metric:emoval; train:0.9032; eval:0.5280; lr:0.000250
epoch:37; metric:emoval; train:0.9008; eval:0.5230; lr:0.000125
epoch:38; metric:emoval; train:0.9057; eval:0.5148; lr:0.000125
epoch:39; metric:emoval; train:0.8965; eval:0.5405; lr:0.000125
epoch:40; metric:emoval; train:0.9059; eval:0.4845; lr:0.000125
epoch:41; metric:emoval; train:0.9050; eval:0.5324; lr:0.000125
epoch:42; metric:emoval; train:0.9106; eval:0.5269; lr:0.000125
epoch:43; metric:emoval; train:0.9131; eval:0.5072; lr:0.000125
epoch:44; metric:emoval; train:0.9072; eval:0.5535; lr:0.000125
epoch:45; metric:emoval; train:0.9018; eval:0.5313; lr:0.000125
Early stopping at epoch 45, best epoch: 15
Step3: saving and testing on the 1 folder
>>>>> Finish: training on the 1-th folder, best_index: 14, duration: 2545.38001203537 >>>>>
>>>>> Cross-validation: training on the 2 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3352; eval:-0.0198; lr:0.000500
epoch:2; metric:emoval; train:0.1008; eval:0.2717; lr:0.000500
epoch:3; metric:emoval; train:0.3782; eval:0.4561; lr:0.000500
epoch:4; metric:emoval; train:0.5178; eval:0.4385; lr:0.000500
epoch:5; metric:emoval; train:0.5911; eval:0.4023; lr:0.000500
epoch:6; metric:emoval; train:0.6340; eval:0.4365; lr:0.000500
epoch:7; metric:emoval; train:0.6732; eval:0.4979; lr:0.000500
epoch:8; metric:emoval; train:0.7164; eval:0.4058; lr:0.000500
epoch:9; metric:emoval; train:0.7394; eval:0.4662; lr:0.000500
epoch:10; metric:emoval; train:0.7485; eval:0.4021; lr:0.000500
epoch:11; metric:emoval; train:0.7831; eval:0.5306; lr:0.000500
epoch:12; metric:emoval; train:0.8081; eval:0.4564; lr:0.000500
epoch:13; metric:emoval; train:0.7939; eval:0.4555; lr:0.000500
epoch:14; metric:emoval; train:0.7730; eval:0.5130; lr:0.000500
epoch:15; metric:emoval; train:0.8027; eval:0.4482; lr:0.000500
epoch:16; metric:emoval; train:0.8492; eval:0.4281; lr:0.000500
epoch:17; metric:emoval; train:0.8743; eval:0.4438; lr:0.000500
epoch:18; metric:emoval; train:0.8468; eval:0.4415; lr:0.000500
epoch:19; metric:emoval; train:0.8533; eval:0.4423; lr:0.000500
epoch:20; metric:emoval; train:0.8588; eval:0.4803; lr:0.000500
epoch:21; metric:emoval; train:0.8729; eval:0.4650; lr:0.000500
epoch:22; metric:emoval; train:0.8602; eval:0.4789; lr:0.000250
epoch:23; metric:emoval; train:0.9227; eval:0.5135; lr:0.000250
epoch:24; metric:emoval; train:0.9252; eval:0.5000; lr:0.000250
epoch:25; metric:emoval; train:0.9308; eval:0.4983; lr:0.000250
epoch:26; metric:emoval; train:0.9356; eval:0.4968; lr:0.000250
epoch:27; metric:emoval; train:0.9226; eval:0.4688; lr:0.000250
epoch:28; metric:emoval; train:0.9106; eval:0.4657; lr:0.000250
epoch:29; metric:emoval; train:0.8986; eval:0.5157; lr:0.000250
epoch:30; metric:emoval; train:0.9129; eval:0.4847; lr:0.000250
epoch:31; metric:emoval; train:0.9236; eval:0.4998; lr:0.000250
epoch:32; metric:emoval; train:0.8935; eval:0.5118; lr:0.000250
epoch:33; metric:emoval; train:0.8978; eval:0.5218; lr:0.000125
epoch:34; metric:emoval; train:0.9219; eval:0.5126; lr:0.000125
epoch:35; metric:emoval; train:0.9158; eval:0.5275; lr:0.000125
epoch:36; metric:emoval; train:0.9230; eval:0.5001; lr:0.000125
epoch:37; metric:emoval; train:0.9179; eval:0.4729; lr:0.000125
epoch:38; metric:emoval; train:0.9149; eval:0.4997; lr:0.000125
epoch:39; metric:emoval; train:0.8994; eval:0.5063; lr:0.000125
epoch:40; metric:emoval; train:0.9013; eval:0.5186; lr:0.000125
epoch:41; metric:emoval; train:0.9131; eval:0.4817; lr:0.000125
Early stopping at epoch 41, best epoch: 11
Step3: saving and testing on the 2 folder
>>>>> Finish: training on the 2-th folder, best_index: 10, duration: 2486.499979734421 >>>>>
>>>>> Cross-validation: training on the 3 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3397; eval:-0.1426; lr:0.000500
epoch:2; metric:emoval; train:0.0638; eval:0.1373; lr:0.000500
epoch:3; metric:emoval; train:0.3669; eval:0.3558; lr:0.000500
epoch:4; metric:emoval; train:0.4876; eval:0.4780; lr:0.000500
epoch:5; metric:emoval; train:0.5349; eval:0.4814; lr:0.000500
epoch:6; metric:emoval; train:0.6090; eval:0.5045; lr:0.000500
epoch:7; metric:emoval; train:0.6520; eval:0.4629; lr:0.000500
epoch:8; metric:emoval; train:0.6758; eval:0.4364; lr:0.000500
epoch:9; metric:emoval; train:0.7172; eval:0.4851; lr:0.000500
epoch:10; metric:emoval; train:0.7175; eval:0.5099; lr:0.000500
epoch:11; metric:emoval; train:0.7545; eval:0.4158; lr:0.000500
epoch:12; metric:emoval; train:0.7570; eval:0.5180; lr:0.000500
epoch:13; metric:emoval; train:0.8018; eval:0.4381; lr:0.000500
epoch:14; metric:emoval; train:0.7857; eval:0.4892; lr:0.000500
epoch:15; metric:emoval; train:0.7726; eval:0.5333; lr:0.000500
epoch:16; metric:emoval; train:0.8132; eval:0.4991; lr:0.000500
epoch:17; metric:emoval; train:0.8303; eval:0.4393; lr:0.000500
epoch:18; metric:emoval; train:0.8217; eval:0.5182; lr:0.000500
epoch:19; metric:emoval; train:0.8149; eval:0.4765; lr:0.000500
epoch:20; metric:emoval; train:0.8315; eval:0.4765; lr:0.000500
epoch:21; metric:emoval; train:0.8385; eval:0.5031; lr:0.000500
epoch:22; metric:emoval; train:0.8505; eval:0.4886; lr:0.000500
epoch:23; metric:emoval; train:0.8705; eval:0.5140; lr:0.000500
epoch:24; metric:emoval; train:0.8618; eval:0.5207; lr:0.000500
epoch:25; metric:emoval; train:0.8417; eval:0.4130; lr:0.000500
epoch:26; metric:emoval; train:0.8566; eval:0.4680; lr:0.000250
epoch:27; metric:emoval; train:0.9132; eval:0.5177; lr:0.000250
epoch:28; metric:emoval; train:0.9155; eval:0.4943; lr:0.000250
epoch:29; metric:emoval; train:0.9142; eval:0.4887; lr:0.000250
epoch:30; metric:emoval; train:0.9160; eval:0.4758; lr:0.000250
epoch:31; metric:emoval; train:0.8943; eval:0.5156; lr:0.000250
epoch:32; metric:emoval; train:0.8988; eval:0.4793; lr:0.000250
epoch:33; metric:emoval; train:0.9032; eval:0.4860; lr:0.000250
epoch:34; metric:emoval; train:0.9015; eval:0.5002; lr:0.000250
epoch:35; metric:emoval; train:0.8816; eval:0.5091; lr:0.000250
epoch:36; metric:emoval; train:0.8723; eval:0.4755; lr:0.000250
epoch:37; metric:emoval; train:0.8942; eval:0.5139; lr:0.000125
epoch:38; metric:emoval; train:0.9062; eval:0.5108; lr:0.000125
epoch:39; metric:emoval; train:0.9053; eval:0.5101; lr:0.000125
epoch:40; metric:emoval; train:0.8990; eval:0.5337; lr:0.000125
epoch:41; metric:emoval; train:0.8893; eval:0.4981; lr:0.000125
epoch:42; metric:emoval; train:0.9060; eval:0.5332; lr:0.000125
epoch:43; metric:emoval; train:0.9027; eval:0.5146; lr:0.000125
epoch:44; metric:emoval; train:0.9104; eval:0.5596; lr:0.000125
epoch:45; metric:emoval; train:0.9050; eval:0.5210; lr:0.000125
epoch:46; metric:emoval; train:0.9099; eval:0.5256; lr:0.000125
epoch:47; metric:emoval; train:0.9129; eval:0.5018; lr:0.000125
epoch:48; metric:emoval; train:0.9158; eval:0.5085; lr:0.000125
epoch:49; metric:emoval; train:0.9157; eval:0.5198; lr:0.000125
epoch:50; metric:emoval; train:0.9078; eval:0.4988; lr:0.000125
epoch:51; metric:emoval; train:0.8953; eval:0.4833; lr:0.000125
epoch:52; metric:emoval; train:0.9214; eval:0.5237; lr:0.000125
epoch:53; metric:emoval; train:0.9122; eval:0.5222; lr:0.000125
epoch:54; metric:emoval; train:0.9142; eval:0.4975; lr:0.000125
epoch:55; metric:emoval; train:0.9194; eval:0.5159; lr:0.000063
epoch:56; metric:emoval; train:0.9214; eval:0.5212; lr:0.000063
epoch:57; metric:emoval; train:0.9279; eval:0.5308; lr:0.000063
epoch:58; metric:emoval; train:0.9336; eval:0.5100; lr:0.000063
epoch:59; metric:emoval; train:0.9297; eval:0.5083; lr:0.000063
epoch:60; metric:emoval; train:0.9254; eval:0.5028; lr:0.000063
epoch:61; metric:emoval; train:0.9352; eval:0.5075; lr:0.000063
epoch:62; metric:emoval; train:0.9300; eval:0.4991; lr:0.000063
epoch:63; metric:emoval; train:0.9382; eval:0.5074; lr:0.000063
epoch:64; metric:emoval; train:0.9312; eval:0.5334; lr:0.000063
epoch:65; metric:emoval; train:0.9277; eval:0.4947; lr:0.000063
epoch:66; metric:emoval; train:0.9290; eval:0.4977; lr:0.000031
epoch:67; metric:emoval; train:0.9424; eval:0.4885; lr:0.000031
epoch:68; metric:emoval; train:0.9422; eval:0.5184; lr:0.000031
epoch:69; metric:emoval; train:0.9370; eval:0.5076; lr:0.000031
epoch:70; metric:emoval; train:0.9479; eval:0.4805; lr:0.000031
epoch:71; metric:emoval; train:0.9436; eval:0.5033; lr:0.000031
epoch:72; metric:emoval; train:0.9377; eval:0.4869; lr:0.000031
epoch:73; metric:emoval; train:0.9389; eval:0.5043; lr:0.000031
epoch:74; metric:emoval; train:0.9348; eval:0.4537; lr:0.000031
Early stopping at epoch 74, best epoch: 44
Step3: saving and testing on the 3 folder
>>>>> Finish: training on the 3-th folder, best_index: 43, duration: 4598.591636657715 >>>>>
>>>>> Cross-validation: training on the 4 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3496; eval:0.0058; lr:0.000500
epoch:2; metric:emoval; train:0.0999; eval:0.2949; lr:0.000500
epoch:3; metric:emoval; train:0.3535; eval:0.5084; lr:0.000500
epoch:4; metric:emoval; train:0.5149; eval:0.4554; lr:0.000500
epoch:5; metric:emoval; train:0.5631; eval:0.3365; lr:0.000500
epoch:6; metric:emoval; train:0.6063; eval:0.5623; lr:0.000500
epoch:7; metric:emoval; train:0.6831; eval:0.5060; lr:0.000500
epoch:8; metric:emoval; train:0.6815; eval:0.5506; lr:0.000500
epoch:9; metric:emoval; train:0.7305; eval:0.4974; lr:0.000500
epoch:10; metric:emoval; train:0.7246; eval:0.4955; lr:0.000500
epoch:11; metric:emoval; train:0.7497; eval:0.5134; lr:0.000500
epoch:12; metric:emoval; train:0.7751; eval:0.4948; lr:0.000500
epoch:13; metric:emoval; train:0.7957; eval:0.4413; lr:0.000500
epoch:14; metric:emoval; train:0.8011; eval:0.5300; lr:0.000500
epoch:15; metric:emoval; train:0.7968; eval:0.5659; lr:0.000500
epoch:16; metric:emoval; train:0.8116; eval:0.5160; lr:0.000500
epoch:17; metric:emoval; train:0.8421; eval:0.5360; lr:0.000500
epoch:18; metric:emoval; train:0.8403; eval:0.5570; lr:0.000500
epoch:19; metric:emoval; train:0.8496; eval:0.4055; lr:0.000500
epoch:20; metric:emoval; train:0.8531; eval:0.5028; lr:0.000500
epoch:21; metric:emoval; train:0.8711; eval:0.3734; lr:0.000500
epoch:22; metric:emoval; train:0.8313; eval:0.5332; lr:0.000500
epoch:23; metric:emoval; train:0.8654; eval:0.5318; lr:0.000500
epoch:24; metric:emoval; train:0.8659; eval:0.5111; lr:0.000500
epoch:25; metric:emoval; train:0.8628; eval:0.5211; lr:0.000500
epoch:26; metric:emoval; train:0.8749; eval:0.5436; lr:0.000250
epoch:27; metric:emoval; train:0.8860; eval:0.5643; lr:0.000250
epoch:28; metric:emoval; train:0.9050; eval:0.5635; lr:0.000250
epoch:29; metric:emoval; train:0.9034; eval:0.5889; lr:0.000250
epoch:30; metric:emoval; train:0.9167; eval:0.5566; lr:0.000250
epoch:31; metric:emoval; train:0.9027; eval:0.5615; lr:0.000250
epoch:32; metric:emoval; train:0.9061; eval:0.5429; lr:0.000250
epoch:33; metric:emoval; train:0.8944; eval:0.5821; lr:0.000250
epoch:34; metric:emoval; train:0.8903; eval:0.4924; lr:0.000250
epoch:35; metric:emoval; train:0.8798; eval:0.5137; lr:0.000250
epoch:36; metric:emoval; train:0.8937; eval:0.5396; lr:0.000250
epoch:37; metric:emoval; train:0.8783; eval:0.5019; lr:0.000250
epoch:38; metric:emoval; train:0.8621; eval:0.5140; lr:0.000250
epoch:39; metric:emoval; train:0.8771; eval:0.5442; lr:0.000250
epoch:40; metric:emoval; train:0.8824; eval:0.5461; lr:0.000125
epoch:41; metric:emoval; train:0.9091; eval:0.5463; lr:0.000125
epoch:42; metric:emoval; train:0.9113; eval:0.5536; lr:0.000125
epoch:43; metric:emoval; train:0.9117; eval:0.5809; lr:0.000125
epoch:44; metric:emoval; train:0.9221; eval:0.5634; lr:0.000125
epoch:45; metric:emoval; train:0.9140; eval:0.4675; lr:0.000125
epoch:46; metric:emoval; train:0.9042; eval:0.5159; lr:0.000125
epoch:47; metric:emoval; train:0.9164; eval:0.5203; lr:0.000125
epoch:48; metric:emoval; train:0.9104; eval:0.5324; lr:0.000125
epoch:49; metric:emoval; train:0.9193; eval:0.5386; lr:0.000125
epoch:50; metric:emoval; train:0.9214; eval:0.5694; lr:0.000125
epoch:51; metric:emoval; train:0.9108; eval:0.4959; lr:0.000063
epoch:52; metric:emoval; train:0.9254; eval:0.5454; lr:0.000063
epoch:53; metric:emoval; train:0.9186; eval:0.5441; lr:0.000063
epoch:54; metric:emoval; train:0.9228; eval:0.5454; lr:0.000063
epoch:55; metric:emoval; train:0.9302; eval:0.5451; lr:0.000063
epoch:56; metric:emoval; train:0.9341; eval:0.5408; lr:0.000063
epoch:57; metric:emoval; train:0.9296; eval:0.5097; lr:0.000063
epoch:58; metric:emoval; train:0.9246; eval:0.5505; lr:0.000063
epoch:59; metric:emoval; train:0.9388; eval:0.5385; lr:0.000063
Early stopping at epoch 59, best epoch: 29
Step3: saving and testing on the 4 folder
>>>>> Finish: training on the 4-th folder, best_index: 28, duration: 2560.5111701488495 >>>>>
>>>>> Cross-validation: training on the 5 folder >>>>>
Step1: build model (each folder has its own model)
/root/miniconda3/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
Step2: training (multiple epoches)
epoch:1; metric:emoval; train:-0.3156; eval:-0.0156; lr:0.000500
epoch:2; metric:emoval; train:0.1606; eval:0.3794; lr:0.000500
epoch:3; metric:emoval; train:0.4025; eval:0.4693; lr:0.000500
epoch:4; metric:emoval; train:0.4865; eval:0.4629; lr:0.000500
epoch:5; metric:emoval; train:0.5577; eval:0.5047; lr:0.000500
epoch:6; metric:emoval; train:0.6161; eval:0.4441; lr:0.000500
epoch:7; metric:emoval; train:0.6660; eval:0.5576; lr:0.000500
epoch:8; metric:emoval; train:0.6868; eval:0.5179; lr:0.000500
epoch:9; metric:emoval; train:0.6666; eval:0.4447; lr:0.000500
epoch:10; metric:emoval; train:0.7578; eval:0.4862; lr:0.000500
epoch:11; metric:emoval; train:0.7690; eval:0.5197; lr:0.000500
epoch:12; metric:emoval; train:0.7598; eval:0.5233; lr:0.000500
epoch:13; metric:emoval; train:0.8056; eval:0.5130; lr:0.000500
epoch:14; metric:emoval; train:0.7949; eval:0.4219; lr:0.000500
epoch:15; metric:emoval; train:0.7866; eval:0.4746; lr:0.000500
epoch:16; metric:emoval; train:0.8188; eval:0.4955; lr:0.000500
epoch:17; metric:emoval; train:0.8141; eval:0.5471; lr:0.000500
epoch:18; metric:emoval; train:0.8050; eval:0.5188; lr:0.000250
epoch:19; metric:emoval; train:0.8891; eval:0.5716; lr:0.000250
epoch:20; metric:emoval; train:0.9192; eval:0.5168; lr:0.000250
epoch:21; metric:emoval; train:0.9245; eval:0.5424; lr:0.000250
epoch:22; metric:emoval; train:0.9225; eval:0.5248; lr:0.000250
epoch:23; metric:emoval; train:0.9122; eval:0.4906; lr:0.000250
epoch:24; metric:emoval; train:0.8996; eval:0.5511; lr:0.000250
epoch:25; metric:emoval; train:0.8903; eval:0.5683; lr:0.000250
epoch:26; metric:emoval; train:0.8983; eval:0.5448; lr:0.000250
epoch:27; metric:emoval; train:0.9066; eval:0.5460; lr:0.000250
epoch:28; metric:emoval; train:0.9074; eval:0.5488; lr:0.000250
epoch:29; metric:emoval; train:0.8924; eval:0.5076; lr:0.000250
epoch:30; metric:emoval; train:0.8709; eval:0.5463; lr:0.000125
epoch:31; metric:emoval; train:0.9090; eval:0.5667; lr:0.000125
epoch:32; metric:emoval; train:0.9178; eval:0.5658; lr:0.000125
epoch:33; metric:emoval; train:0.9212; eval:0.5553; lr:0.000125
epoch:34; metric:emoval; train:0.9112; eval:0.5248; lr:0.000125
epoch:35; metric:emoval; train:0.9103; eval:0.5469; lr:0.000125
epoch:36; metric:emoval; train:0.9012; eval:0.5374; lr:0.000125
epoch:37; metric:emoval; train:0.9212; eval:0.5584; lr:0.000125
epoch:38; metric:emoval; train:0.8952; eval:0.5399; lr:0.000125
epoch:39; metric:emoval; train:0.8999; eval:0.4808; lr:0.000125
epoch:40; metric:emoval; train:0.8949; eval:0.5291; lr:0.000125
epoch:41; metric:emoval; train:0.8844; eval:0.5275; lr:0.000063
epoch:42; metric:emoval; train:0.9090; eval:0.5538; lr:0.000063
epoch:43; metric:emoval; train:0.9184; eval:0.5453; lr:0.000063
epoch:44; metric:emoval; train:0.9154; eval:0.5202; lr:0.000063
epoch:45; metric:emoval; train:0.9282; eval:0.5227; lr:0.000063
epoch:46; metric:emoval; train:0.9165; eval:0.5210; lr:0.000063
epoch:47; metric:emoval; train:0.9108; eval:0.5351; lr:0.000063
epoch:48; metric:emoval; train:0.9057; eval:0.5450; lr:0.000063
epoch:49; metric:emoval; train:0.9101; eval:0.5147; lr:0.000063
Early stopping at epoch 49, best epoch: 19
Step3: saving and testing on the 5 folder
>>>>> Finish: training on the 5-th folder, best_index: 18, duration: 1042.9061298370361 >>>>>
====== Prediction and Saving =======
save results in ./saved-trimodal/result/cv_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7350_acc:0.7376_val:0.6864_1770136596.6949956.npz
save results in ./saved-trimodal/result/test1_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7993_acc:0.8005_val:0.6666_1770136596.6949956.npz
save results in ./saved-trimodal/result/test2_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.7619_acc:0.7621_val:0.6704_1770136596.6949956.npz
save results in ./saved-trimodal/result/test3_features:Baichuan-13B-Base-UTT+chinese-hubert-large-UTT+clip-vit-large-patch14-UTT_dataset:MER2023_model:attention_robust_v5+utt+None_f1:0.8711_acc:0.8729_val:79.2659_1770136596.6949956.npz
